<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>Linear Regression & Logistic Regression - 奔赴下一场山海</title><meta name=keywords content="博客,程序员,架构师,思考,读书,笔记,技术,分享,大数据,产品"><meta name=author content="Murphy"><meta property="og:title" content="Linear Regression & Logistic Regression"><meta property="og:site_name" content="奔赴下一场山海"><meta property="og:image" content="/img/author.jpg"><meta name=title content="Linear Regression & Logistic Regression - 奔赴下一场山海"><meta name=description content="欢迎来到Murphy的博客网站。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i>
<a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span>
<span class=site-title>奔赴下一场山海</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>但远山长，云山乱，晓山青。</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span>
<span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://murphyhanxu.github.io/post/linearregressionlogisticregression/ itemprop=url>Linear Regression & Logistic Regression</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i>
<span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2023-03-30">2023-03-30</time></span>
<span class=post-category>&nbsp; | &nbsp;
<i class="fa fa-folder-o fa-fw"></i>
<span class=post-meta-item-text>分类：</span>
<span itemprop=about itemscope itemtype=https://schema.org/Thing><a href=/categories/cs itemprop=url rel=index style=text-decoration:underline><span itemprop=name>CS</span></a>
&nbsp;</span></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i>
<span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>1186 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i>
<span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>3分钟</span></span>
<span id=/post/linearregressionlogisticregression/ class=leancloud_visitors data-flag-title="Linear Regression & Logistic Regression">|
<i class="fa fa-binoculars fa-fw"></i>
<span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><h4 id=linear-regression>Linear Regression</h4><p>一个一般的线性回归的问题为给出共$N$个样本$x^1,\cdots,x^N$，其中每个$x^j,,j=1,\cdots,N$有$m$个特征$x_1^j,\cdots,x_m^j$和这$N$个样本的观测数据$y^1,\cdots,y^N$，对每个$j$设有$n+1$个权重为$\omega_0^j,\omega_1^j,\cdots,\omega_n^j$。考虑$\omega_i^j$的线性组合：
$$
\hat{y}(x^j)=\omega_0+\omega_1x_1^j+\cdots+\omega_mx_m^j
$$
定义一些符号：</p><ol><li>$x^j=[x_0^j=1,x_1^j,\cdots,x_m^j]^T,,j=1,\cdots,N$。</li><li>$X=\left[(x^1)^T,\cdots,(x^N)^T\right]=\begin{bmatrix}1&x^1_1&\cdots &x^1_m\1&x^2_1&\cdots&x^2_m\\vdots&\vdots&\ddots&\vdots\1&x^N_1&\cdots&x^N_m\end{bmatrix}_{N\times(m+1)}$</li><li>$\omega=\left[\omega_0,\omega_1,\cdots,\omega_m\right]^T$</li><li>$y=\left[y^1,\cdots,y^N\right]^T$</li></ol><p>我们要解决的问题是：希望通过$x^1,\cdots,x^N$这些在$\Bbb{R}^{m+1}$空间中的$N$个点去拟合一条直线$\hat{y}(x^j)$，其能最佳地逼近$y(x^j)$。</p><p>接下来通过极小化MSE损失函数得到最优的$\omega$，定义loss为：
$$
\begin{align}loss&=\frac{1}{2}\sum_{j=1}^N[\hat{y}(x^j)-y^j]^2\
&=\frac{1}{2}\sum_{j=1}^N[\omega^Tx^j-y^j]^2\
&=\frac{1}{2}(X\omega-y)^T(X\omega-y)
\end{align}
$$
则问题称为如下泛函极小问题：
$$
\min_{\omega}\frac{1}{2}(X\omega-y)^T(X\omega-y)
$$
一般用数值代数的方法，可以直接令loss的梯度等于零得到最优解（极小值点）$x^<em>$：
$$
\begin{align}\nabla_{\omega} loss&=\nabla_{\omega}[\frac{1}{2}(\omega^TX^T-y^T)(X\omega-y)]\
&= \nabla_{\omega}[\frac{1}{2}(\omega^TX^TX\omega-\omega^TX^Ty-y^TX\omega+y^Ty)]\
&=\frac{1}{2}[2X^TX\omega-X^Ty-(y^TX)^T]\
&=X^TX\omega-X^Ty\
&=0\
\implies x^</em>&=(X^TX)^{-1}X^Ty
\end{align}
$$
而采用梯度下降法(Gredient descent)迭代过程为：
$$
\begin{align}\omega^{k+1}&=\omega^k-\alpha^k\nabla_{\omega}loss\
&=\omega^k-\alpha^k\sum_{j=1}^N[\omega^Tx^j-y^j]x^j
\end{align}
$$</p><h4 id=logistic-regression>Logistic Regression</h4><p>一个二分类问题为给出共$N$个样本$x^1,\cdots,x^N$，其中每个$x^j,,j=1,\cdots,N$有$m$个特征$x_1^j,\cdots,x_m^j$和标签值$y^j=0,or,1$，对每个$j$设有$n+1$个权重为$\omega_0^j,\omega_1^j,\cdots,\omega_n^j$。考虑$\omega^Tx$的激活函数：
$$
\hat{y}(x^j)=\sigma(\omega^Tx^j)=\frac{1}{1+\exp(-\omega^Tx^j)}
$$
定义一些符号：</p><ol><li>$x^j=[x_0^j=1,x_1^j,\cdots,x_m^j]^T,,j=1,\cdots,N$。</li><li>$X=\left[(x^1)^T,\cdots,(x^N)^T\right]=\begin{bmatrix}1&x^1_1&\cdots &x^1_m\1&x^2_1&\cdots&x^2_m\\vdots&\vdots&\ddots&\vdots\1&x^N_1&\cdots&x^N_m\end{bmatrix}_{N\times(m+1)}$</li><li>$\omega=\left[\omega_0,\omega_1,\cdots,\omega_m\right]^T$</li><li>$y=\left[y^1,\cdots,y^N\right]^T$</li></ol><p>我们要解决的问题是：希望通过在$\Bbb{R}^{m+1}$空间中找到一条直线将$x^1,\cdots,x^N$这$N$个点分成两类。</p><p>如何定义损失函数呢？</p><p>假设$y^j$是独立的Bernoulli随机变量，则在参数$\omega$下，概率密度函数为：
$$
\begin{align}p(y^j|x^j,\omega)&=
\begin{cases}
\hat{y}(x^j)\qquad \quad ,,,,,y^j=1\
1-\hat{y}(x^j)\qquad y^j=0
\end{cases}\
&=\hat{y}(x^j)^{y^j}[1-\hat{y}(x^j)]^{1-y^j}\quad y^j\in{0,1}
\end{align}
$$
则极大似然函数为：
$$
L(\omega)=\prod_{j=1}^N{\hat{y}(x^j)^{y^j}[1-\hat{y}(x^j)]^{1-y^j}}
$$
去极大化似然函数$\max L(\omega)$，等价于$\max l(\omega)$，其中
$$
\begin{align}l(\omega)&=\sum_{j=1}^N{y^j\ln\hat{y}(x^j)+(1-y^j)\ln(1-\hat{y}(x^j))}\
&=\sum_{j=1}^N{y^j\ln\frac{1}{1+\exp(-\omega^Tx^j)}+(1-y^j)\ln(1-\frac{1}{1+\exp(-\omega^Tx^j)})}\
&=\sum_{j=1}^N{-y^j\ln[1+\exp(-\omega^Tx^j)]+(1-y^j)\ln\frac{\exp(-\omega^Tx^j)}{1+\exp(-\omega^Tx^j)}}\
&=\sum_{j=1}^N{-y^j\ln[1+\exp(-\omega^Tx^j)]+(1-y^j)\ln\exp(-\omega^Tx^j)-(1-y^j)\ln[1+\exp(-\omega^Tx^j)]\
&=\sum_{j=1}^N-(1-y^j)(\omega^Tx^j)-\ln[1+\exp(-\omega^Tx^j)]
\end{align}
$$
于是$\max l(\omega)\iff\min\sum_{j=1}^N{-y^j\ln\hat{y}(x^j)-(1-y^j)\ln(1-\hat{y}(x^j))}=\min loss,crossentorpy$</p><p>这证明了极小化交叉熵损失函数和极大化似然估计等价，这也是为什么分类问题用交叉熵损失函数，而不用MSE损失函数的根本原因！</p><p>而
$$
\begin{align}\nabla_\omega loss&=\sum_{j=1}^N\frac{-\exp (-\omega^Tx^j)x^j}{1+\exp(-\omega^Tx^j)}+(1-y^j)x^j\
&=\sum_{j=1}^N\frac{x^j}{1+\exp(-\omega^Tx^j)}-y^jx^j\
&=\sum_{j=1}^N\sigma(\omega^Tx^j)x^j-y^jx^j
\end{align}
$$</p><p>$$
\begin{align}\nabla^2_\omega loss&=\sum_{j=1}^N\frac{\exp (-\omega^Tx^j)(x^j)^2}{1+\exp(-\omega^Tx^j)}\&=\sum_{j=1}^N\frac{(x^j)^2+\exp (-\omega^Tx^j)(x^j)^2-(x^j)^2}{1+\exp(-\omega^Tx^j)}\
&=\sum_{j=1}^N(x^j)^2\sigma(\omega^Tx^j)-(x^j)^2\sigma(\omega^Tx^j)^2\
&=\sum_{j=1}^N(x^j)^2\sigma(\omega^Tx^j)(1-\sigma(\omega^Tx^j))\ge0
\end{align}
$$</p><p>因此loss函数是下凸函数，局部极小值就是全局最小值，因此</p><p>而采用梯度下降法(Gredient descent)迭代过程为：
$$
\begin{align}\omega^{k+1}&=\omega^k-\alpha^k\nabla_{\omega}loss\
&=\omega^k-\alpha^k\sum_{j=1}^N[\sigma(\omega^Tx^j)-y^j]x^j
\end{align}
$$
这与Linear Regression的迭代表达式高度相像！事实上，Linear Regression的激活函数$\sigma(x)=x$就是恒等映射而已。</p></div><footer class=post-footer><div class=post-tags><a href=/tags/math rel=tag title=Math>#Math#</a></div><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.jpg width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>Linear Regression & Logistic Regression</p><p><span>链接：</span>https://murphyhanxu.github.io/post/linearregressionlogisticregression/</p><p><span>作者：</span>Murphy</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick='var qr=document.getElementById("QR");qr.style.display==="none"?qr.style.display="block":qr.style.display="none"'>
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"></div><div class="post-nav-prev post-nav-item"><a href=https://murphyhanxu.github.io/post/note-of-numerical-experiments/ rel=prev title="Notes of Numerical Experiments">Notes of Numerical Experiments
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>文章目录</li><li class=sidebar-nav-overview data-target=site-overview>站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/avatar.png alt=Murphy><p class=site-author-name itemprop=name>Murphy</p><p class="site-description motion-element" itemprop=description>谁的脸谁的姓名</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>19</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>1</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>8</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/MurphyHanxu target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>
GitHub</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li><li class=links-of-blogroll-item><a href=https://math.mickeylili.com/ title=Mickeylili target=_blank>Mickeylili</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>
标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/machine-learning>Machine learning</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/github-pages>Github pages</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python>Python</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/hugo>Hugo</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/math>Math</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/sql>SQL</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/didl>Didl</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/mathematical-modeling>Mathematical modeling</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><nav id=TableOfContents><ul><li><ul><li></li></ul></li></ul></nav></div></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2023</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=copyright-author>奔赴下一场山海</span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i>
<span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script>
<script type=text/javascript src=/js/search.js></script>
<script type=text/javascript src=/js/affix.js></script>
<script type=text/javascript src=/js/scrollspy.js></script>
<script type=text/javascript>function detectIE(){var e=window.navigator.userAgent,t=e.indexOf("MSIE "),n=e.indexOf("Trident/"),s=e.indexOf("Edge/");return t>0||n>0||s>0?-1:1}function getCntViewHeight(){var t=$("#content").height(),e=$(window).height(),n=t>e?t-e:$(document).height()-e;return n}function getScrollbarWidth(){var e=$("<div />").addClass("scrollbar-measure").prependTo("body"),t=e[0],n=t.offsetWidth-t.clientWidth;return e.remove(),n}function registerBackTop(){var t=50,e=$(".back-to-top");$(window).on("scroll",function(){e.toggleClass("back-to-top-on",window.pageYOffset>t);var s=$(window).scrollTop(),o=getCntViewHeight(),i=s/o,n=Math.round(i*100),a=n>100?100:n;$("#scrollpercent>span").html(a)}),e.on("click",function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var e=".post-toc",s=$(e),t=".active-current";s.on("activate.bs.scrollspy",function(){var t=$(e+" .active").last();n(),t.addClass("active-current")}).on("clear.bs.scrollspy",n),$("body").scrollspy({target:e});function n(){$(e+" "+t).removeClass(t.substring(1))}}function initAffix(){var e=$(".header-inner").height(),t=parseInt($(".main").css("padding-bottom"),10),n=e+10;$(".sidebar-inner").affix({offset:{top:n,bottom:t}}),$(document).on("affixed.bs.affix",function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){$(window).on("resize",function(){e&&clearTimeout(e),e=setTimeout(function(){var e=document.body.clientHeight-100;updateTOCHeight(e)},0)}),updateTOCHeight(document.body.clientHeight-100);var e,t=getScrollbarWidth();$(".post-toc").css("width","calc(100% + "+t+"px)")}function updateTOCHeight(e){e=e||"auto",$(".post-toc").css("max-height",e)}$(function(){var e,t,n,s,o=$(".header-inner").height()+10;$("#sidebar").css({'margin-top':o}).show(),t=parseInt($("#sidebar").css("margin-top")),n=parseInt($(".sidebar-inner").css("height")),e=t+n,s=$(".content-wrap").height(),s<e&&$(".content-wrap").css("min-height",e),$(".site-nav-toggle").on("click",function(){var e=$(".site-nav"),o=$(".toggle"),t="site-nav-on",i="toggle-close",n=e.hasClass(t),a=n?"slideUp":"slideDown",s=n?"removeClass":"addClass";e.stop()[a]("normal",function(){e[s](t),o[s](i)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$(".sidebar-nav-toc").click(function(){$(this).addClass("sidebar-nav-active"),$(this).next().removeClass("sidebar-nav-active"),$("."+$(this).next().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)}),$(".sidebar-nav-overview").click(function(){$(this).addClass("sidebar-nav-active"),$(this).prev().removeClass("sidebar-nav-active"),$("."+$(this).prev().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script>
<script type=text/javascript>$(function(){$(".post-body").viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+"//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js",function(){new Waline({el:"#wcomments",visitor:!0,avatar:"wavatar",avatarCDN:"https://sdn.geekzu.org/avatar/",avatarForce:!1,wordLimit:"200",placeholder:" 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ",requiredFields:["nick","mail"],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$("#wcomments").html("抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。")})</script><script>MathJax={tex:{inlineMath:[["$","$"]]},displayMath:[["$$","$$"],["[[","]]"]],svg:{fontCache:"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script>
<script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script>
<script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script></body></html>