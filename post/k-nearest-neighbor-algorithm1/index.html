<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>k近邻算法--1.k近邻算法概述 - 奔赴下一场山海</title><meta name=keywords content="博客,程序员,架构师,思考,读书,笔记,技术,分享,大数据,产品"><meta name=author content="Murphy"><meta property="og:title" content="k近邻算法--1.k近邻算法概述"><meta property="og:site_name" content="奔赴下一场山海"><meta property="og:image" content="/img/author.jpg"><meta name=title content="k近邻算法--1.k近邻算法概述 - 奔赴下一场山海"><meta name=description content="欢迎来到Murphy的博客网站。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i>
<a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span>
<span class=site-title>奔赴下一场山海</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>但远山长，云山乱，晓山青。</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span>
<span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://murphyhanxu.github.io/post/k-nearest-neighbor-algorithm1/ itemprop=url>k近邻算法--1.k近邻算法概述</a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i>
<span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="2022-08-09">2022-08-09</time></span>
<span class=post-category>&nbsp; | &nbsp;
<i class="fa fa-folder-o fa-fw"></i>
<span class=post-meta-item-text>分类：</span>
<span itemprop=about itemscope itemtype=https://schema.org/Thing><a href=/categories/cs itemprop=url rel=index style=text-decoration:underline><span itemprop=name>CS</span></a>
&nbsp;</span></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i>
<span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>2532 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i>
<span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>6分钟</span></span>
<span id=/post/k-nearest-neighbor-algorithm1/ class=leancloud_visitors data-flag-title=k近邻算法--1.k近邻算法概述>|
<i class="fa fa-binoculars fa-fw"></i>
<span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><p>简单地说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。</p><h2 id=21k近邻算法概述>2.1k近邻算法概述</h2><p>k近邻算法</p><p>优点：精度高、对异常值不敏感、无数据输入假定。</p><p>缺点：计算复杂度高、空间复杂度高。</p><p>适用数据范围：数值型和标称型。</p><p>工作原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。</p><p>我们举一个电影分类的例子，使用k近邻算法分类爱情片和动作片。有人曾经统计过很多电影的打斗镜头和接吻镜头，图1显示了6部电影的打斗和接吻镜头数。假如有一部未看过的电影，如何确定它是爱情片还是动作片呢？</p><p><img src=https://raw.githubusercontent.com/MurphyHanxu/blogs-images/master/images/K-nearest-neighbor-algorithm1.1.png alt=K-nearest-neighbor-algorithm1.1></p><p><img src=https://raw.githubusercontent.com/MurphyHanxu/blogs-images/master/images/K-nearest-neighbor-algorithm1.2.png alt=K-nearest-neighbor-algorithm1.2></p><p>即使不知道未知电影属于哪种类型，我们也可以通过某种方法计算出来。首先计算未知电影与样本集中其他电影的距离。此处暂时不关心如何计算得到这些距离值，使用Python实现电影分类应用时，会提供具体的计算方法。</p><p><img src=https://raw.githubusercontent.com/MurphyHanxu/blogs-images/master/images/K-nearest-neighbor-algorithm1.3.png alt=K-nearest-neighbor-algorithm1.3></p><p>现在我们得到了样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到k个距离最近的电影。假定k=3，则三个最靠近的电影依次是He&rsquo;s Not Really into Dudes、Beautiful Woman和California Man。k近邻算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。</p><p>k近邻算法的一般流程</p><p>1.收集数据：可以使用任何方法。</p><p>2.准备数据：距离计算所需要的数值，最好是结构化的数据格式。</p><p>3.分析数据：可以使用任何方法。</p><p>4.训练算法：此步骤不适用于k近邻算法。</p><p>5.测试算法：计算错误率。</p><p>6.使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。</p><h3 id=211准备使用python导入数据>2.1.1准备：使用Python导入数据</h3><p>首先，创建名为kNN.py的Python模块，我们使用的所有代码都在这个文件中。在kNN.py文件中增加下面的代码：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>numpy</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>operator</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>def</span> <span style=color:#00a000>createDataSet</span>():
</span></span><span style=display:flex><span>    group <span style=color:#666>=</span> array([[<span style=color:#666>1.0</span>, <span style=color:#666>1.1</span>], [<span style=color:#666>1.0</span>, <span style=color:#666>1.0</span>], [<span style=color:#666>0</span>, <span style=color:#666>0</span>], [<span style=color:#666>0</span>, <span style=color:#666>0.1</span>]])
</span></span><span style=display:flex><span>    labels <span style=color:#666>=</span> [<span style=color:#b44>&#39;A&#39;</span>, <span style=color:#b44>&#39;A&#39;</span>, <span style=color:#b44>&#39;B&#39;</span>, <span style=color:#b44>&#39;B&#39;</span>]
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>return</span> group, labels
</span></span></code></pre></div><p>这里有4组数据，每组数据有两个我们已知的属性或者特征值。上面的group矩阵每行包含一个不同的数据，我们可以把它想象为某个日志文件中不同的测量点或者入口。由于人类大脑的限制，我们通常只能可视化处理三维以下的事务。因此为了简单地实现数据可视化，对于每个数据点我们通常只使用两个特征。</p><p>向量label包含了每个数据点的标签信息，label包含的元素个数等于group矩阵行数。这里我们将数据点(1, 1.1)定义为类A，数据点(0, 0.1)定义为类B。为了说明方便，例子中的数值是任意选择的，并没有给出轴标签。下图是带有类标签信息的四个数据点。</p><p><img src=https://raw.githubusercontent.com/MurphyHanxu/blogs-images/master/images/K-nearest-neighbor-algorithm1.4.png alt=K-nearest-neighbor-algorithm1.4></p><p>现在我们已经知道Python如何解析数据，如何加载数据，以及kNN算法的工作原理，接下来我们将使用这些方法完成分类任务。</p><h3 id=12从文本文件中解析数据>1.2从文本文件中解析数据</h3><p>本节使用程序清单1.2.1的函数运行kNN算法，为每组数据分类。这里首先给出k近邻算法的伪代码和实际的Python代码，然后详细地解释每行代码的含义。该函数的功能是使用k近邻算法将每组数据划分到某个类中，其伪代码如下：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>对未知类别属性的数据集中的每个点依次执行以下操作<span>：</span>
</span></span><span style=display:flex><span>(<span style=color:#666>1</span>)计算已知类别数据集中的点与当前点之间的距离
</span></span><span style=display:flex><span>(<span style=color:#666>2</span>)按照距离递增次序排序
</span></span><span style=display:flex><span>(<span style=color:#666>3</span>)选取与当前点距离最小的k个点
</span></span><span style=display:flex><span>(<span style=color:#666>4</span>)确定前k个点所在类别的出现频率
</span></span><span style=display:flex><span>(<span style=color:#666>5</span>)返回前k个点出现频率最高的类别作为当前点的预测分类
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#080;font-style:italic>#  程序清单1.2.1 k近邻算法</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>def</span> <span style=color:#00a000>classify0</span>(inX, dataSet, labels, k):
</span></span><span style=display:flex><span>    dataSetSize <span style=color:#666>=</span> dataSet<span style=color:#666>.</span>shape[<span style=color:#666>0</span>]
</span></span><span style=display:flex><span>    <span style=color:#080;font-style:italic>#  ①距离计算</span>
</span></span><span style=display:flex><span>    diffMat <span style=color:#666>=</span> tile(inX, (dataSetSize,<span style=color:#666>1</span>)) <span style=color:#666>-</span> dataSet
</span></span><span style=display:flex><span>    sqDiffMat <span style=color:#666>=</span> diffMat<span style=color:#666>**</span><span style=color:#666>2</span>
</span></span><span style=display:flex><span>    sqDistances <span style=color:#666>=</span> sqDiffMat<span style=color:#666>.</span>sum(axis<span style=color:#666>=</span><span style=color:#666>1</span>)
</span></span><span style=display:flex><span>    distances <span style=color:#666>=</span> sqDistances<span style=color:#666>**</span><span style=color:#666>0.5</span>
</span></span><span style=display:flex><span>    sortedDistIndicies <span style=color:#666>=</span> distances<span style=color:#666>.</span>argsort()
</span></span><span style=display:flex><span>    classCount<span style=color:#666>=</span>{}
</span></span><span style=display:flex><span>    <span style=color:#080;font-style:italic>#  ②选择距离最小的k个点</span>
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>for</span> i <span style=color:#a2f;font-weight:700>in</span> <span style=color:#a2f>range</span>(k):
</span></span><span style=display:flex><span>        voteIlabel <span style=color:#666>=</span> labels[sortedDistIndicies[i]]
</span></span><span style=display:flex><span>        classCount[voteIlabel] <span style=color:#666>=</span> classCount<span style=color:#666>.</span>get(voteIlabel,<span style=color:#666>0</span>) <span style=color:#666>+</span> <span style=color:#666>1</span>
</span></span><span style=display:flex><span>    <span style=color:#080;font-style:italic>#  ③排序</span>
</span></span><span style=display:flex><span>    sortedClassCount <span style=color:#666>=</span> <span style=color:#a2f>sorted</span>(classCount<span style=color:#666>.</span>iteritems(), key<span style=color:#666>=</span>operator<span style=color:#666>.</span>itemgetter(<span style=color:#666>1</span>), reverse<span style=color:#666>=</span><span style=color:#a2f;font-weight:700>True</span>)
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>return</span> sortedClassCount[<span style=color:#666>0</span>][<span style=color:#666>0</span>]
</span></span></code></pre></div><p>classify0()函数有4个输入参数：用于分类的输入向量是inX，输入的训练样本集为dataSet，标签向量为labels，最后的参数k表示用于选择最近邻居的数目，其中标签向量的元素数目和矩阵dataSet的行数相同。程序清单1.2.1使用欧氏距离公式，计算两个向量点xA和xB之间的距离①：
$$
d=\sqrt {(xA_0-xB_0)^2+(xA_1-xB_1)^2}
$$
计算完所有点之间的距离后，可以对数据按照从小到大的次序排序。然后，确定前k个距离最小元素所在的主要分类②，输入k总是正整数。最后，将classCount字典分解为元组列表，然后使用程序第二行导入运算法模块的itemgetter方法，按照第二个元素的次序对元组进行排序②。此处的排序为逆序，即按照从最大到最小次序排序，最后返回发生频率最高的元素标签。</p><p>为了预测数据所在分类，在Python提示符下输入下列命令：</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#666>&gt;&gt;&gt;</span>kNN<span style=color:#666>.</span>classify0([<span style=color:#666>0</span>, <span style=color:#666>0</span>], group, labels, <span style=color:#666>3</span>)
</span></span></code></pre></div><p>输出结果应该是B，大家也可以改变输入[0, 0]为其他值，测试程序的运行结果。</p><p>到现在为止，我们已经构造了第一个分类器，使用这个分类器可以完成很多分类任务。从这个实例出发，构造使用分类算法将会更加容易。</p><h3 id=13如何测试分类器>1.3如何测试分类器</h3><p>上文我们已经使用k近邻算法构造了第一个分类器，也可以检验分类器给出的答案是否符合我们的预期。但我们不免有疑问：“分类器何种情况下会出错？”或“答案是否总是正确的？”答案是否定的，分类器并不会得到百分百正确的结果，我们可以使用多种方法检测分类器的正确率。此外分类器的性能也会收到多种因素的影响，如分类器设置和数据集等。不同的算法在不同数据集上的表现可能完全不同，这也是本部分的6章都在讨论分类算法的原因所在。</p><p>为了测试分类器的效果，我们可以使用一致答案的数据，当然答案不能告诉分类器，检验分类器给出的结果是否符合预期结果。通过大量的测试数据，我们可以得到分类器的错误率——分类器给出错误结果的次数除以测试执行的总数。错误率是常用的评估方法，主要用于评估分类器在某个数据集上的执行效果。完美分类器的错误率为0，最差分类器的错误率为1，在这种情况下，分类器根本无法找到一个正确答案。</p><p>上一节介绍的例子已经可以正常运转了，但是并没有太大的实际用处，本章的后两节将在现实世界中使用k近邻算法。</p></div><footer class=post-footer><div class=post-tags><a href=/tags/machine-learning rel=tag title="Machine Learning">#Machine Learning#</a></div><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.jpg width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span>k近邻算法--1.k近邻算法概述</p><p><span>链接：</span>https://murphyhanxu.github.io/post/k-nearest-neighbor-algorithm1/</p><p><span>作者：</span>Murphy</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick='var qr=document.getElementById("QR");qr.style.display==="none"?qr.style.display="block":qr.style.display="none"'>
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"></div><div class="post-nav-prev post-nav-item"><a href=https://murphyhanxu.github.io/post/decisiontree3/ rel=prev title=决策树--3.测试和分类储存器>决策树--3.测试和分类储存器
<i class="fa fa-chevron-right"></i></a></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target=post-toc-wrap>文章目录</li><li class=sidebar-nav-overview data-target=site-overview>站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/avatar.png alt=Murphy><p class=site-author-name itemprop=name>Murphy</p><p class="site-description motion-element" itemprop=description>谁的脸谁的姓名</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>13</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>1</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>6</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/MurphyHanxu target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>
GitHub</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li><li class=links-of-blogroll-item><a href=https://math.mickeylili.com/ title=Mickeylili target=_blank>Mickeylili</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>
标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/machine-learning>Machine learning</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/github-pages>Github pages</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python>Python</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/hugo>Hugo</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/sql>SQL</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/mathematical-modeling>Mathematical modeling</a></li></ul></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class=post-toc><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#21k近邻算法概述>2.1k近邻算法概述</a><ul><li><a href=#211准备使用python导入数据>2.1.1准备：使用Python导入数据</a></li><li><a href=#12从文本文件中解析数据>1.2从文本文件中解析数据</a></li><li><a href=#13如何测试分类器>1.3如何测试分类器</a></li></ul></li></ul></nav></div></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=copyright-author>奔赴下一场山海</span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i>
<span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script>
<script type=text/javascript src=/js/search.js></script>
<script type=text/javascript src=/js/affix.js></script>
<script type=text/javascript src=/js/scrollspy.js></script>
<script type=text/javascript>function detectIE(){var e=window.navigator.userAgent,t=e.indexOf("MSIE "),n=e.indexOf("Trident/"),s=e.indexOf("Edge/");return t>0||n>0||s>0?-1:1}function getCntViewHeight(){var t=$("#content").height(),e=$(window).height(),n=t>e?t-e:$(document).height()-e;return n}function getScrollbarWidth(){var e=$("<div />").addClass("scrollbar-measure").prependTo("body"),t=e[0],n=t.offsetWidth-t.clientWidth;return e.remove(),n}function registerBackTop(){var t=50,e=$(".back-to-top");$(window).on("scroll",function(){e.toggleClass("back-to-top-on",window.pageYOffset>t);var s=$(window).scrollTop(),o=getCntViewHeight(),i=s/o,n=Math.round(i*100),a=n>100?100:n;$("#scrollpercent>span").html(a)}),e.on("click",function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var e=".post-toc",s=$(e),t=".active-current";s.on("activate.bs.scrollspy",function(){var t=$(e+" .active").last();n(),t.addClass("active-current")}).on("clear.bs.scrollspy",n),$("body").scrollspy({target:e});function n(){$(e+" "+t).removeClass(t.substring(1))}}function initAffix(){var e=$(".header-inner").height(),t=parseInt($(".main").css("padding-bottom"),10),n=e+10;$(".sidebar-inner").affix({offset:{top:n,bottom:t}}),$(document).on("affixed.bs.affix",function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){$(window).on("resize",function(){e&&clearTimeout(e),e=setTimeout(function(){var e=document.body.clientHeight-100;updateTOCHeight(e)},0)}),updateTOCHeight(document.body.clientHeight-100);var e,t=getScrollbarWidth();$(".post-toc").css("width","calc(100% + "+t+"px)")}function updateTOCHeight(e){e=e||"auto",$(".post-toc").css("max-height",e)}$(function(){var e,t,n,s,o=$(".header-inner").height()+10;$("#sidebar").css({'margin-top':o}).show(),t=parseInt($("#sidebar").css("margin-top")),n=parseInt($(".sidebar-inner").css("height")),e=t+n,s=$(".content-wrap").height(),s<e&&$(".content-wrap").css("min-height",e),$(".site-nav-toggle").on("click",function(){var e=$(".site-nav"),o=$(".toggle"),t="site-nav-on",i="toggle-close",n=e.hasClass(t),a=n?"slideUp":"slideDown",s=n?"removeClass":"addClass";e.stop()[a]("normal",function(){e[s](t),o[s](i)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$(".sidebar-nav-toc").click(function(){$(this).addClass("sidebar-nav-active"),$(this).next().removeClass("sidebar-nav-active"),$("."+$(this).next().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)}),$(".sidebar-nav-overview").click(function(){$(this).addClass("sidebar-nav-active"),$(this).prev().removeClass("sidebar-nav-active"),$("."+$(this).prev().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script>
<script type=text/javascript>$(function(){$(".post-body").viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+"//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js",function(){new Waline({el:"#wcomments",visitor:!0,avatar:"wavatar",avatarCDN:"https://sdn.geekzu.org/avatar/",avatarForce:!1,wordLimit:"200",placeholder:" 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ",requiredFields:["nick","mail"],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$("#wcomments").html("抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。")})</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_SVG"></script>
<script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script>
<script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script></body></html>