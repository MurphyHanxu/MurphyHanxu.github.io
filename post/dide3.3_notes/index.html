<!doctype html><html lang=zh-cn dir=content/zh-cn><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=content-security-policy content="upgrade-insecure-requests"><title>- 奔赴下一场山海</title><meta name=keywords content="博客,程序员,架构师,思考,读书,笔记,技术,分享,大数据,产品"><meta name=author content="Murphy"><meta property="og:title" content><meta property="og:site_name" content="奔赴下一场山海"><meta property="og:image" content="/img/author.jpg"><meta name=title content=" - 奔赴下一场山海"><meta name=description content="欢迎来到Murphy的博客网站。"><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/apple-touch-icon.png><link rel=apple-touch-icon-precomposed href=/img/apple-touch-icon.png><link href=//cdn.bootcdn.net/ajax/libs/font-awesome/4.6.2/css/font-awesome.min.css rel=stylesheet type=text/css><link href=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet type=text/css><link href=/css/syntax.css rel=stylesheet type=text/css></head><body itemscope itemtype=http://schema.org/WebPage lang=zh-hans><div class="container one-collumn sidebar-position-left page-home"><div class=headband></div><header id=header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle role=button style=opacity:1;top:0><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><div class=multi-lang-switch><i class="fa fa-fw fa-language" style=margin-right:5px></i>
<a class=lang-link id=zh-cn href=#>中文</a></div><div class=custom-logo-site-title><a href=/ class=brand rel=start><span class=logo-line-before><i></i></span>
<span class=site-title>奔赴下一场山海</span>
<span class=logo-line-after><i></i></span></a></div><p class=site-subtitle>但远山长，云山乱，晓山青。</p></div><div class=site-nav-right><div class="toggle popup-trigger" style=opacity:1;top:0><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul id=menu class=menu><li class=menu-item><a href=/ rel=section><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class=menu-item><a href=/post rel=section><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class=menu-item><a href=/about.html rel=section><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于我</a></li><li class=menu-item><a href=/404.html rel=section><i class="menu-item-icon fa fa-fw fa-heartbeat"></i><br>公益404</a></li><li class="menu-item menu-item-search"><a href=javascript:; class=popup-trigger><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class=site-search><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class=search-icon><i class="fa fa-search"></i></span>
<span class=popup-btn-close><i class="fa fa-times-circle"></i></span><div class=local-search-input-wrapper><input autocomplete=off placeholder=搜索关键字... spellcheck=false type=text id=local-search-input autocapitalize=none autocorrect=off></div></div><div id=local-search-result></div></div></div></nav></div></header><main id=main class=main><div class=main-inner><div class=content-wrap><div id=content class=content><section id=posts class=posts-expand><article class="post post-type-normal" itemscope itemtype=http://schema.org/Article><header class=post-header><h1 class=post-title itemprop="name headline"><a class=post-title-link href=https://murphyhanxu.github.io/post/dide3.3_notes/ itemprop=url></a></h1><div class=post-meta><span class=post-time><i class="fa fa-calendar-o fa-fw"></i>
<span class=post-meta-item-text>时间：</span>
<time itemprop=dateCreated datetime=2016-03-22T13:04:35+08:00 content="0001-01-01">0001-01-01</time></span>
<span>|
<i class="fa fa-file-word-o fa-fw"></i>
<span class=post-meta-item-text>字数：</span>
<span class=leancloud-world-count>1998 字</span></span>
<span>|
<i class="fa fa-eye fa-fw"></i>
<span class=post-meta-item-text>阅读：</span>
<span class=leancloud-view-count>4分钟</span></span>
<span id=/post/dide3.3_notes/ class=leancloud_visitors data-flag-title>|
<i class="fa fa-binoculars fa-fw"></i>
<span class=post-meta-item-text>阅读次数：</span>
<span class=leancloud-visitors-count></span></span></div></header><div class=post-body itemprop=articleBody><p>author = &ldquo;Murphy&rdquo;
title = &ldquo;DIDL3.2 Notes&rdquo;
date = &ldquo;2022-09-07&rdquo;</p><p>description = ""
tags = [
&ldquo;DIDL&rdquo;,
]</p><p>categories = [
&ldquo;CS&rdquo;,
]</p><p>math= true</p><p>toc= true</p><p>+++</p><p>3.3</p><p>线性回归的简洁实现</p><h2 id=1生成数据集>1.生成数据集</h2><p>与3.2节相同，我们首先生成数据集。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>numpy</span> <span style=color:#a2f;font-weight:700>as</span> <span style=color:#00f;font-weight:700>np</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>import</span> <span style=color:#00f;font-weight:700>torch</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>torch.utils</span> <span style=color:#a2f;font-weight:700>import</span> data
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>d2l</span> <span style=color:#a2f;font-weight:700>import</span> torch <span style=color:#a2f;font-weight:700>as</span> d2l
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>true_w <span style=color:#666>=</span> torch<span style=color:#666>.</span>tensor([<span style=color:#666>2</span>, <span style=color:#666>-</span><span style=color:#666>3.4</span>])
</span></span><span style=display:flex><span>true_b <span style=color:#666>=</span> <span style=color:#666>4.2</span>
</span></span><span style=display:flex><span>features, labels <span style=color:#666>=</span> d2l<span style=color:#666>.</span>synthetic_data(true_w, true_b, <span style=color:#666>1000</span>)
</span></span></code></pre></div><h2 id=2读取数据集>2.读取数据集</h2><p>我们可以调用框架中现有的API来读取数据。我们将features和labels作为API的参数传递，并通过数据迭代器制定batch_size。此外，布尔值is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a2f;font-weight:700>def</span> <span style=color:#00a000>load_array</span>(data_arrays, batch_size, is_train<span style=color:#666>=</span><span style=color:#a2f;font-weight:700>True</span>):  <span style=color:#080;font-style:italic>#@save</span>
</span></span><span style=display:flex><span>    <span style=color:#b44>&#34;&#34;&#34;构造一个PyTorch数据迭代器&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span>    dataset <span style=color:#666>=</span> data<span style=color:#666>.</span>TensorDataset(<span style=color:#666>*</span>data_arrays)
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>return</span> data<span style=color:#666>.</span>DataLoader(dataset, batch_size, shuffle<span style=color:#666>=</span>is_train)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>batch_size <span style=color:#666>=</span> <span style=color:#666>10</span>
</span></span><span style=display:flex><span>data_iter <span style=color:#666>=</span> load_array((features, labels), batch_size)
</span></span></code></pre></div><p>使用data_iter的方式与我们在3.2节中使用data_iter函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。与3.2节不同，这里我们使用iter构造Python迭代器，并使用next从迭代器中获取第一项。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a2f>next</span>(<span style=color:#a2f>iter</span>(data_iter))
</span></span><span style=display:flex><span><span style=color:#a2f>print</span>(<span style=color:#a2f>next</span>(<span style=color:#a2f>iter</span>(data_iter)))
</span></span></code></pre></div><h2 id=3定义模型>3.定义模型</h2><p>当我们在3.2节中实现线性回归时，我们明确定义了模型参数变量，并编写了计算的代码，这样通过基本的线性代数运算得到输出。但是，如果模型变得更加复杂，且当你几乎每天都需要实现模型时，你会想简化这个过程。这种情况类似于为自己的博客从零开始编写网页。做一两次是有益的，但如果每个新博客你就花一个月的时间重新开始编写网页，那并不高效。</p><p>对于标准深度学习模型，我们可以使用框架的预定义好的层。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。我们首先定义一个模型变量net，它是一个Sequential类的实例。Sequential类将多个层串联在一起。当给定输入数据时，Sequential实例将数据传入到第一层，然后将第一层的输出作为第二层的输入，以此类推。在下面的例子中，我们的模型只包含一个层，因此实际上不需要Sequential。但是由于以后几乎所有的模型都是多层的，在这里使用Sequential会让你熟悉“标准的流水线”。</p><p><img src=https://MurphyHanxu.github.io/blogs-images/images/DIDL3.3.1.png alt=3.3.1></p><p>回顾单层网络架构，这一单层被称为全连接层(fully-connected layer)，因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。</p><p>在PyTorch中，全连接层在Linear类中定义。值得注意的是，我们将两个参数传递到nn.Linear中。第一个指定输入特征形状，即2。第二个指定输出特征形状，输出特征形状为单个标量，因此为1。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#080;font-style:italic># nn是神经网络的缩写</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>from</span> <span style=color:#00f;font-weight:700>torch</span> <span style=color:#a2f;font-weight:700>import</span> nn
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>net <span style=color:#666>=</span> nn<span style=color:#666>.</span>Sequential(nn<span style=color:#666>.</span>Linear(<span style=color:#666>2</span>, <span style=color:#666>1</span>))
</span></span></code></pre></div><h2 id=4初始化模型参数>4.初始化模型参数</h2><p>在使用net之前，我们需要初始化模型参数。如在线性回归模型中的权重和偏置。深度学习框架通常有预定义的方法来初始化参数。在这里，我们指定每个权重参数应该从均值为0，标准差为0.01的正太分布中随机采样，偏置参数将初始化为零。</p><p>正如我们在构造nn.Linear时指定输入和输出尺寸一样，现在我们能直接访问参数以设定它们的初始值。我们通过net[0]选择网络中的第一个图层，然后使用weight.data和bias.data方法访问参数。我们还可以使用替换方法normal_和fill_来重写参数值。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>net[<span style=color:#666>0</span>]<span style=color:#666>.</span>weight<span style=color:#666>.</span>data<span style=color:#666>.</span>normal_(<span style=color:#666>0</span>, <span style=color:#666>0.01</span>)
</span></span><span style=display:flex><span>net[<span style=color:#666>0</span>]<span style=color:#666>.</span>bias<span style=color:#666>.</span>data<span style=color:#666>.</span>fill_(<span style=color:#666>0</span>)
</span></span></code></pre></div><h2 id=5定义损失函数>5.定义损失函数</h2><p>计算均方误差使用的是MSELoss类，也称为平方$L_2$范数。默认情况下，它返回所有样本损失的平均值。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>loss <span style=color:#666>=</span> nn<span style=color:#666>.</span>MSELoss()
</span></span></code></pre></div><h2 id=6定义优化算法>6.定义优化算法</h2><p>小批量随机梯度下降算法是一种优化神经网络的标准工具，PyTorch在optim模块中实现了该算法的许多变种。当我们实例化一个SGD实例时，我们要指定优化的参数（可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典。小批量随机梯度下降只需要设置lr值，这里设置为0.03。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>trainer <span style=color:#666>=</span> torch<span style=color:#666>.</span>optim<span style=color:#666>.</span>SGD(net<span style=color:#666>.</span>parameters(), lr<span style=color:#666>=</span><span style=color:#666>0.03</span>)
</span></span></code></pre></div><h2 id=7训练>7.训练</h2><p>通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。当我们需要更复杂的模型时，高级API的优势将大大增加。当我们有了所有的基本组件，训练过程代码与我们从零开始实现时所做的非常相似。</p><p>回顾一下：在每个迭代周期里，我们将完整遍历一次数据集(train_data)，不停地从中获取一个小批量的输入和相应的标签。对于每一个小批量，我们会进行以下步骤：</p><ul><li>通过调用net(X)生成预测并计算损失l(前向传播)。</li><li>通过进行反向传播来计算梯度</li><li>通过调用优化器来更新模型参数。</li></ul><p>为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>num_epochs <span style=color:#666>=</span> <span style=color:#666>3</span>
</span></span><span style=display:flex><span><span style=color:#a2f;font-weight:700>for</span> epoch <span style=color:#a2f;font-weight:700>in</span> <span style=color:#a2f>range</span>(num_epochs):
</span></span><span style=display:flex><span>    <span style=color:#a2f;font-weight:700>for</span> X, y <span style=color:#a2f;font-weight:700>in</span> data_iter:
</span></span><span style=display:flex><span>        l <span style=color:#666>=</span> loss(net(X) ,y)
</span></span><span style=display:flex><span>        trainer<span style=color:#666>.</span>zero_grad()
</span></span><span style=display:flex><span>        l<span style=color:#666>.</span>backward()
</span></span><span style=display:flex><span>        trainer<span style=color:#666>.</span>step()
</span></span><span style=display:flex><span>    l <span style=color:#666>=</span> loss(net(features), labels)
</span></span><span style=display:flex><span>    <span style=color:#a2f>print</span>(<span style=color:#b44>f</span><span style=color:#b44>&#39;epoch </span><span style=color:#b68;font-weight:700>{</span>epoch <span style=color:#666>+</span> <span style=color:#666>1</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>, loss </span><span style=color:#b68;font-weight:700>{</span>l<span style=color:#b68;font-weight:700>:</span><span style=color:#b44>f</span><span style=color:#b68;font-weight:700>}</span><span style=color:#b44>&#39;</span>)
</span></span></code></pre></div><p>下面我们比较生成数据集的真实参数和通过有限数据训练获得的模型参数。要访问参数，我们首先从net访问所需的层，然后读取该层的权重和偏置。正如在3.2节中一样，我们估计得到的参数与生成数据的真实参数非常接近。</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>w <span style=color:#666>=</span> net[<span style=color:#666>0</span>]<span style=color:#666>.</span>weight<span style=color:#666>.</span>data
</span></span><span style=display:flex><span><span style=color:#a2f>print</span>(<span style=color:#b44>&#39;w的估计误差：&#39;</span>, true_w <span style=color:#666>-</span> w<span style=color:#666>.</span>reshape(true_w<span style=color:#666>.</span>shape))
</span></span><span style=display:flex><span>b <span style=color:#666>=</span> net[<span style=color:#666>0</span>]<span style=color:#666>.</span>bias<span style=color:#666>.</span>data
</span></span><span style=display:flex><span><span style=color:#a2f>print</span>(<span style=color:#b44>&#39;b的估计误差：&#39;</span>, true_b <span style=color:#666>-</span> b)
</span></span></code></pre></div></div><footer class=post-footer><div class=addthis_inline_share_toolbox></div><div class=post-nav><div class=article-copyright><div class=article-copyright-img><img src=/img/qq_qrcode.jpg width=129px height=129px><div style=text-align:center>QQ扫一扫交流</div></div><div class=article-copyright-info><p><span>声明：</span></p><p><span>链接：</span>https://murphyhanxu.github.io/post/dide3.3_notes/</p><p><span>作者：</span>Murphy</p><p><span>声明： </span>本博客文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/ target=_blank style=text-decoration:underline>CC BY-NC-SA 3.0</a>许可协议，转载请注明出处！</p></div></div><div class=clear></div></div><div class=reward-qr-info><div>创作实属不易，如有帮助，那就打赏博主些许茶钱吧 ^_^</div><button id=rewardButton disable=enable onclick='var qr=document.getElementById("QR");qr.style.display==="none"?qr.style.display="block":qr.style.display="none"'>
<span>赏</span></button><div id=QR style=display:none><div id=wechat style=display:inline-block><img id=wechat_qr src=/img/wechat-pay.png alt="WeChat Pay"><p>微信打赏</p></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=https://murphyhanxu.github.io/post/setup-helloworld/ rel=next title="创建第一个GitHub Page"><i class="fa fa-chevron-left"></i> 创建第一个GitHub Page</a></div><div class="post-nav-prev post-nav-item"></div></div><div id=wcomments></div></footer></article></section></div></div><div class=sidebar-toggle><div class=sidebar-toggle-line-wrap><span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
<span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id=sidebar class=sidebar><div class=sidebar-inner><section class="site-overview sidebar-panel sidebar-panel-active"><div class="site-author motion-element" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image src=/img/avatar.png alt=Murphy><p class=site-author-name itemprop=name>Murphy</p><p class="site-description motion-element" itemprop=description>谁的脸谁的姓名</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href=/post/><span class=site-state-item-count>17</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>1</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>8</span>
<span class=site-state-item-name>标签</span></a></div></nav><div class="links-of-author motion-element"><span class=links-of-author-item><a href=https://github.com/MurphyHanxu target=_blank title=GitHub><i class="fa fa-fw fa-github"></i>
GitHub</a></span></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class=links-of-blogroll-title><i class="fa fa-fw fa-globe"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://www.liaoxuefeng.com/ title=廖雪峰 target=_blank>廖雪峰</a></li><li class=links-of-blogroll-item><a href=https://math.mickeylili.com/ title=Mickeylili target=_blank>Mickeylili</a></li></ul></div><div class="tagcloud-of-blogroll motion-element tagcloud-of-blogroll-inline"><div class=tagcloud-of-blogroll-title><i class="fa fa-fw fa-tags"></i>
标签云</div><ul class=tagcloud-of-blogroll-list><li class=tagcloud-of-blogroll-item><a href=/tags/machine-learning>Machine learning</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/github-pages>Github pages</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/python>Python</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/hugo>Hugo</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/sql>SQL</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/didl>Didl</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/homework>Homework</a></li><li class=tagcloud-of-blogroll-item><a href=/tags/mathematical-modeling>Mathematical modeling</a></li></ul></div></section></div></aside></div></main><footer id=footer class=footer><div class=footer-inner><div class=copyright><span class=copyright-year>&copy; 2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=copyright-author>奔赴下一场山海</span></div></div></footer><div class=back-to-top><i class="fa fa-arrow-up"></i>
<span id=scrollpercent><span>0</span>%</span></div></div><script type=text/javascript src=//cdn.bootcdn.net/ajax/libs/jquery/2.1.4/jquery.min.js></script>
<script type=text/javascript src=/js/search.js></script>
<script type=text/javascript src=/js/affix.js></script>
<script type=text/javascript src=/js/scrollspy.js></script>
<script type=text/javascript>function detectIE(){var e=window.navigator.userAgent,t=e.indexOf("MSIE "),n=e.indexOf("Trident/"),s=e.indexOf("Edge/");return t>0||n>0||s>0?-1:1}function getCntViewHeight(){var t=$("#content").height(),e=$(window).height(),n=t>e?t-e:$(document).height()-e;return n}function getScrollbarWidth(){var e=$("<div />").addClass("scrollbar-measure").prependTo("body"),t=e[0],n=t.offsetWidth-t.clientWidth;return e.remove(),n}function registerBackTop(){var t=50,e=$(".back-to-top");$(window).on("scroll",function(){e.toggleClass("back-to-top-on",window.pageYOffset>t);var s=$(window).scrollTop(),o=getCntViewHeight(),i=s/o,n=Math.round(i*100),a=n>100?100:n;$("#scrollpercent>span").html(a)}),e.on("click",function(){$("html,body").animate({scrollTop:0,screenLeft:0},800)})}function initScrollSpy(){var e=".post-toc",s=$(e),t=".active-current";s.on("activate.bs.scrollspy",function(){var t=$(e+" .active").last();n(),t.addClass("active-current")}).on("clear.bs.scrollspy",n),$("body").scrollspy({target:e});function n(){$(e+" "+t).removeClass(t.substring(1))}}function initAffix(){var e=$(".header-inner").height(),t=parseInt($(".main").css("padding-bottom"),10),n=e+10;$(".sidebar-inner").affix({offset:{top:n,bottom:t}}),$(document).on("affixed.bs.affix",function(){updateTOCHeight(document.body.clientHeight-100)})}function initTOCDimension(){$(window).on("resize",function(){e&&clearTimeout(e),e=setTimeout(function(){var e=document.body.clientHeight-100;updateTOCHeight(e)},0)}),updateTOCHeight(document.body.clientHeight-100);var e,t=getScrollbarWidth();$(".post-toc").css("width","calc(100% + "+t+"px)")}function updateTOCHeight(e){e=e||"auto",$(".post-toc").css("max-height",e)}$(function(){var e,t,n,s,o=$(".header-inner").height()+10;$("#sidebar").css({'margin-top':o}).show(),t=parseInt($("#sidebar").css("margin-top")),n=parseInt($(".sidebar-inner").css("height")),e=t+n,s=$(".content-wrap").height(),s<e&&$(".content-wrap").css("min-height",e),$(".site-nav-toggle").on("click",function(){var e=$(".site-nav"),o=$(".toggle"),t="site-nav-on",i="toggle-close",n=e.hasClass(t),a=n?"slideUp":"slideDown",s=n?"removeClass":"addClass";e.stop()[a]("normal",function(){e[s](t),o[s](i)})}),registerBackTop(),initScrollSpy(),initAffix(),initTOCDimension(),$(".sidebar-nav-toc").click(function(){$(this).addClass("sidebar-nav-active"),$(this).next().removeClass("sidebar-nav-active"),$("."+$(this).next().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)}),$(".sidebar-nav-overview").click(function(){$(this).addClass("sidebar-nav-active"),$(this).prev().removeClass("sidebar-nav-active"),$("."+$(this).prev().attr("data-target")).toggle(500),$("."+$(this).attr("data-target")).toggle(500)})})</script><script src=//cdn.bootcdn.net/ajax/libs/imageviewer/0.1.0/viewer.min.js></script>
<script type=text/javascript>$(function(){$(".post-body").viewer()})</script><script type=text/javascript>$(function(){detectIE()>0?$.getScript(document.location.protocol+"//cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js",function(){new Waline({el:"#wcomments",visitor:!0,avatar:"wavatar",avatarCDN:"https://sdn.geekzu.org/avatar/",avatarForce:!1,wordLimit:"200",placeholder:" 欢迎留下您的宝贵建议，请填写您的昵称和邮箱便于后续交流. ^_^ ",requiredFields:["nick","mail"],serverURL:"Your WalineSerURL",lang:"zh-cn"})}):$("#wcomments").html("抱歉，Waline插件不支持IE或Edge，建议使用Chrome浏览器。")})</script><script type=text/javascript src="//s7.addthis.com/js/300/addthis_widget.js#pubid=Your%20AddthisId"></script>
<script>(function(){var t,e=document.createElement("script"),n=window.location.protocol.split(":")[0];n==="https"?e.src="https://zz.bdstatic.com/linksubmit/push.js":e.src="http://push.zhanzhang.baidu.com/push.js",t=document.getElementsByTagName("script")[0],t.parentNode.insertBefore(e,t)})()</script></body></html>