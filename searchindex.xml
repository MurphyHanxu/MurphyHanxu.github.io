<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>DIDL3.2 Notes</title><url>https://murphyhanxu.github.io/post/dide3.2_notes/</url><categories><category>CS</category></categories><tags><tag>DIDL</tag></tags><content type="html"> 3.2
线性回归的从零开始实现
1.生成数据集 为了简单起见，我们将根据带有噪声的线性模型构造一个人造数据集。我们的任务是使用这个有限样本的数据集来恢复这个模型的参数。我们将使用低维数据，这样可以很容易地将其可视化。在下面的代码中，我们生成一个包含1000个样本的数据集，每个样本包含从标准正态分布中采样的2个特征。我们合成的数据集是一个矩阵$\mathbf{X}\in\mathbb{R}^{1000\times2}$。
我们使用线性模型参数$\mathbf{w}=[2,-3.4]^{T}$、$b=4.2$和噪声项$\epsilon$生成数据集及其标签： $$ \mathbf{y}=\mathbf{Xw}+b+\epsilon \tag{3.2.1} $$
你可以将$\epsilon$视为模型预测和标签时的潜在观测误差。在这里我们认为标准假设成立，即$\epsilon$服从均值为$0$的正太分布。为了简化问题，我们将标准差设为$0.01$。下面的代码生成合成数据集。
def synthetic_data(w, b, num_examples): #@save """生成y=Xw+b+噪声""" X = torch.normal(0, 1, (num_examples, len(w))) # X的形状是num_examples x len(w) y = torch.matmul(X, w) + b # y的形状是1 x num_examples y += torch.normal(0, 0.01, y.shape) # 将y加上epsilon return X, y.reshape((-1, 1)) # 返回噪声集x,y # torch.normal(mean, std, (number of samples, dimension)) # torch.matmul(A, B)指矩阵乘法 # .reshape((-1,1))转换成一列 true_w = torch.tensor([2, -3.4]) # w的形状为1 x 2 true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) 则features中的每一行都包含一个二维数据样本，labels中的每一行都包含一维标签值（一个标量）。
通过生成第二个特征features[:,1]和labels的散点图，可以直观观察到两者之间的线性关系。
d2l.set_figsize() d2l.plt.scatter(features[:, (1)].detach().numpy(), labels.detach().numpy(), 1) # 1表示的是样本点在图像上的大小 # .detach() 返回一个新的tensor，从当前计算图中分离下来的，但是仍指向原变量的存放位置,不同之处只是requires_grad为false，得到的这个tensor永远不需要计算其梯度，不具有grad。 d2l.plt.show() 2.读取数据集 回想一下，训练模型时要对数据集进行遍历，每次抽取一小批量样本，并使用它们来更新我们的模型。由于这个过程是训练机器学习算法的基础，所以有必要定义一个函数，该函数能打乱数据集中的样本并以小批量方式获取数据。
在下面的代码中，我们定义一个data_iter函数，该函数接收批量大小、特征矩阵和标签向量作为插入，生成大小为batch_size的小批量。每个小批量包含一组特征和标签。
def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) # 这些样本是随机读取的，没有特定的顺序 random.shuffle(indices) # 将列表所有的元素随机排列 for i in range(0, num_examples, batch_size): batch_indices = torch.tensor( indices[i: min(i + batch_size, num_examples)]) yield features[batch_indices], labels[batch_indices] # 迭代器生成随机顺序的features和labels 通常，我们利用GPU并行运算的优势，处理合理大小的“小批量”。每个样本都可以并行地进行模型计算，且每个样本损失函数的梯度也可以被并行计算。GPU可以在处理几百个样本时，所花费的时间不比处理一个样本时间多太多。
我们直观感受一下小批量运算：读取第一个小批量数据样本并打印。每个批量的特征维度显示批量大小和输入特征数。同样的，批量的标签形状与batch_size相等。
batch_size = 10 for X, y in data_iter(batch_size, features, labels): print(X, '\n', y) break 当我们运行迭代时，我们会连续地获得不同的小批量，直至遍历完整个数据集。上面实现的迭代对于教学来说很好，但它的执行效率很低，可能会在实际问题上陷入麻烦。例如，它要求我们将所有数据加载到内存中，并执行大量的随机内存访问。在深度学习框架中实现的内置迭代器效率要高得多，它可以处理存储在文件中的数据和数据流提供的数据。
3.初始化模型参数 在我们开始用小批量随机梯度下降优化我们的模型参数之前，我们需要先有一些参数。在下面的代码中，我们通过从均值为0、标准差为0.01的正态分布中采样随机数来初始化权重，并将偏置初始化为0。
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True) b = torch.zeros(1, requires_grad=True) 在初始化参数之后，我们的任务是更新这些参数，直到这些参数足够拟合我们的数据。每次更新都需要计算损失函数关于模型参数的梯度。有了这个梯度，我们就可以向减小损失的方向更新每个参数。因为手动计算梯度很枯燥而且容易出错，所以没有人会手动计算梯度。我们使用2.5节中引入的自动微分来计算梯度。
4.定义模型 接下来，我们必须定义模型，将模型的输入和参数同模型的输出关联起来。回想一下，要计算线性模型的输出，我们只需计算输入特征$\mathbf{X}$和模型权重$\mathbf{w}$的矩阵-向量乘法后向上偏置$b$。注意，上面的$\mathbf{Xw}$是一个向量，而$b$是一个标量。回想广播机制：当我们用一个向量加一个标量时，标量会被加到向量的每个分量上。
def linreg(X, w, b): #@save """线性回归模型""" return torch.matmul(X, w) + b 5.定义损失函数 因为需要计算损失函数的梯度，所以我们应该先定义损失函数。这里我们使用平方损失函数。在实现中，我们需要将真实值y的形状转换为和预测值y_hat的形状相同。
def squared_loss(y_hat, y): #@save """均方损失""" return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 6.定义优化算法 尽管线性回归有解析解，但本书中的其他模型却没有。这里我们介绍小批量随机梯度下降。
在每一步中，使用从数据集中随机抽取的一个小批量，然后根据参数计算损失的梯度。接下来，朝着减少损失的方向更新我们的参数。下面的函数实现小批量随机梯度下降更新。该函数接受模型参数集合、学习速率和批量大小作为输入。每一步更新的大小由学习速率lr决定。因为我们计算的损失是一个批量样本的总和，所以我们用批量大小(batch_size)来规范化步长，这样步长大小就不会取决于我们对批量大小的选择。
def sgd(params, lr, batch_size): #@save """小批量随机梯度下降""" with torch.no_grad(): # 更新的时候不参与梯度计算 for param in params: param -= lr * param.grad / batch_size param.grad.zero_() # 将梯度重新归零，以便下一次计算梯度 7.训练 现在我们已经准备好了模型训练所有需要的要素，可以实现主要的训练过程部分了。理解这段代码至关重要，因为从事深度学习后，你会一遍又一遍地看到几乎相同的训练过程。在每次迭代中，我们读取一小批量训练样本，并通过我们的模型来获得一组预测。计算完损失后，我们开始反向传播，存储每个参数的梯度。最后，我们调用优化算法sgd来更新模型参数。
概括一下，我们将执行一下循环：
初始化参数 重复一下训练，直到完成 计算梯度$\mathbf{g}\leftarrow\partial_{(\mathbf{w},b)}\frac{1}{\vert\mathbf{B}\vert}\sum_{i\in\mathbf{B}}l(X^{(i)},y{(i)},\mathbf{w},b)$ 更新参数$(\mathbf{w},b)\leftarrow(\mathbf{w},b)-\eta\mathbf{g}$ 在每个迭代周期(epoch)中，我们使用data_iter函数遍历整个数据集，并将训练数据集中所有样本都使用一次（假设样本数能够被批量大小整除）。这里的迭代周期个数num_epochs和学习率lr都是超参数，分别设为$3$和$0.03$。设置超参数很棘手，需要通过反复试验进行调整。我们现在忽略这些细节，以后会在11节中详细介绍。
lr = 0.03 # 学习率 num_epochs = 3 # 迭代次数（周期） net = linreg loss = squared_loss for epoch in range(num_epochs): for X, y in data_iter(batch_size, features, labels): l = loss(net(X, w, b), y) # X和y的小批量损失 # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起， # 并以此计算关于[w,b]的梯度 l.sum().backward() sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数 with torch.no_grad(): train_l = loss(net(features, w, b), labels) print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}') 因为我们使用的是自己合成的数据集，所以我们知道真正的参数是什么。因此，我们可以通过比较真实参数和通过训练学到的参数来评估训练的成功程度。事实上，真实参数和通过训练学到的参数确实非常接近。
print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}') print(f'b的估计误差: {true_b - b}') 注意，我们不应该想当然地认为我们能够完美地求解参数。在机器学习中，我么通常不太关心恢复真正的参数，而更关心如何高度准确预测参数。幸运的是，即使是在复杂的优化问题上，随机梯度下降通常也能找到非常好的解。其中一个原因是，在深度学习网络中存在许多参数组合能够实现高度精确的预测。</content></entry><entry><title>k近邻算法--2.示例：使用k近邻算法改进约会网站的配对效果</title><url>https://murphyhanxu.github.io/post/k-nearest-neighbor-algorithm2/</url><categories><category>CS</category></categories><tags><tag>Machine Learning</tag></tags><content type="html"> 2.2 示例：使用k近邻算法改进约会网站的配对效果 我的朋友海伦一直使用在线约会网站寻找适合自己的约会对象。尽管约会网站会推荐不同的人选，但她没有从中找到喜欢的人。经过一番总结，她发现曾交往过三种类型的人：(1)不喜欢的人、(2)魅力一般的人、(3)极具魅力的人。
尽管发现了上述规律，但海伦依然无法将约会网站推荐的匹配对象归入恰当的分类。她觉得可以在周一到周五约会那些魅力一般的人，而周末则更喜欢与那些极具魅力的人为伴。海伦希望我们的分类软件可以更好地帮助她将匹配对象划分到确切的分类中。此外海伦还收集了一些约会网站未曾记录的数据信息，她认为这些数据更有助于匹配对象的归类。
示例：在约会网站上使用k近邻算法
收集数据：提供文本文件
准备数据：使用Python解析文本文件
分析数据：使用Matplotlib画二维扩散图
训练算法：此步骤不适用于k近邻算法
测试算法：使用海伦提供的部分数据作为测试样本。
测试样本和非测试样本的区别在于：测试样本是已经完成分类的数据，如果预测分类与实际类别不同，则标记为一个错误。
使用算法：产生简单的命令行程序，然后海伦可以输入一些特征数据以判断对方是否为自己喜欢的类型。
2.1 准备数据：从文本文件中解析数据 海伦收集约会数据已经有了一段时间，她把这些数据存放在文本文件datingTextSet.txt中，每个样本数据占据一行，总共有1k行。海伦的样本主要包含一下三种特征：
每年获得的飞行常客里程数 玩视频游戏所耗时间百分比 每周消费的冰淇淋公升数 在将上述特征数据输入到分类器之前，必须将待处理数据的格式改变为分类器可以接收的格式。将结果类型(1)不喜欢的人赋值为1，(2)魅力一般的人赋值为2，(3)极具魅力的人赋值为3。存放在文本文件datingTextSet2.txt中。
在kNN.py中创建名为file2matrix的函数，以此来处理输入格式问题。该函数的输入为文件名字符串，输出为训练样本矩阵和类标签向量。将下面的代码增加到kNN.py中：
# 程序清单2.1.1 将文本记录到转换NumPy的解析程序 def file2matrix(filename): fr = open(filename) # ①得到文件行数 numberOfLines = len(fr.readlines()) # ②创建返回的NumPy矩阵 returnMat = zeros((numberOfLines,3)) # ③解析文件数据到列表 classLabelVector = [] fr = open(filename) index = 0 for line in fr.readlines(): line = line.strip() listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat, classLabelVector 从上面的代码可以看到，Python处理文本文件非常容易。首先我们需要知道文本文件包含多少行。打开文件，得到文件的行数①。然后创建以零填充的矩阵NumPy②。为了简化处理，我们将该矩阵的另一维度设置为固定值3，你可以按照自己的实际需求增加相应的代码以适应变化的输入值。循环处理文件中的每行数据③，首先使用函数line.strip()截取掉所有的回车字符，然后使用tab字符\t将上一步得到的整行数据分割成一个元素列表。接着，我们选取前3个元素，将它们存储到特征矩阵中。Python语言可以使用索引值-1表示列表中的最后一个元素。需要注意的是，我们必须明确地通知解释器，告诉它列表中存储的元素值为整型，否则Python语言会将这些元素当做字符串处理。以前我们必须自己处理这些变量值类型问题，现在这些细节问题完全可以交给NumPy函数库来处理。
>>>datingDataMat, datingLabels = kNN.file2matrix('./datingTestSet.txt') 使用函数file2matrix读取文件数据，必须确保文件datingTestSet.txt存储在我们的工作目录中。现在已经从文本文件中导入了数据，并将其格式化为想要的格式，接着我们需要了解数据的真实含义。当然我们可以直接浏览文本文件，但一般来说，我们会采用图形化的方式直观地展示数据。
2.2 分析数据：使用Matplotlib创建散点图 首先我们使用Matplotlib制作原始数据的散点图，在Python命令行环境中，输入下列命令:
import matplotlib.pyplot as plt from matplotlib import font_manager # 导入字体管理模块 datingDataMat, datingLabels = file2matrix(r'./datingTestSet.txt') # print(datingDataMat) # print(datingLabels) fig = plt.figure() ax = fig.add_subplot(111) ax.scatter(datingDataMat[:, 1], datingDataMat[:, 2]) my_font = font_manager.FontProperties(fname=r"C:/WINDOWS/Fonts/simfang.ttf") plt.xlabel("玩视频游戏所耗时间百分比", fontproperties = my_font) plt.ylabel("每周消费的冰淇淋公升数", fontproperties = my_font) plt.show() 输出效果如下图所示，散点图使用datingDataMat矩阵的第二、第三列数据，分别表示特征值“玩视频游戏所耗时间百分比”和“每周所消费的冰淇淋公升数”。
由于没有使用样本分类的特征值，我们很难从上图中看到任何有用的数据模式信息。一般来说，我们会采用色彩或其他的记号来标记不用样本分类，以便更好地理解数据信息。重新输入上面的代码，更改scatter函数：
def showdatas(datingDataMat, datingLabels): from matplotlib.font_manager import FontProperties import matplotlib.lines as mlines import matplotlib.pyplot as plt # 设置汉字格式 font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14) # 将fig画布分隔成1行1列,不共享x轴和y轴,fig画布的大小为(13,8) # 当nrow=2,nclos=2时,代表fig画布被分为四个区域,axs[0][0]表示第一行第一个区域 fig, axs = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False, figsize=(13, 8)) numberOfLabels = len(datingLabels) LabelsColors = [] for i in datingLabels: if i == 1: LabelsColors.append('black') if i == 2: LabelsColors.append('orange') if i == 3: LabelsColors.append('red') # 画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第二列(玩游戏)数据画散点数据,散点大小为15,透明度为0.5 axs[0][0].scatter(x=datingDataMat[:, 0], y=datingDataMat[:, 1], color=LabelsColors, s=15, alpha=.5) # 设置标题,x轴label,y轴label axs0_title_text = axs[0][0].set_title(u'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比', fontproperties=font) axs0_xlabel_text = axs[0][0].set_xlabel(u'每年获得的飞行常客里程数', fontproperties=font) axs0_ylabel_text = axs[0][0].set_ylabel(u'玩视频游戏所消耗时间占', fontproperties=font) plt.setp(axs0_title_text, size=9, weight='bold', color='red') plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black') plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black') # 画出散点图,以datingDataMat矩阵的第一(飞行常客例程)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5 axs[0][1].scatter(x=datingDataMat[:, 0], y=datingDataMat[:, 2], color=LabelsColors, s=15, alpha=.5) # 设置标题,x轴label,y轴label axs1_title_text = axs[0][1].set_title(u'每年获得的飞行常客里程数与每周消费的冰激淋公升数', fontproperties=font) axs1_xlabel_text = axs[0][1].set_xlabel(u'每年获得的飞行常客里程数', fontproperties=font) axs1_ylabel_text = axs[0][1].set_ylabel(u'每周消费的冰激淋公升数', fontproperties=font) plt.setp(axs1_title_text, size=9, weight='bold', color='red') plt.setp(axs1_xlabel_text, size=7, weight='bold', color='black') plt.setp(axs1_ylabel_text, size=7, weight='bold', color='black') # 画出散点图,以datingDataMat矩阵的第二(玩游戏)、第三列(冰激凌)数据画散点数据,散点大小为15,透明度为0.5 axs[1][0].scatter(x=datingDataMat[:, 1], y=datingDataMat[:, 2], color=LabelsColors, s=15, alpha=.5) # 设置标题,x轴label,y轴label axs2_title_text = axs[1][0].set_title(u'玩视频游戏所消耗时间占比与每周消费的冰激淋公升数', fontproperties=font) axs2_xlabel_text = axs[1][0].set_xlabel(u'玩视频游戏所消耗时间占比', fontproperties=font) axs2_ylabel_text = axs[1][0].set_ylabel(u'每周消费的冰激淋公升数', fontproperties=font) plt.setp(axs2_title_text, size=9, weight='bold', color='red') plt.setp(axs2_xlabel_text, size=7, weight='bold', color='black') plt.setp(axs2_ylabel_text, size=7, weight='bold', color='black') # 设置图例 didntLike = mlines.Line2D([], [], color='black', marker='.', markersize=6, label='didntLike') smallDoses = mlines.Line2D([], [], color='orange', marker='.', markersize=6, label='smallDoses') largeDoses = mlines.Line2D([], [], color='red', marker='.', markersize=6, label='largeDoses') # 添加图例 axs[0][0].legend(handles=[didntLike, smallDoses, largeDoses]) axs[0][1].legend(handles=[didntLike, smallDoses, largeDoses]) axs[1][0].legend(handles=[didntLike, smallDoses, largeDoses]) # 显示图片 plt.show() 由于利用颜色和尺寸标识了数据点的属性类别，因而我们基本上可以从上图看到数据点所属三个样本分类的区域轮廓。
2.3 准备数据：归一化数值 我们很容易发现，数值插值大的属性对计算结果影响很大，也就是说，每年获取的飞行常客里程数对于计算结果的影响将远远大于其他两个特征的影响。而产生的这种现象的原因，仅仅是因为飞行常客里程数远大于其他特征值。但海伦认为这三种特征是同等重要的，因此作为三个等权重的特征之一，飞行常客里程数并不应该如此严重地影响到计算结果。
在处理不同取值范围的特征值时，我们通常采用的方法是将数值归一化，如将取值范围处理为0到1或-1到1之间。
我们需要在文件kNN.py中增加一个新函数autoNorm()，该函数可以自动将数字特征值转化为0到1的区间。
# 程序清单2.3.1 归一化特征值 def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDataSet = zeros(shape(dataSet)) m = dataSet.shape[0] normDataSet = dataSet - tile(minVals, (m,1)) normDataSet = normDataSet/tile(ranges, (m,1)) #element wise divide return normDataSet, ranges, minVals 在函数autoNorm()中，我们将每列的最小值放在变量minVals中，将最大值放在变量maxVals中，其中dataSet.min(0)中的参数0可以使得函数可以从列中选取最小值，而不是选取当前行的最小值。然后，函数计算可能的取值范围，并创建新的返回矩阵。需要注意的是，特征值矩阵有1000x3个值，而minVals和range的值都为1x3。为了解决这个问题，我们使用NumPy库中tile()函数将变量内容复制成输入矩阵同样大小的矩阵，注意这是具体特征值相除，而对于某些数值处理软件包，/可能意味着矩阵除法，但在NumPy库中，矩阵除法需要使用函数linalg.solve(matA, matB)。
2.4 测试算法：作为完整程序验证分类器 前面已经将数据按照需求进行了处理，本节我们将测试分类器的效果。如果分类器的正确率满足要求，海伦就可以使用这个软件来处理约会网站提供的约会名单了。机器学习算法一个很重要的工作就是评估算法的正确率，通常我们只提供已有数据的90%作为训练样本来训练分类器，而使用其余的10%数据去测试分类器，检测分类器的正确率。需要注意的是，10%测试数据应该是随机选择的，由于海伦提供的数据并没有按照特定目的来排序，所以我们可以随意选择10%数据而不影响其随机性。
前面我们已经提到可以使用错误率来检测分类器的性能。对于分类器来说，错误率就是分类器给出错误结果的次数除以测试数据的总数，完美分类器的错误率为0，而错误率为1的分类器不会给出任何正确的分类结果。代码里我们定义一个计数器变量，每次分类器错误地分类数据，计数器就加1，程序执行完成之后计数器的结果除以数据点总数即是错误率。
# 程序清单2.4.1 分类器针对约会网站的测试代码 def datingClassTest(): # 打开的文件名 filename = "./datingTestSet.txt" # 将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中 datingDataMat, datingLabels = file2matrix(filename) # 取所有数据的百分之十 hoRatio = 0.10 # 数据归一化,返回归一化后的矩阵,数据范围,数据最小值 normMat, ranges, minVals = autoNorm(datingDataMat) # 获得normMat的行数 m = normMat.shape[0] # 百分之十的测试数据的个数 numTestVecs = int(m * hoRatio) # 分类错误计数 errorCount = 0.0 for i in range(numTestVecs): # 前numTestVecs个数据作为测试集,后m-numTestVecs个数据作为训练集 classifierResult = classify0(normMat[i,:], normMat[numTestVecs:m,:], datingLabels[numTestVecs:m], 4) print("分类结果:%d\t真实类别:%d" % (classifierResult, datingLabels[i])) if classifierResult != datingLabels[i]: errorCount += 1.0 print("错误率:%f%%" %(errorCount/float(numTestVecs)*100)) datingClassTest()首先使用了file2matrix()和autoNorm()函数从文件中读取数据并将其转换为归一化特征值。接着计算测试向量的数量，此步决定了normMat向量中哪些数据用于测试，哪些数据用于分类器的训练样本；然后将这两部分数据输入到原始kNN分类器函数classify0。最后，函数计算错误率并输出结果。我们可以改变函数datingClassTest()内变量hoRatio和变量k的值，检测错误率是否随着变量值的变化而增加。依赖于分类算法、数据集和程序设置，分类器的输出结果可能有很大的不同。
2.5 使用算法：构建完整可用系统 前面我们已经在数据上对分类器进行了测试，现在终于可以使用这个分类器为海伦来对人们分类。我们会给海伦一小段程序，通过该程序海伦会在约会网站上找到某个人并输入他的信息，程序会给出她对对方喜欢程度的预测值。
# 程序清单2.5.1 约会网站预测函数 def classifyPerson(): # 输出结果 resultList = ['讨厌','有些喜欢','非常喜欢'] # 三维特征用户输入 precentTats = float(input("玩视频游戏所耗时间百分比:")) ffMiles = float(input("每年获得的飞行常客里程数:")) iceCream = float(input("每周消费的冰激淋公升数:")) # 打开的文件名 filename = "datingTestSet.txt" # 打开并处理数据 datingDataMat, datingLabels = file2matrix(filename) # 训练集归一化 normMat, ranges, minVals = autoNorm(datingDataMat) # 生成NumPy数组,测试集 inArr = np.array([precentTats, ffMiles, iceCream]) # 测试集归一化 norminArr = (inArr - minVals) / ranges # 返回分类结果 classifierResult = classify0(norminArr, normMat, datingLabels, 3) # 打印结果 print("你可能%s这个人" % (resultList[classifierResult-1])) 接着我们只需输入数据，海伦即可得到预测结果。</content></entry><entry><title>k近邻算法--1.k近邻算法概述</title><url>https://murphyhanxu.github.io/post/k-nearest-neighbor-algorithm1/</url><categories><category>CS</category></categories><tags><tag>Machine Learning</tag></tags><content type="html"> 简单地说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。
1. k近邻算法概述 k近邻算法
优点：精度高、对异常值不敏感、无数据输入假定。
缺点：计算复杂度高、空间复杂度高。
适用数据范围：数值型和标称型。
工作原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。
我们举一个电影分类的例子，使用k近邻算法分类爱情片和动作片。有人曾经统计过很多电影的打斗镜头和接吻镜头，图1显示了6部电影的打斗和接吻镜头数。假如有一部未看过的电影，如何确定它是爱情片还是动作片呢？
即使不知道未知电影属于哪种类型，我们也可以通过某种方法计算出来。首先计算未知电影与样本集中其他电影的距离。此处暂时不关心如何计算得到这些距离值，使用Python实现电影分类应用时，会提供具体的计算方法。
现在我们得到了样本集中所有电影与未知电影的距离，按照距离递增排序，可以找到k个距离最近的电影。假定k=3，则三个最靠近的电影依次是He&rsquo;s Not Really into Dudes、Beautiful Woman和California Man。k近邻算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。
k近邻算法一般流程
收集数据：可以使用任何方法 距离计算所需要的数值，最好是结构化的数据格式 分析数据：可以使用任何方法 训练数据：此步骤不适用于k近邻算法 测试算法：计算错误率 使用算法：首先需要输入样本数据和结构化的输出结果，然后运行k近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。 1.1 准备：使用Python导入数据 首先，创建名为kNN.py的Python模块，我们使用的所有代码都在这个文件中。在kNN.py文件中增加下面的代码：
import numpy import operator def createDataSet(): group = array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]]) labels = ['A', 'A', 'B', 'B'] return group, labels 这里有4组数据，每组数据有两个我们已知的属性或者特征值。上面的group矩阵每行包含一个不同的数据，我们可以把它想象为某个日志文件中不同的测量点或者入口。由于人类大脑的限制，我们通常只能可视化处理三维以下的事务。因此为了简单地实现数据可视化，对于每个数据点我们通常只使用两个特征。
向量label包含了每个数据点的标签信息，label包含的元素个数等于group矩阵行数。这里我们将数据点(1, 1.1)定义为类A，数据点(0, 0.1)定义为类B。为了说明方便，例子中的数值是任意选择的，并没有给出轴标签。下图是带有类标签信息的四个数据点。
现在我们已经知道Python如何解析数据，如何加载数据，以及kNN算法的工作原理，接下来我们将使用这些方法完成分类任务。
1.2 从文本文件中解析数据 本节使用程序清单1.2.1的函数运行kNN算法，为每组数据分类。这里首先给出k近邻算法的伪代码和实际的Python代码，然后详细地解释每行代码的含义。该函数的功能是使用k近邻算法将每组数据划分到某个类中，其伪代码如下：
对未知类别属性的数据集中的每个点依次执行以下操作： (1)计算已知类别数据集中的点与当前点之间的距离 (2)按照距离递增次序排序 (3)选取与当前点距离最小的k个点 (4)确定前k个点所在类别的出现频率 (5)返回前k个点出现频率最高的类别作为当前点的预测分类 # 程序清单1.2.1 k近邻算法 def classify0(inX, dataSet, labels, k): # 函数说明:打开并解析文件，对数据进行分类：1代表不喜欢,2代表魅力一般,3代表极具魅力 # numpy函数shape[0]返回dataSet的行数 dataSetSize = dataSet.shape[0] # 在列向量方向上重复inX共1次(横向),行向量方向上重复inX共dataSetSize次(纵向) diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet # 二维特征相减后平方 sqDiffMat = diffMat ** 2 # sum()所有元素相加,sum(0)列相加,sum(1)行相加 sqDistances = sqDiffMat.sum(axis=1) # 开方,计算出距离 distances = sqDistances ** 0.5 # 返回distances中元素从小到大排序后的索引值 sortedDistIndices = distances.argsort() # 定一个记录类别次数的字典 classCount = {} for i in range(k): # 取出前k个元素的类别 voteIlabel = labels[sortedDistIndices[i]] # dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。 # 计算类别次数 classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1 # python3中用items()替换python2中的iteritems() # key=operator.itemgetter(1)根据字典的值进行排序 # key=operator.itemgetter(0)根据字典的键进行排序 # reverse降序排序字典 sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True) # 返回次数最多的类别,即所要分类的类别 return sortedClassCount[0][0] classify0()函数有4个输入参数：用于分类的输入向量是inX，输入的训练样本集为dataSet，标签向量为labels，最后的参数k表示用于选择最近邻居的数目，其中标签向量的元素数目和矩阵dataSet的行数相同。程序清单1.2.1使用欧氏距离公式，计算两个向量点xA和xB之间的距离①： $$ d=\sqrt {(xA_0-xB_0)^2+(xA_1-xB_1)^2} $$ 计算完所有点之间的距离后，可以对数据按照从小到大的次序排序。然后，确定前k个距离最小元素所在的主要分类②，输入k总是正整数。最后，将classCount字典分解为元组列表，然后使用程序第二行导入运算法模块的itemgetter方法，按照第二个元素的次序对元组进行排序②。此处的排序为逆序，即按照从最大到最小次序排序，最后返回发生频率最高的元素标签。
为了预测数据所在分类，在Python提示符下输入下列命令：
>>>kNN.classify0([0, 0], group, labels, 3) 输出结果应该是B，大家也可以改变输入[0, 0]为其他值，测试程序的运行结果。
到现在为止，我们已经构造了第一个分类器，使用这个分类器可以完成很多分类任务。从这个实例出发，构造使用分类算法将会更加容易。
1.3 如何测试分类器 上文我们已经使用k近邻算法构造了第一个分类器，也可以检验分类器给出的答案是否符合我们的预期。但我们不免有疑问：“分类器何种情况下会出错？”或“答案是否总是正确的？”答案是否定的，分类器并不会得到百分百正确的结果，我们可以使用多种方法检测分类器的正确率。此外分类器的性能也会收到多种因素的影响，如分类器设置和数据集等。不同的算法在不同数据集上的表现可能完全不同，这也是本部分的6章都在讨论分类算法的原因所在。
为了测试分类器的效果，我们可以使用一致答案的数据，当然答案不能告诉分类器，检验分类器给出的结果是否符合预期结果。通过大量的测试数据，我们可以得到分类器的错误率——分类器给出错误结果的次数除以测试执行的总数。错误率是常用的评估方法，主要用于评估分类器在某个数据集上的执行效果。完美分类器的错误率为0，最差分类器的错误率为1，在这种情况下，分类器根本无法找到一个正确答案。
上一节介绍的例子已经可以正常运转了，但是并没有太大的实际用处，本章的后两节将在现实世界中使用k近邻算法。</content></entry><entry><title>决策树--3.测试和分类储存器</title><url>https://murphyhanxu.github.io/post/decisiontree3/</url><categories><category>CS</category></categories><tags><tag>Machine Learning</tag></tags><content type="html"> 本节我们将把重点转移到如何利用决策树执行数据分类上，我们将使用决策树构建分类器，以及实际应用中如何存储分类器。
3. 测试和储存分类器 3.1 测试算法：使用决策树执行分类 依靠训练数据构造了决策树之后，我们可以将它用于实际数据的分类。在执行数据分类时，需要决策树以及用于构造树的标签向量。然后，程序比较测试数据与决策树上的数值，递归执行该过程直到进入叶子节点。最后将测试数据定义为叶子节点所属的类型。
将程序清单3.1.1的代码添加到文件tree.py中
# 程序清单3.1.1 使用决策树的分类函数 def classify(inputTree, featLabels, testVec): firstStr = list(inputTree.keys())[0] secondDict = inputTree[firstStr] # ①将标签字符串转换为索引 featIndex = featLabels.index(firstStr) key = testVec[featIndex] valueOfFeat = secondDict[key] if isinstance(valueOfFeat, dict): classLabel = classify(valueOfFeat, featLabels, testVec) else: classLabel = valueOfFeat return classLabel 程序清单3.1.1定义的函数也是一个递归函数，在存储带有特征的数据会面临一个问题：程序无法确定特征在数据集中的位置，例如前面例子的第一个用于划分数据集的特征是no surfacing属性，但是在实际数据集中该属性存储在哪个位置？是第一个属性还是第二个属性？特征标签列表将帮助程序处理这个问题。使用index方法查找当前列表中第一个匹配firstStr变量的元素①。然后代码递归遍历整棵树，比较testVec变量中的值与树节点的值，如果达到叶子节点，则返回当前节点的分类标签。
将程序清单3.1.1的代码添加到文件trees.py之后，输入下列命令：
>>>myDat, labels = trees.createDataSet() >>>labels ["no surfacing", "flippers"] >>>myTree = treePlotter.retrieveTree(0) >>>trees.classify(myTree, labels, [1,0]) "no" >>>trees.classify(myTree, labels, [1,1]) "yes" 第一节点名为no surfing，它有两个子节点：一个是名字为0的叶子节点，类标签为no；另一个是名为flippers的判断节点，此处进入递归调用，flippers节点有两个子节点。以前绘制的树形图和此处代表树的数据结构完全相同。
3.2 使用算法：决策树的存储 构造决策树时很耗时的任务，即使处理很小的数据集，如前面的样本数据，也要花费几秒的数据，如果数据集很大，则会耗费很多计算时间。然而用创建好的决策树解决分类问题，则可以很快完成。因此，为了节省计算时间，最好能够在每次执行分类时调用已经构造好的决策树。为了解决这个问题，需要使用Python模块pickle序列化对象。序列化对象可以在磁盘上保存对象，并在需要的时候读取出来。任何对象都可以执行序列化操作，字典对象也不例外。
# 程序清单3.2.1 使用pickle模块存储决策树 def storeTree(inputTree,filename): import pickle fw = open(filename, "wb") pickle.dump(inputTree, fw) fw.close() def grabTree(filename): import pickle fr = open(filename, "rb") return pickle.load(fr) 在Python命令提示符下输入下列命令验证上述代码：
>>>trees.storeTree(myTree, "classifierStorage.txt") >>>trees.grabTree("classifierStorage.txt") {'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}} 通过上面的代码，我们可以将分类器存储在硬盘上，而不用每次对数据分类时重新学习一遍，这也是决策树的优点之一。我们可以预先提炼并存储数据集中包含的知识信息，在需要对事物进行分类时再使用这些知识。
我们之后将学习另一个决策树算法CART，本章使用的算法称为ID3，它是一个好的算法但并不完美。ID3算法无法直接处理数值型数据，尽管我们可以通过量化的方法将数值型数据转化为标称型数据，但是如果存在太多的划分，仍会面临其他问题。</content></entry><entry><title>决策树--2.绘制树形图</title><url>https://murphyhanxu.github.io/post/decisiontree2/</url><categories><category>CS</category></categories><tags><tag>Machine Learning</tag></tags><content type="html"> 上节我们已经学习了如何从数据集中创建树，然而字典的表示形式非常不易于理解，而且直接绘制图形也比较困难。本节我们将使用Matplotlib库创建树形图。决策树的主要优点就是直观易于理解，如果不能将其直观地显示出来，就无法发挥其优势。
决策树的范例：
2. 在Python中使用Matplotlib注解绘制树形图 2.1 Matplotlib注解 Matplotlib提供了一个注解工具annotations，它可以在数据图形上添加文本注释。注释通常用于解释数据的内容。由于数据上面直接存在文本描述非常丑陋，因此工具内嵌支持带箭头的划线工具，使得我们可以在其他恰当的地方指向数据位置，并在此处添加描述信息，解释数据内容。
我们将使用Matplotlib的注解功能绘制树形图，它可以对文字着色并提供多种形状以供选择，而且我们还可以反转箭头，将它指向文本框而不是数据点。创建名为treePlotter.py的新文件，然后输入下面的程序代码。
# 程序清单2.1.1 使用文本注解绘制树节点 import matplotlib.pyplot as plt # 定义文本框和箭头格式 decisionNode = dict(boxstyle = "sawtooth", fc = "0.8") leafNode = dict(boxstyle = "round4", fc = "0.8") arrow_args = dict(arrowstyle = "&lt;-") # 绘制带箭头的注解 def createPlot(): fig = plt.figure(1, facecolor='white') fig.clf() createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses plotNode('a decision node', (0.5, 0.1), (0.1, 0.5), decisionNode) plotNode('a leaf node', (0.8, 0.1), (0.3, 0.8), leafNode) plt.show() def plotNode(nodeTxt, centerPt, parentPt, nodeType): createPlot.ax1.annotate(nodeTxt, xy=parentPt, xycoords='axes fraction', xytext=centerPt, textcoords='axes fraction', va="center", ha="center", bbox=nodeType, arrowprops=arrow_args ) 代码定义了树节点格式的常量①。然后定义plotNode()函数执行了实际的绘图功能，该函数需要一个绘图区，该区域由全局变量createPlot.ax1定义。最后定义createPlot()函数，它是这段代码的核心。createPlot()函数首先创建了一个新图形并清空绘图区，然后在绘图区上绘制两个代表不同类型的树节点，后面我们将用这两个节点绘制树形图。
为了测试上面代码的实际输出结果，打开Python命令提示符：
>>>treePlotter.createPlot() 2.2 构造注解树 绘制一棵完整的树需要一些技巧。我们虽然有$x$$、$$y$坐标，但是如何防止所有的树节点却是个问题。我们必须知道有多少个叶节点，以便可以正确确定$x$轴的长度；我们还需要知道树有多少层，以便可以正确确定$y$轴的高度。这里我们定义两个新函数getBumLeafs()和getTreeDepth()，来获取叶节点的数目和树的层数，参见程序清单2.2.1，并将这两个函数添加到文件treePlotter.py中。
# 程序清单2.2.1 获取叶节点的数目和树的层数 def getNumLeafs(myTree): numLeafs = 0 firstStr = list(myTree.keys())[0] secondDict = myTree[firstStr] for key in secondDict.keys(): if type(secondDict[key]).__name__=='dict': # ①测试节点的数据类型是否为字典 numLeafs += getNumLeafs(secondDict[key]) else: numLeafs +=1 return numLeafs def getTreeDepth(myTree): maxDepth = 0 firstStr = list(myTree.keys())[0] secondDict = myTree[firstStr] for key in secondDict.keys(): if type(secondDict[key]).__name__=='dict': # 测试节点的数据类型是否为字典 thisDepth = 1 + getTreeDepth(secondDict[key]) else: thisDepth = 1 if thisDepth > maxDepth: maxDepth = thisDepth return maxDepth 上述程序中的两个函数具有相同的结构，后面我们也将使用到这两个函数。这里使用的数据结构说明了如何在Python字典类型中存储树信息。第一个关键字是第一次划分数据集的类别标签，附带的数值表示子节点的取值。从第一个关键字出发，我们可以遍历整棵树的所有子节点。如果子节点是字典类型，则该节点也是一个判断节点，需要递归调用getNumLeafs()函数。getNumLeafs()函数遍历整棵树，累计叶子节点的个数，并返回该数值。第2个函数getTreeDepth()计算遍历过程中遇到判断节点的个数。该函数的终止条件是叶子节点，一旦到达叶子节点，则从递归调用中返回，并将计算树深度的变量加一。为了节省大家的时间，函数retrieveTree输出预先存储的树信息，避免了每次测试代码时都要从数据中创建树的麻烦。
添加下面的代码到treePlotter.py中
def retrieveTree(i): listOfTrees =[{'no surfacing': {0: 'no', 1: {'flippers': {0: 'no', 1: 'yes'}}}}, {'no surfacing': {0: 'no', 1: {'flippers': {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'}}}} ] return listOfTrees[i] 保存文件treePlotter.py，在Python命令提示符下输入下列命令：
>>>reload(treePlotter) >>>treePlotter.retrieveTree(1) {'no surfacing': {0: 'no', 1: {'flippers': {0: {'head': {0: 'no', 1: 'yes'}}, 1: 'no'}}}} >>>myTree = treePlotter.retrieveTree(0) >>>treePlotter.getNumLeafs(myTree) 3 >>>treePlotter.getTreeDepth(myTree) 2 函数retrieveTree()主要用于测试，返回预定义的树结构。上述命令中调用getNumLeafs()函数返回值为3，等于树0的叶子节点数；调用getTreeDepths()函数也能够正确返回树的层数。现在我们可以将前面学到的方法组合在一起，绘制一棵完整的树。
更新函数createPlot()
# 程序清单2.2.2 plotTree函数 # ①在父子节点中添加文本信息 def plotMidText(cntrPt, parentPt, txtString): xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0] yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1] createPlot.ax1.text(xMid, yMid, txtString, va="center", ha="center", rotation=30) # ②计算宽与高 def plotTree(myTree, parentPt, nodeTxt): numLeafs = getNumLeafs(myTree) depth = getTreeDepth(myTree) firstStr = list(myTree.keys())[0] cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff) # ③标记子节点属性值 plotMidText(cntrPt, parentPt, nodeTxt) plotNode(firstStr, cntrPt, parentPt, decisionNode) secondDict = myTree[firstStr] plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD # ④减少y偏移 for key in secondDict.keys(): if type(secondDict[key]).__name__=='dict': plotTree(secondDict[key],cntrPt,str(key)) else: plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode) plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key)) plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD def createPlot(inTree): fig = plt.figure(1, facecolor='white') fig.clf() axprops = dict(xticks=[], yticks=[]) createPlot.ax1 = plt.subplot(111, frameon=False, **axprops) #no ticks #createPlot.ax1 = plt.subplot(111, frameon=False) #ticks for demo puropses plotTree.totalW = float(getNumLeafs(inTree)) plotTree.totalD = float(getTreeDepth(inTree)) plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0 plotTree(inTree, (0.5, 1.0), '') plt.show() 函数createPlot()是我们的主函数。绘制树形图的很多工作都是在函数plotTree()中完成的，函数plotTree()首先计算树的宽和高②。全局变量plotTree.totalW存储树的宽度，全局变量plotTree.totalD存储树的深度，我们使用这两个变量计算树节点的摆放位置，这样可以将树绘制在水平方向和垂直方向的中心位置。与程序清单2.2.1类似，函数plotTree()也是个递归函数。树的宽度用于计算放置判断节点的位置，主要的计算原则是将它放在所有叶子节点的中间，而不仅仅是它子节点的中间。同时我们使用两个全局变量plotTree.xOff和plotTree.yOff追踪已经绘制的节点位置，以及放置下一个节点的恰当位置。另一个需要说明的问题是，绘制图形的$x$轴有效范围是0到1，$y$轴有效范围也是0到1。通过计算树包含的所有叶子节点树，划分图形的宽度，从而计算得到当前节点的中心位置，也就是说，我们按照叶子节点的数目将$x$轴划分为若干部分。按照图形比例绘制树形图的最大好处是无需关心实际输出图形的大小，一旦图形大小发生了变化，函数会自动按照图形大小重新绘制。如果以像素为单位绘制图形，则缩放图形就不是一件简单的工作。
接着，绘出子节点具有的特征值，或者沿此分支向下的数据实例必须具有的特征值③。使用函数plotMidText()计算父节点和子节点的中间位置，并在此处添加简单的文本标签信息②。
然后，按比例减少全局变量plotTree.yOff，并标注此处将要绘制子节点④，这些节点即可以是叶子节点也可以是判断节点，此处需要只保存绘制图形的轨迹。因为我们是自顶向下绘制图形，因此需要一次递减$y$坐标值，而不是递增$y$坐标值。然后程序采用函数getNumLeafs()和getTreeDepth()以相同的方式递归遍历整棵树，如果节点是叶子节点则在图形上画出叶子节点，如果不是叶子节点，则递归调用plotTree()函数。在绘制了所有子节点之后，增加全局变量Y的偏移。
最后一个函数式createPlot()，它创建绘图区，计算树形图的全局尺寸，并递归调用函数plotTree()。
现在我们验证一下实际的输出效果。添加上述代码到文件treePlotter.py之后，在Python命令提示符下输入下列命令：
>>>reload(treePlotter) >>>myTree = treePlotter.retrieveTree(0) >>>treePlotter.createPlot(myTree) 输出效果如图，但是没有坐标轴标签。
接着按照如下命令变更字典，重新绘制树形图。你也可以在树字典中随意添加一些数据，并重新绘制树形图观察输出结果的变化：
>>>myTree["no surfacing"][3]="maybe" >>>treeplotter.createPlot(myTree) 到目前为止，我们已经学习了如何构造决策树，以及绘制树形图的方法，下节我们将实际使用这些方法，并从数据和算法中得到某些新知识。</content></entry><entry><title>决策树--1.决策树的构造</title><url>https://murphyhanxu.github.io/post/decisiontree1/</url><categories><category>CS</category></categories><tags><tag>Machine Learning</tag></tags><content type="html"> 本章构造的决策树算法能够读取数据集合，构建类似于图1的决策树。
决策树很多任务都是为了数据中所蕴含的知识信息，因此决策树可以使用不熟悉的数据集合，并从中提取出一系列规则，机器学习算法最终将使用这些机器从数据集中创造的规则。
专家系统中经常使用决策树，而且决策树给出结果往往可以匹敌在当前领域具有几十年工作经验的人类专家。
1. 决策树的构造 决策树
优点：计算复杂度不高，输出结果易于理解，对中间值的缺失不敏感，可以处理不相关特征数据。
缺点：可能会产生过度匹配问题。
适用数据类型：数值型和标称型。
我们将一步步地构造决策树算法，并会涉及许多有趣的细节。首先我们讨论数学上如何使用信息论划分数据集，然后编写代码将理论应用到具体的数据集上，最后编写代码构造决策树。
在构造决策树时，我们需要解决的第一个问题就是，当前数据集上哪个特征在划分数据分类时起决定性作用。为了找到决定性的特征，划分出最好的结果，我们必须评估每个特征。完成测试之后，原始数据集就被划分为几个数据子集。这些数据子集会分布在第一个决策点的所有分支上。如果某个分支下的数据属于同一类型，则当前无需阅读的垃圾邮件已经正确地划分数据分类，无需进一步对数据集进行分割。如果数据子集内的数据不属于同一类型，则需要重复划分数据子集的过程。如何划分数据子集的算法和划分原始数据集的方法相同，知道所有具有相同类型的数据均在一个数据子集内。
创建分支的伪代码函数createBranch()如下所示：
检测数据集中的每个子项是否属于同一分类： If so return 类标签: Else 寻找划分数据集的最好特征 划分数据集 创建分支节点 for 每个划分的子集 调用函数createBranch并增加返回结果到分支节点中 return 分支节点 上面的伪代码createBranch是一个递归函数，在倒数第二行直接调用了它自己。后面将把上述的伪代码转换为Python代码，这里我们需要进一步了解算法是如何划分数据集的。
决策树的一般流程
1.收集数据：可以使用任何方法
2.准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。
3.分析数据：可以使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。
4.训练数据：构造树的数据结构。
5.测试算法：使用经验树计算错误率。
6.使用算法：此步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。
下表包含5个海洋动物，特征包括：不浮出水面是否可以生存，以及是否有脚蹼。我们可以将这些动物分成两类：鱼类和非鱼类。现在我们想要决定依据第一个特征还是第二个特征划分数据。在回答这个问题之前，我们必须采用量化的方法判断如何划分数据。
编号 不浮出水面是否可以生存 是否有脚蹼 属于鱼类 1 是 是 是 2 是 是 是 3 是 否 否 4 否 是 否 5 否 是 否 1.1 信息增益 划分数据集的大原则是：将无序的数据变得更加有序。我们可以使用多种方法划分数据集，但是每种方法都有各自的优缺点。组织杂乱无章数据的一种方法就是使用信息论度量信息，信息论是量化处理信息的分支科学。
我们可以在划分数据之前使用信息论量化度量信息的内容。
在划分数据集之前之后信息发生的变化称为信息增益（information gain），知道如何计算信息增益，我们就可以计算每个特征值划分数据集获得的信息增益，获得信息增益最高的特征就是最好的选择。
在可以评测哪种数据划分方式是最好的数据划分之前，我们必须学习如何计算信息增益。集合信息的度量方式称为香农熵或者简称为熵（entropy），这个名字来源于信息论之父克劳德香农。
熵定义为信息的期望值，在明晰这个概念之前，我们必须知道信息的定义。如果待分类的事务可能划分在多个分类之中，则符号$ x_i $的信息定义为
$$ l(x_i)=-\log_2 p(x_i) $$ 其中$p(x_i)$是选择该分类的概率。
为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值，通过下面的公式得到： $$ H=-\sum_{i=1}^np(x_i)\log_2p(x_i) $$ 其中$n$是分类的数目。
下面我们将使用Python计算信息熵，创建名为trees.py的文件，此代码的功能是计算给定数据集的熵。
# 程序清单1.1.1 计算给定数据集的香农熵 from math import log def calcShannonEnt(dataSet): numEntries = len(dataSet) labelCounts = {} # ①为所有可能分类创建字典 for featVec in dataSet: currentLabel = featVec[-1] if currentLabel not in labelCounts.keys(): labelCounts[currentLabel] = 0 labelCounts[currentLabel] += 1 shannonEnt = 0 # ②以2为底求对数 for key in labelCounts: prob = float(labelCounts[key])/numEntries shannonEnt -= prob * log(prob, 2) return shannonEnt 首先，计算数据集中实例的总数。我们也可以在需要时再计算这个值，但是由于代码中多次用到这个值，为了提高代码效率，我们显式地声明一个变量保存实例总数。然后，创建一个数据字典，它的键值是最后一列的数值①。如果当前键值不存在，则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。最后，使用所有类标签的发生频率计算类别分别出现的概率。我们将用这个概率计算香农熵②，统计所有类标签发生的次数。
下面我们看看如何使用熵划分数据集。
在trees.py中，我们利用creaDataSet()函数得到表的简单数据集。
def createDataSet(): dataSet = [[1, 1, "yes"], [1, 1, "yes"], [1, 0, "no"], [0, 1, "no"], [0, 1, "no"]] labels = ["no surfacing", "flippers"] return dataSet, labels 在Python命令提示符下输入下列命令：
>>>reload(trees.py) >>>myDat, label = trees.createDataSet() >>>myDat [[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] >>>trees.calcShannonEnt(myDat) 0.9287712379549449 # 熵越高，则混合的数据也越多，我们可以在数据集中添加更多的分类，观察熵是如何变化的。这里我们增加第三个名为maybe的分类，测试熵的变化： >>>myDat[0][-1] = "maybe" >>>myDat [[1, 1, 'maybe'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] >>>trees.calcShannonEnt(myDat) 1.3931568569324173 得到熵之后，我们就可以按照获取最大信息增益的方法划分数据集，下一节我们讨论如何划分数据集并创建决策树，以及如何度量信息增益。
1.2 划分数据集 上节我们学习了如何度量数据集里的无序程度，分类算法除了需要测量信息熵，还需要划分数据集，度量花费数据集的熵，以便判断当前是否正确地划分了数据集。我们将对每个特征划分数据集的结果计算一次信息熵，然后判断按照哪个特征划分数据集是最好的划分方式。想象一下分布在二维空间的数据散点图，需要在数据之间划条线，将它们分成两部分，我们接下来将讨论是按照$x$$轴还是$$y$轴划线呢？
要划分数据集，在trees.py文件下输入下列的代码：
# 程序清单1.2.1 按照给定特征划分数据集 def splitDataSet(dataSet, axis, value): # ①创建新的list对象 retDataSet = [] for featVec in dataSet: # ②抽取 if featVec[axis] == value: reducedFeatVec = featVec[:axis] reducedFeatVec.extend(featVec[axis+1:]) retDataSet.append(reducedFeatVec) return retDataSet 程序清单1.2.1使用了三个输入参数：待划分的数据集、划分数据集的特征、特征的返回值。
需要注意的是，Python语言不用考虑内存分配问题。Python语言在函数中传递的是列表的引用，在函数内部对列表对象的修改，将会影响该列表对象的整个生存周期。为了消除这个不良影响，我们需要在函数的开始声明一个新列表对象。因为该函数代码在同一数据集上被调用多次，为了不修改原始数据集，创建一个新的列表对象①。数据集这个列表中的各个元素列表，我们要遍历数据集中的每个元素，一旦发现符合要求的值，则将其添加到新创建的列表中。
在if语句中，程序将符合特征的数据抽取出来②。后面讲述得更简单，这里我们可以这样理解这段代码：当我们按照某个特征划分数据集时，就需要将所有符合要求的元素抽取出来。
代码中使用了Python语言列表类型自带的extend()和append()方法。这两个方法功能类似，但是在处理多个列表时，这两个方法的处理结果是完全不同的。
# 假定存在两个列表，a和b： >>>a = [1, 2, 3] >>>b = [4, 5, 6] >>>a.append(b) >>>a [1, 2, 3, [4, 5, 6]] # 如果执行a.append(b)，则列表得到了第四个元素，而且第四个元素也是一个列表。然而如果使用.extend()方法： >>>a = [1, 2, 3] >>>a.extend(b) >>>a [1, 2, 3, 4, 5, 6] # 则得到一个包含a和b所有元素的列表。 我们可以在前面的简单样本数据上测试函数splitDataSet()。首先还是要将程序清单1.2.1的代码增加到trees.py文件中，然后再Python命令提示符内输入下述命令：
>>>reload(trees) &lt;module 'trees' from 'trees.pyc'> >>>myDat, labels=trees.createDataSet() >>>myDat [[1, 1, "yes"], [1, 1, "yes"], [1, 0, "no"], [0, 1, "no"], [0, 1, "no"]] >>>trees.splitDataSet(myDat, 0, 1) [[1, "yes"], [1, "yes"], [0, "no"]] >>>trees.splitDataSet(myDat, 0, 0) [[1, "no"], [1, "no"]] 接下来我们将遍历整个数据集，循环计算香农熵和splitDataSet()函数，找到最好的特征划分方式。熵计算将会告诉我们如何划分数据集时最好的数据组织方式。
在trees.py文件中输入下面的程序代码。
# 程序清单1.2.2 选择最好的数据集划分方式 def chooseBestFeatureToSplit(dataSet): numFeatures = len(dataSet[0]) - 1 baseEntropy = calcShannonEnt(dataSet) bestInfoGain = 0 bestFeature = -1 for i in range(numFeatures): # ①创建唯一的分类标签列表 featList = [example[i] for example in dataSet] uniqueVals = set(featList) newEntropy = 0 for value in uniqueVals: # ②计算每种划分方式的信息熵 subDataSet = splitDataSet(dataSet, i, value) prob = len(subDataSet)/float(len(dataSet)) newEntroy += prob * calcShannonEnt(subDataSet) infoGain = baseEntropy - newRntropy # ③计算最好的信息增益 if (infoGain > bestInfoGain): bestInfoGain = infoGain bestFeature = i return bestFeature 程序清单1.2.2给出了函数chooseBestFeatureToSplit()的完整代码，该函数实现选取特征，划分数据集，计算得出最好的划分数据集的特征。函数chooseBestFeatureToSplit()使用了程序清单1.1.1和1.2.1中的函数。在函数调用的数据需要满足一定的要求：第一个要求是，数据必须是一种由列表元素组成的列表，而且所有的列表元素都要具有相同的数据长度；第二个要求是，数据的最后一列或者每个实例的最后一个元素是当前实例的类别标签。数据集一旦满足上述要求，我们就可以在函数的第一行判定当前数据集包含多少特征属性。我们无需限定list中的数据类型，它们既可以是数字也可以是字符串，并不影响实际计算。
在开始划分数据集之前，程序清单1.2.2的第3行代码计算了整个数据集的原始香农熵，我们保存最初的无序度量值，用于与划分完之后的数据集计算的熵值进行比较。第1个for循环遍历数据集中的所有特征。使用列表推导来创建新的列表，将数据集中所有第i个特征值或者所有可能存在的值写入这个新list中①。然后使用Python的集合（set）数据类型。集合数据类型与列表类型相似，不同之处仅在于集合类型中的每个值互不相同。从列表中创建集合是Python语言得到列表中唯一元素值的最快方法。
遍历当前特征中的所有唯一属性值，对每个特征划分一次数据集②，然后计算数据集的新熵值，并对所有唯一特征值得到的熵求和。信息增益是熵减或是数据无序度的减少，大家肯定对于将熵用于度量数据无序度的减少更容易理解。最后，比较所有特征中的信息增益，返回最好特征划分的索引值③。
现在我们可以测试上面代码的实际输出结果，首先将程序清单1.2.2的内容输入到文件trees.py中，然后在Python命令提示符下输入下列命令：
>>>reload(trees) >>>myDat, labels = trees.createDataSet() >>>trees.chooseBestFeatureToSplit(myDat) 0 >>>myDat [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']] 代码运行结果告诉我们，第0个特征是最好的用于划分数据集的特征。让我们来观察一下变量myDat中的数据。按照上述的方法划分数据集，第一个特征为1的海洋生物分组将有两个属于鱼类，一个属于非鱼类；另一个分组则全部属于非鱼类。如果按照第二个特征分组，结果又是怎样呢？第一个海洋动物分组将有两个属于鱼类，两个属于非鱼类；另一个分组则只有一个非鱼类。因此，第0个特征确实是最好的用于划分数据集的特征。
下一节我们将介绍如何将这些函数功能放在一起，构建决策树。
1.3 递归构建决策树 目前我们已经学习了从数据集构造决策树算法所需要的子功能模块，其工作原理如下：得到原始数据集，然后基于最好的属性值划分数据集，由于特征值可能多于两个，因此可能存在大于两个分支的数据集划分。第一次划分之后，数据将被向下传递到树分支的下一个节点，在这个节点上，我们可以再次划分数据。因此我们可以采用递归的原则处理数据集。
递归结束的条件是：程序遍历完所有划分数据集的属性，或者每个分支下的所有实例都具有相同的分类。如果所有实例具有相同的分类，则得到一个叶子节点或者终止块。任何到达叶子节点的数据必然属于叶子节点的分类，如下图所示。
第一个结束条件使得算法可以终止，我们甚至可以设置算法可以划分的最大分组数目。后续章节还会介绍其他决策树算法，如C4.5和CART，这些算法在运行时并不总是在每次划分分组时都会消耗特征。由于特征数目并不是在每次划分数据分组时都减少，因此这些算法在实际使用时可能引起一定的问题。目前我们并不需要考虑这个问题，只需要在算法开始运行前计算列的数目，查看算法是否使用了所有属性即可。如果数据集已经处理了所有属性，但是类标签依然不是唯一的，此时我们需要决定如何定义该叶子节点，在这种情况下，我们通常会采用多数表决的方法决定该叶子节点的分类。
import operator def majorityCnt(classList): classCount={} for vote in classList: if vote not in classCount.keys(): classCount[vote] = 0 classCount[vote] += 1 sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True) return sortedClassCount[0][0] 上面的代码与1.2.2的投票表决代码非常类似，该函数使用分类名称的列表，然后创建键值为classList中唯一值的数据字典，字典对象存储量classList中每个类标签出现的频率，最后利用operator操作键值排序字典，并返回出现次数最多的分类名称。
# 程序清单1.3.1 创建树的函数代码 def createTree(dataSet,labels): classList = [example[-1] for example in dataSet] # ①类别完全相同则停止继续划分 if classList.count(classList[0]) == len(classList): return classList[0] if len(dataSet[0]) == 1: # ②遍历完所有特征时返回出现次数最多的 return majorityCnt(classList) bestFeat = chooseBestFeatureToSplit(dataSet) bestFeatLabel = labels[bestFeat] myTree = {bestFeatLabel:{}} del(labels[bestFeat]) featValues = [example[bestFeat] for example in dataSet] # ③得到列表包含的所有属性值 uniqueVals = set(featValues) for value in uniqueVals: subLabels = labels[:] #copy all of labels, so trees don't mess up existing labels myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels) return myTree 程序清单1.3.1的代码使用两个输入参数：数据集和标签列表。标签列表包含了数据集中所有特征的标签，算法本身并不需要这个变量，但是为了给出数据明确的含义，我们将它作为一个输入参数提供。此外，前面提到的对数据集的要求这里依然需要满足。上述代码首先创建了名为classList的列表变量，其中包含了数据集的所有类标签。递归函数的第一个停止条件是所有的类标签完全相同，则直接返回该类标签①。
递归函数的第二个停止条件是使用完了所有特征，仍然不能将数据集划分成仅包含唯一类别的分组②。由于第二个条件无法简单地返回唯一的类标签，这里使用程序清单1.3.1的函数挑选出现次数最多的类别作为返回值。
下一步程序开始创建树，这里使用Python语言的字典类型存储树的信息，当然也可以声明特殊的数据类型存储树，但这里完全没有必要。字典变量myTree存储了树的所有信息，这对于其后绘制树形图非常重要。当前数据集选取的最好特征存储在变量bestFeat中，得到列表包含的所有属性值③。这部分代码与程序清单1.3.1的部分代码类似。
最后代码遍历当前选择特征包含的所有属性值，在每个数据集划分上递归调用函数createTree()，得到的返回值将被插入到字典变量myTree中，因此函数终止执行时，字典中将会嵌套很多代表叶子节点信息的字典数据。在解释这个嵌套数据之前，我们先看一下循环的第一行subLabels = labels[:]，这行代码复制了类标签，参数是按照引用方式传递的。为了保证每次调用函数createTree()时不改变原始列表的内容，使用新变量subLabels代替原始列表。
在Python命令提示符下输入下列命令：
>>>reload(trees) >>>myDat, labels = trees.createDataSet() >>>myTree = trees.createTree(myDat, labels) >>>myTree {"no surfacing":{0:"no",1:{"flippers":{0:"no", 1:"yes"}}}} 变量myTree包含了很多代表树结构信息的嵌套字典，从左边开始，第一个关键字nosurfacing是第一个划分数据集的特征名称，该关键字的值也是另一个数据字典。第二个关键字是no surfacing特征划分的数据集，这些关键字的值是no surfacing节点的子节点。这些值可能是类标签，也可能是另一个数据字典。如果值是类标签，则该子节点是叶子节点；如果值是另一个数据字典，则子节点是一个判断节点，这种格式结构不断重复就肿成了整棵树。本节的例子中，这棵树包含了3个叶子节点以及2个判断节点。
下一章将介绍如何绘制图形，方便我们正确理解数据信息的内在含义。</content></entry><entry><title>Python(xlrd,xlwt)对于excel的操作</title><url>https://murphyhanxu.github.io/post/autoexcel/</url><categories><category>CS</category></categories><tags><tag>Python</tag></tags><content type="html"> 总结xlrd，xlwt，pandas对于excel的常用操作。
库 .xls .xlsx 读取 消耗时间（以10MB.xlsx文件为例） 写入 修改 保存 样式调整 xlrd √ √ √ 12.38s × × × × xlwt √ × × - √ √ √ √ xlrd 1.导入模块 import xlrd 2.打开文件 path = r"example.xlsx xlrd.open_workbook(path) path = r"example.xlsx wb = xlrd.open_workbook(path) print(wb) # &lt;xlrd.book.Book object at 0x000001F905A33DC0> 3.获取所有表名 wb.sheet_names() sheet_names_list = wb.sheet_names() # list print(sheet_names_list) # ['Sheet1', 'Sheet2', 'Sheet3'] 4.选定sheet表 wb.sheet_by_index(索引) wb.sheet_by_name("sheet表名") # 方式1：索引顺序获取 sheet_1 = wb.sheet_by_index(0) # 方式2:名称获取 sheet_2 = wb.sheet_by_name("Sheet1") 5.对sheet表的行操作 # 1.sheet.nrows:获取sheet表的有效行数 print(sheet_1.nrows) # 2.sheet.row(1)返回由该行中所有单元格对象组成的列表，列表中的内容是键值对形式 print(sheet_1.row(1)) # [列名1:"值1", 列名2:"值2"...] # 3.sheet.row_values(rowx, start_colx=0, end_colx=None)：返回指定行的所有单元格数值组成的列表 print(sheet_1.row_values(1)) # ["值1", "值2"...] # 4.sheet.row_slice(rowx, start_col=0, end_col=None):可以获得一个行中指定的列的切片 print(sheet_1.row_slice(1, 0, 3)) # [列名1:"值1", 列名2:"值2", 列名3:"值3"] # 5.sheet.row_len(rox):返回指定行的有效长度 print(sheet_1.row_len(1)) # 6.sheet.get_rows():获取表中所有行构成一个迭代器对象 for row in list(sheet_1.get_rows())[0:15]: print(row) # 使用list()的好处是对获取的所有行返回的列表进行切片操作 6.对sheet表的列操作 # 1.sheet.ncols:返回指定sheet表的有效列数 print(sheet_1.ncols) # 2.sheet.col(1):返回由该列中所有的单元格对象组成的列表，列表内是键值对 print(sheet_1.col(1)) # ["行名1":"值1", "行名2":"值2"...] 若无行名，则默认行名为empty # 3.sheet.col_values(colx, start_colx=0, end_colx=None)：返回指定列的所有单元格数值组成的列表 print(sheet_1.col_values(0)) # 带列名 print(sheet_1.col_values(0, 1)) # 不带列名 # ["列名", "值1", "值2"...] # [值1", "值2"...] # 4.sheet.col_slice(colx, start_rowx=0, end_rowx=None)：返回由该列中所有的单元格对象组成的列表 print(sheet1.col_slice(0, 0, 3)) # [列名:"值1", type:"值2",type:"值3"] # 5.sheet.col_types(colx, start_rowx=0, end_rowx=None)：返回由该列中所有单元格的数据类型组成的列表 print(sheet1.col_types(0)) # 0-空，1-文本，2-数字，3-日期，4-布尔，5-array 7.对sheet表的单元格操作 # 1.sheet.cell(rowx,colx)：返回单元格对象 # 键值对 # 2.sheet.cell_type(rowx,colx)：返回单元格中的数据类型 # 0-空，1-文本，2-数字，3-日期，4-布尔，5-array # 3.sheet.cell_value(rowx,colx)：返回单元格中的数据 xlwt 1.导入模块 import xlwt 2.写入单个数据 # 1.创建Excel表对象 wb = xlwt.Workbook(encoding='utf8') # 2.新建sheet表 sheet = workbook.add_sheet('Sheet1') # 3.写入数据到指定单元格 sheet.write(0, 0, "python") # 4. 保存文件分两种格式 wb.save('test.xls') wb.save('test.xlsx') 3.写入多个数据 data_list = [('小白', '20', '男'), ('小黑', '21', '男'), ('小红', '20', '女')] # 1.创建Excel表对象 wb = xlwt.Workbook(encoding='utf8') # 2.新建sheet表 sheet = workbook.add_sheet('Sheet1') # 3.自定义列名 col1 = ('姓名', '年龄', '性别') # 4.将列属性元组col写进sheet表单中第一行 for i in range(0, len(col1)): wb.write(0, i, col1[i]) # 5.将数据写进sheet表单中 for i in range(0, len(data_list)): data = data_list[i] for j in range(0, len(col1)): worksheet.write(i + 1, j, data[j]) # 6.保存文件分两种格式 wb.save('test.xls') 4.设置列宽 for c in range(len(col1)): sheet.col(c).width = 256 * 24 5.设置行高 # 1.将数据写进sheet表单中 for i in range(0, len(data_list)): data = data_list[i] for j in range(0, len(col1)): sheet.write(i + 1, j, data[j]) # 2.设置行高 sheet.row(i + 1).height_mismatch = True sheet.row(i + 1).height = 1600 6.设置单元格风格 def body_style(): # 1.创建一个样式对象，初始化样式 style style = xlwt.XFStyle() # Create Style对象 # 2.字体风格设置 font = xlwt.Font() # Create Font对象 font.name = "SimSun" # 设置字体类型，宋体 font.colour_index = 4 # 设置字体颜色 font.height = 20 * 12 # 字体大小，12为字号，20为衡量单位 font.bont = True # 设置字体加粗 font.underline = True # 下划线 font.italic = True # 斜体字 # 3.背景设置 pattern = xlwt.Pattern() pattern.pattern = xlwt.Pattern.SOLID_PATTERN # May be: NO_PATTERN, SOLID_PATTERN, or 0x00 through 0x12 pattern.pattern_fore_colour = 4 # 给背景颜色赋值 # 4.边框设置 borders = xlwt.Borders() # 创建边框对象， # .DASHED：虚线；.NO_LINE：没有 # 上下左右都添加边框 borders.left = 1 borders.right = 1 borders.top = 1 borders.bottom = 1 # 设置边框颜色 borders.left_colour = 2 borders.right_colour = 2 borders.top_colour = 2 borders.bottom_colour = 2 # 5.位置设置 alignment = xlwt.Alignment() alignment.horz = 1 # 设置水平位置，0是左对齐，1是居中，2是右对齐 alignment.wrap = 1 # 设置自动换行 # 6.设置好之后，全部都加到style上 style.alignment = alignment style.font = font style.borders = borders return style</content></entry><entry><title>蒙特卡洛算法基于python的简单实现</title><url>https://murphyhanxu.github.io/post/montecarlo/</url><categories><category>CS</category></categories><tags><tag>Mathematical modeling</tag></tags><content type="html"> 基于python用蒙特卡洛方法解决几道简单的数学建模问题。
前言 什么是蒙特卡洛算法？ 蒙特·卡罗（ Monte Carlo method），又称统计模拟方法，是二十世纪四十年代中叶由于科学技术的发展和电子计算机的发明，而被提出的一种以概率统计理论为指导的一类非常重要的数值计算方法。是指使用随机数（或更常见的伪随机数）来解决很多计算问题的方法。
起源 蒙特卡洛方法于20世纪40年代美国在第二次世界大战中研制原子弹的“曼哈顿计划”计划成员S.M.乌拉姆和J.冯·诺依曼首先提出。数学家冯·诺依曼用驰名世界的赌城——摩纳哥的Monte Carlo——来命名这种方法，为它蒙上一层神秘色彩。公认的蒙特卡洛方法的起源是1777年法国数学家布丰提出用投针实验的方法求圆周率π。
基本思想 当所求解问题是某种随机事件出现的概率，或者是某个随机变量的期望值时，通过某种“实验”的方法，以这种事件出现的频率估计这一随机事件的概率，或者得到这个随机变量的某些数字特征，并将其作为问题的解。
工作步骤 构造或描述概率过程
实现从已知概率分布抽样
建立各种估计量
例1 Buffon’s needle problem
18世纪，蒲丰提出以下问题：设我们有一个以平行且等距木纹铺成的地板法国数学家布丰（1707-1788）最早设计了投针试验。
这一方法的步骤是：
1） 取一张白纸，在上面画上许多条间距为a的平行线。
2） 取一根长度为l（l≤a） 的针，随机地向画有平行直线的纸上掷n次，观察针与直线相交的次数，记为m。
3）计算针与直线相交的概率。
18世纪，法国数学家布丰提出的“投针问题”，记载于布丰1777年出版的著作中：“在平面上画有一组间距为a的平行线，将一根长度为l（l≤a）的针任意掷在这个平面上，求此针与平行线中任一条相交的概率。”
布丰本人证明了，这个概率是： $$ p=\frac{2l}{πa} $$
# 布丰投针实验用于估计pi的精确值 import random import math import numpy as np import matplotlib.pyplot as plt l = 1.5 # 任意给出针的长度l=1.5 a = 2 # 平行线的宽度，要求a>l即可 n = 1000 # 做n次投针实验，n越大pi越精确 m = 0 # 用于记录针与平行线相交的次数 x = [] phi = [] # 画图 fig = plt.figure() ax = fig.add_subplot(111) ax.set(xlim=[0, math.pi], ylim=[0, a/2], title='An Example Axes', ylabel='Y-Axis', xlabel='X-Axis') for i in range(0, n): temp = np.random.random() * a / 2 x.append(temp) for i in range(0, n): temp = np.random.random() * math.pi phi.append(temp) for i in range(0, n): if x[i] &lt;= l/2*math.sin(phi[i]): m = m+1 plt.scatter(phi[i], x[i], color='red') p = m/n # 针和平行线相交出现的频率 mypi = (2*l)/(a*p) print(mypi) plt.show() # 注意在画图时，n不能取的太大，否则导致占计算机内存较多，画图需要花费较长时间呈现。 # 而如果想得到越精确的mypi则n越大越好 例2 1.计算函数y = x^2在[0,1]区间的定积分
2.计算函数y = ln(1+x)/1+x^2 在[0,1]区间的定积分
通过生成大量的随机数来估算定积分的值。同例1一样也是几何概型问题。
import math import matplotlib.pylab as plt import numpy as np import random # 1.计算函数y = x^2在[0,1]区间的定积分 # m = 1000000 # n = 0 # for i in range(m): # x = random.random() # y = random.random() # if y >= x**2: # n += 1 # r = n / m # print("r = {}".format(r)) # r = 0.666817 # 2.计算函数y = ln(1+x)/1+x^2 在[0,1]区间的定积分 # 绘制函数图像 x = np.linspace(0, 1, num=50) y = np.log(1 + x) / (1 + x**2) plt.plot(x, y, '-') plt.show() m = 100000 n = 0 for i in range(m): x = random.random() y = random.random() if np.log(1 + x) / (1 + x**2) > y: n += 1 ans = n / m print(ans) 例3 三门问题
三门问题（Monty Hall probelm）亦称为蒙提霍尔问题，出自美国电视游戏节目Let’s Make a Deal。
参赛者会看见三扇关闭了的门，其中一扇的后面有一辆汽车，选中后面有车的那扇门可赢得该汽车，另外两扇门则各藏有一只山羊。当参赛者选定了一扇门，但未去开启它的时候，节目主持人开启剩下两扇门的其中一扇，露出其中一只山羊。主持人其后问参赛者要不要换另一扇仍然关上的门。
问题是：换另一扇门是否会增加参赛者赢得汽车的几率？
如果严格按照上述条件，即主持人清楚地知道，自己打开的那扇门后面是羊，那么答案是会。不换门的话，赢得汽车的几率是1/3,，换门的话，赢得汽车的几率是2/3。
蒙特卡洛思想的应用
应用蒙特卡洛重点在使用随机数来模拟类似于赌博问题的赢率问题，并且通过多次模拟得到所要计算值的模拟值。 在三门问题中，用0、1、2分代表三扇门的编号，在[0,2]之间随机生成一个整数代表奖品所在门的编号prize，再次在[0,2]之间随机生成一个整数代表参赛者所选择的门的编号guess。用变量change代表游戏中的换门（true）与不换门（false）。
import random def play(change): prize = random.randint(0, 2) guess = random.randint(0, 2) if guess == prize: if change: return False else: return True else: if change: return True else: return False def winRate(change, N): win = 0 for i in range(N): if (play(change)): win += 1 print("中奖率为{}".format(win / N)) N = 1000000 if __name__ == "__main__": print("每次换门的中奖概率：") winRate(True, N) print("每次都不换门的中奖概率：") winRate(False, N) # 理论换门2/3 不换门1/3 # 每次换门的中奖概率： # 中奖率为0.665769 # 每次都不换门的中奖概率： # 中奖率为0.33292 例4 M&amp;M豆贝叶斯统计问题
M&amp;M豆是有各种颜色的糖果巧克力豆。制造M&amp;M豆的Mars公司会不时变更不同颜色巧克力豆之间的混合比例。
在此前一袋普通的M&amp;M豆中，颜色的搭配为：30%褐色，20%黄色，20%红色，10%绿色，10%橙色，10%黄褐色。
这之后变成了：24%蓝色，20%绿色，16%橙色，14%黄色，13%红色，13%褐色。
假设已知两袋M&amp;M豆，一袋是1994年，一袋是1996年。但不知道具体哪个袋子是哪一年的，现从每个袋子里各取了一个M&amp;M豆，一个是黄色，一个是绿色的。那么黄色豆来自1994年的袋子的概率是多少？
import time import random for i in range(10): print(time.strftime("%Y-%m-%d%X",time.localtime())) dou = {1994:{'褐色':30,'黄色':20,'红色':20,'绿色':10,'橙色':10,'黄褐':30}, 1996:{'蓝色':24,'绿色':20,'橙色':16,'黄色':14,'红色':13,'褐色':13}} num = 10000 list_1994 = ['褐色']*30*num+['黄色']*20*num+['红色']*20*num+['绿色']*10*num+['橙色']*10*num+['黄褐']*10*num list_1996 = ['蓝色']*24*num+['绿色']*20*num+['橙色']*16*num+['黄色']*14*num+['红色']*13*num+['褐色']*13*num random.shuffle(list_1994) random.shuffle(list_1996) count_all = 0 count_key = 0 for key in range(100 * num): if list_1994[key] == '黄色' and list_1996[key] == '绿色': count_all += 1 count_key += 1 if list_1994[key] == '绿色' and list_1996[key] == '黄色': count_all += 1 print(count_key / count_all,20/27) print(time.strftime("%Y-%m-%d%X",time.localtime())) # 0.7407064573459715 0.7407407407407407 # 20/27是理论答案 例5 书店购书问题（0-1规划问题）
某同学从六家线上商场选购五本书籍，B1、B2、B3、B4、B5，每本书籍在不同商家的售价以及每个商家的单次运费如下表所示，请给该同学制定最省钱的选购方案。（注：在同一家店购买多本书也只会收取一次运费）
B1 B2 B3 B4 B5 运费 A商城 18 39 29 48 59 10 B商城 24 45 23 54 44 15 C商城 22 45 23 53 53 15 D商城 28 47 17 57 47 10 E商城 24 42 24 47 59 10 F商城 27 48 20 55 53 15 import numpy as np import random # 用于去掉列表中的重复元素 def func1(data_list): return list(set(data_list)) min_money = float('inf') # 初始化最小的花费为无穷大，后续只要找到比它小的就更新 min_result = np.random.randint(1, 7, size=5) # 初始化五本书都在哪一家书店购买，后续我们不断对其更新 # 若min_result = [5 3 6 2 3]，则解释为：第1本书在第5家店买，第2本书在第3家店买，第3本书在第6家店买，第4本书在第2家店买，第5本书在第3家店买 n = 800000 # 蒙特卡罗模拟的次数 M = np.array([[18, 39, 29, 48, 59], [24, 45, 23, 54, 44], [22, 45, 23, 53, 53], [28, 47, 17, 57, 47], [24, 42, 24, 47, 59], [27, 48, 20, 55, 53]]) # m_ij 第j本书在第i家店的售价 freight = [10, 15, 15, 10, 10, 15] # 第i家店的运费 for i in range(0, n): result = np.random.randint(0, 6, size=5) # 在1-6这些整数中随机抽取一个1*5的向量，表示这五本书分别在哪家书店购买 index = func1(result) # 在哪些商店购买了商品，因为我们等下要计算运费 # print(index) money = 0 for j in index: money = money + freight[j] # print(money) # 计算总花费：刚刚计算出来的运费 + 五本书的售价 for k in range(0, 5): money = money + M[result[k] - 1, k] if money &lt; min_money: # 判断刚刚随机生成的这组数据的花费是否小于最小花费，如果小于的话 min_money = money # 我们更新最小的花费 min_result = result # 用这组数据更新最小花费的结果 print(min_result) print(min_money) # 最优情况为： [1 1 4 1 4] # 最少花费为: 194</content></entry><entry><title>Mysql-use notes</title><url>https://murphyhanxu.github.io/post/mysql-use/</url><categories><category>CS</category></categories><tags><tag>SQL</tag></tags><content type="html"> 学习Mysql视频记录的笔记 整理MySQL最常用的SQL语句（增删改查CRUD）。 更多的命令可参考：https://www.runoob.com/mysql/mysql-select-database.html
#Mysql-use
常用命令 执行下列SQL语句前，请参照上节内容登录MySQL环境。
选择数据库（上节已创建数据库mypython）。
mysql>usemypython;系统提示“Database changed”代表操作成功。
查看系统中默认的表。
在我们创建数据库时，系统会默认创建一些表。使用如下命令可查看。
mysql>showtables; 查看其他库的所有表。
当已经在一个库中，想查看另外库的表，可用如下命令。
mysql>showtablesfrom库名； 使用create table语句，创建自己的表。
下例的表名为students_info，他有id，name，gender，class四个字段，其中id为主键。
mysql>createtablestudents_info(idvarchar(10)notnull,#列名 列类型 namevarchar(10)notnull,gendervarchar(10),classint,primarykey(id));下例的表名为test_scores，他有id，student_id，subject，score，submit_date四个字段，id为主键，且为自增长字段，即每次插入数据时自动加1。
mysql>createtabletest_scores(idintnotnullauto_increment,student_idvarchar(10)notnull,subjectvarchar(10)notnull,scoreintnotnull,submit_dateDate,primarykey(id));创建完毕，可以重复步骤2的命令（show tables），检查是否创建成功。
查看服务器版本
mysql>selectversion() MYSQL的语法规范 不区分大小写，但建议关键字大写，表明、列名小写
每条命令最好用分号结尾
每条命令根据需要，可以进行缩进或换行
注释
单行注释：#注释内容 单行注释：--注释内容多行注释：/*注释内容*/ DQL语言的学习 基础查询 查询常量、表达式、函数
mysql>select内容1,内容2...from表名；查询的结果是一个虚拟的表格
起别名
mysql>select内容1as别名1,内容2as别名2from表名;select内容1别名1,内容2别名2from表名; 去重
mysql>selectdistinct内容from表名; +号的作用
只有一个功能：运算符。
select 100+90; 两个操作数都为数值型，则做加法运算。
select &lsquo;123&rsquo;+321; 其中一方为字符型，试图将字符型数值转换成数值型。如果转换成功，则继续做加法运算。如果转换失败，则将字符型数值转换成0。
select null+1; 只要其中一方为null，则结果一定为null。
mysql>select内容1+内容2as别名from表名; 使用concat进行连接
mysql>selectconcat(内容1，内容2)as别名from表名; 条件查询 where语法
mysql>select内容from表名where筛选条件;根据筛选条件可分类：
1.按条件表达式筛选。条件运算符：＞,＜,＝,&lt;>, >=, &lt;=
2.按逻辑表达式筛选。用于连接逻辑表达式。逻辑运算符：and, or, not
3.模糊查询。
​ like, 一般和通配符搭配使用，通配符：%：任意多（0）个字符，_：任意单个字符。
​ between and, data between 10 and 20等价于data >=10 and data &lt;=20
​ in, 判断某字段的值是否属于in列表中的某一项。使用in提高语句简洁度，in列表的值类型必须一致或兼容，不支持使用通配符。
​ is (not) null,=或&lt;>不能用于判断null值，is (not) null 可以用来判断null值。
安全等于&lt;=>
安全等于既可以判断null值又可以判断普通数值，可读性低。
is (not) null只能判断null值，可读性高。
排序查询 语法
mysql>select内容from表名where筛选条件orderby排序列表desc(asc)特点：
1.desc 降序，asc 升序。如果不写默认是升序。
2.order by子句中可以支持单个字段、多个字段、表达式、函数、别名。
3.order by子句一般是放在查询语句的最后面，limit子句除外。
常见函数 功能：类似于java的方法，将一组逻辑语句封装在方法体中，对外暴露方法名。
好处：1.隐藏了实现细节。2.提高代码的重用性。
调用：
mysql>select函数名()from表名;分类：1.单行函数：如concat(), length(), ifnull() 等
​ 2.分组函数：做统计使用，又称为统计函数、聚合函数、组函数
字符函数
length()：获取参数值的字节个数
mysql>selectlength('john');--4selectlength('我爱你')--9concat()：拼接字符串
mysql>selectconcat(lastname,'_',firstname)姓名fromemployees;upper(), lower()：大写小写
mysql>selectupper('john');selectlower('JOHN');substr(), substring()：返回子字符串
索引从1开始
mysql>selectsubstr('柯西的柯西收敛原理',4);--柯西收敛原理selectsubstr('柯西的柯西收敛原理',4,4);--柯西收敛instr()：返回子串第一次出现的索引，如果找不到返回0
mysql>selectinstr('有理数是实数集的稠子集','实数集');--5trim()：掐头去尾
mysql>selecttrim(' 你是人间肆月甜 ');--你是人间肆月甜selecttrim('a'from'aaaaa你是人间肆月甜');--你是人间肆月甜lpad()：用指定字符实现左填充指定长度
mysql>selectlpad('mathmatical analysis',5,'*');--*****mathmaticalanalysisrpad()：用指定字符实现右填充指定长度
mysql>selectrpad('mathmatical analysis',5,'*');--mathmaticalanalysis*****replace()：替换
mysql>selectreplace('张无忌爱上了周芷若','周芷若','赵敏');--张无忌爱上了赵敏 数学函数
round()：四舍五入
mysql>selectround(5.567,2);--5.57selectround(5.2);--5ceil()：向上取整，返回>=改参数的最小整数
mysql>selectceil();floor()：向下取整，返回&lt;=改参数的最大整数
mysql>selectfloor(-9.99);-- -10 truncate()：截断
mysql>selecttruncate(1.65,1);--1.6mod()：取余
mysql>selectmod(10,3);--1mod(a,b)=a-a/b*b
日期函数
now()：返回当前系统日期+时间
mysql>selectnow();curdate()：返回当前日期，不包含时间
mysql>selectcurdate();curtime()：返回当前时间，不包含日期
mysql>selectcurtime();year(), month(), monthname(), day(), hour(), minute(), second()：可以获取数据的对应值
mysql>selectyear(now());str_to_date：将字符通过指定的格式转换成日期
mysql>selectstr_to_date('2002-2-19','%Y-%c-%d');--2002-2-19date_format：将日期转换成字符
mysql>selectdate_format(now(),'%Y年%m月%d日'); 其它函数
mysql>selectversion();selectdatabase();selectuser(); 流程控制函数
1.if()：
mysql>selectif(表达式,ans1,ans2);如果表达式为真，返回ans1。如果表达式为假，返回ans2。
2.case()：
mysql>selectsalary,department_idcasedepartment_idwhen30thensalary*1.1when40thensalary*1.2when50thensalary*1.3elsesalaryendasnewsalaryfromemployees;mysql>selectsalary,casewhensalary>20000then'A'whensalary>15000then'B'whensalary>10000then'C'else'D'endassalarylevelfromemployees 分组函数 功能：用作统计使用，又称为聚合函数或统计函数或组函数。
sum 求和，avg 平均值，max 最大值，min 最小值，count 计算个数
简单的使用
mysql>selectsum(salary)fromemployees;selectavg(salary)fromemployees;selectmin(salary)fromemployees;selectmax(salary)fromemployees;selectcount(salary)fromemployees;mysql>selectsum(salary)和,avg(salary)平均fromemployees; 参数支持哪些类型
sum(), avg()，一般用于数值型。
max(), min()，可以处理任何类型。
count()，计算不为null的个数。
是否忽略null值
以上分组函数都忽略null值
可以和distinct搭配使用
mysql>selectsum(distinctsalary),sum(salary)fromemployees;selectcount(distinctsalary),count(salary)fromemployees; count()函数的详细介绍
mysql>selectcount(salary)fromemployees;selectcount(*)fromemployees;#在表里写一列常量值并统计个数 selectcount(1)fromemployees;效率：
myisam存储引擎下，count(*)的效率高
innodb存储引擎下，count(*)和count(1)效率差不多，比count(字段)要高一些
和分组函数一同查询的字段有限制
和分组函数一同查询的字段要求是group by后的字段
分组查询 mysql>selectgroup_function(column),columnfromtablewhereconditiongroupbygroup_by_expressionorderbycolumn;注意，查询列表必须特殊，要求是分组函数和group by后出现的字段
例：
mysql>selectmax(salary),job_idfromemployeesgroupbyjob_id;mysql>selectcount(*),location_idfromdepartmentsgroupbylocation_id;mysql>selectavg(salary),department_idfromemployeeswhereemaillike'%a%'groupbydepartment_id;mysql>selectmax(salary),manager_idfromemployeeswherecommision_pctisnotnullgroupbymanager_id;mysql>#添加分组后的筛选 selectcount(*),department_idfromemployeesgroupbydepartment_idhavingcount(*)>2;mysql>#添加分组后的筛选 selectmax(salary),job_idfromemployeeswherecommission_petisnotnullgroupbyjob_idhavingmax(salary)>12000;mysql>#添加分组后的筛选 selectmin(salary),manager_idfromemployeeswheremanager_id>12groupbymanager_idhavingmin(salary)>5000;按表达式或函数分组，例：
mysql>selectcount(*)c,length(lase_name)len_namefromemployeesgroupbylen_namehavingc>5;按多个字段分组，例：
mysql>selectavg(salary),department_id,job_idfromemployeesgroupbydepartment_id,job_id添加排序，例：
mysql>selectavg(salary),department_id,job_idfromemployeeswheredepartment_idisnotnullgroupbydepartment_id,job_idhavingavg(salary)>10000orderbyavg(salary)desc;总结：
1.分组查询中的筛选条件分为两类。分组前筛选，分组后筛选。数据源不一样。前者为原始表，后者为分组后的结果集。位置不一样。前者为group by子句前，关键字为where，后者为group by子句后，关键字为having。
分组函数做条件肯定是放在having子句中。
2.group by子句支持单个字段分组，多个字段分组，表达式或函数
3.也可以添加排序（排序放在整个分组查询的最后）
连接查询 含义：又称多表连接，当查询的字段来自于多个表时，就会用到连接查询。
笛卡尔乘积现象：表1有m行，表2有n行，结果=m*n行
发生原因：没有有效的连接条件
分类：
​ 按年代分类：sq192标准：仅支持内连接；
​ sq199标准：支持内连接，外连接（左外连接+右外连接），交叉连接
​ 按功能分类：内连接(inner)：等值连接；非等值连接，自连接。
​ 外连接：左外连接(left)；右外连接(right)；全外连接(full)。
​ 交叉连接(cross)
sq92: 等值连接
例：
mysql>selectlast_name,department_namefromemployees,departmentswhereemployees.'department_id'=departments.'department_id';mysql>selectlast_name,e.'job_id',job_titlefromemployeesase,jobsasjwheree.'job_id'=j.'job_id';注意：如果为表起了别名，则查询的字段（select）就不能使用原来的表名去限定
mysql>selectlast_name,depatment_namefromemployeesase,departmentsasdwheree.'department_id'=d.'department_id'ande.'commission_pct'isnotnull;mysql>selectdepartment_name,cityfromdepartmentsasd,locationaslwhered.'location_id'=l.'location_id'andcitylike'_o%'mysql>#可以添加分组和排序 selectcount(*)as个数,cityfromdepartmentsasd,locationsaslwhered.'location_id'=l.'location_id'groupbycity;mysql>selectjob_title,count(*)fromemployeesase,jobsasjwheree.'job_id'=j.'job_id'groupbyjob_titleorderbycount(*)desc;总结
1.多表等值连接的结果为多表的交集部分
2.n表连接，至少需要n-1个连接条件
3.多表的顺序没有要求
4.一般需要为表起别名
5.可以搭配前面介绍的所有子句使用，比如排序、分组、筛选
​ 2.非等值连接
例：
mysql>selectsalary,grade_levelfromemoloyeesase,job_gradesasgwheresalarybetweeng.'lowest_sal'andg.'hightest_sal'andg.'grade_level'='A';​ 3.自连接
例：
mysql>selecte.'employee_id',e.'last_name',m.'employee_id',m.'last_name'fromemployeesase,employeesasmwheree.'manager_id'=m.'employee_id';sq99: 内连接
特点：
添加排序、分组、筛选
inner可以省略
筛选条件放在where后面，连接条件放在on后面，提高分离性，便于阅读
inner join连接和sql92语法中的等值连接效果是一样的
​ 1.等值连接
mysql>#语法 select查询列表from表1innerjoin表2on连接条件;例：
mysql>selectlast_name,department_namefromemployeesaseinnerjoindepartmentsasdone.'department_id'=d.'department_id';mysql>selectlast_name,job_titlefromemployeesaseinnerjoinjobsasone.'job_id'=j.'job_id'wheree.'last_name'like'%e%';mysql>selectcity,count(*)部门个数fromdepartmentsasdinnerjoinlacationsaslond.'location_id'=l.'location_id'groupbycityhavingcount(*)>2;mysql>selectlastname,department_name,job_titlefromemployeesaseinnerjoindepartmentsasdone.'department_id'=d.'department_id'innerjoinjobsasjone.'job_id'=j.'job_id'orderbydepartment_namedesc;​ 2.非等值连接
例：
mysql>selectsalary,grade_levelfromemployeesasejoinjob_gradesasgone.'salary'betweeng.'lowest_sal'andg.'highest_sal';​ 3.自连接
例：
mysql>selecte.last_name,m.last_namefromemployeesasejoinemployeesasmone.'manager_id'=m.'employee_id'wheree.'last_name'like'%k%';外连接
应用场景：用于查询一个表中有，而另一个表中没有的记录
特点：
1.外连接的查询结果为主表中的所有记录
​ 如果从表中有和它匹配的，则显示匹配的值
​ 如果从表中没有和它匹配的，则显示null
​ 外连接查询结果=内连接查询结果+主表中有而从表中没有的记录
2.左外连接，left join左边的是主表
右外连接，right join右边的是主表
3.左外和右外交换两个表的顺序，可以实现同样的效果
例：
mysql>#左外连接 selectd.*,e.'employee_id'fromdepartmentsasdleftjoinemployeesaseond.'department_id'=e.'department_id'wheree.'employee_id'isnull;mysql>#右外连接 selectd.*,e.'employee_id'fromemployeesaserightjoindepartmentsasdond.'department_id'=e.'department_id'wheree.'employee_id'isnull;交叉连接：
mysql>#本质为实现笛卡尔乘积 selectgirls.*,boys.*fromgirlscrossjoinboys;子查询 含义：
出现在其他语句中的select语句，称为子查询。内部嵌套其他select语句的查询，称为主查询。
分类：
按子查询出现的位置。
按结果集的行列数不同。标量子查询（一行一列）；列子查询（一列多行）；行子查询（一行多列）；表子查询（多行多列）
​ 1.标量子查询
例：
mysql>select*fromemployeeswheresalary>(selectsalaryfromemployeeswherelast_name='Abel');mysql>selectlast_name,job_id,salaryfromemployeeswherejob_id=(selectjob_idfromemployeeswhereemployee_id=141)andsalary>(selectsalaryfromemployeeswhereemployee_id=143);​ 2.列子查询
例：
mysql>selectlast_namefromemployeeswheredepartment_idin(selectdistinctdepartment_idfromdepartmentswherelocation_idin(1400,1700));mysql>selectlast_namefromemployeeswheredepartment_id=(selectdistinctdepartment_idfromdepartmentswherelocation_idin(1400,1700));​ 3.行子查询
例：
mysql>select*fromemployeeswhere(employee_id,salary)=(selectmin(employee_id,max(salary)fromemployees)​ 4.select 后面的子查询
例：
mysql>selectd.*,(selectcount(*)fromemployeeswheree.'department_id'=d.'department_id')fromdepartmentsasd;mysql>select(selectdepartment_namefromdepartmentsasdinnerjoinemployeesaseond.'d.department_id'=e.'department+id'wheree.'employee_id'=102)部门名;​ 5.from后面的子查询
例：
mysql>selectag_dep.*,g.'grade_level'from(selectavg(salary),department_idfromemployeesgroupbydepartment_id)asag_depinnerjoinjob_gradesasgonag_dep.agbetweenlowest_salandhighest_sal;​ 6.exists后面（相关子查询）
例：
mysql>selectexists(selectemployee_idfromemployeeswheresalary=30000);分页查询 应用场景：当要显示的数据，一页显示不全，需要分页提交sql请求
语法：
mysql>select查询列表from表(jointype)join表2where筛选条件groupby分组字段having分组后的筛选orderby排序limitoffset,size;#offset要显示条目的起始索引（起始索引从0开始）(page-1)*s #size 要显示的条目个数 例：
mysql>#查询前5条员工信息 select*fromemployeeslimit0,5mysql>#查询第11条到第25条员工信息 select*fromemployeeslimit10,15mysql>#有奖金的员工信息，并且工资前10名显示 select*fromemployeeswherecommision_pctisnotnullorderbysalarydesclimit10;特点：
1.limit语句放在查询语句的最后，执行逻辑也是在最后
联合查询 语法：
mysql>查询语句1union查询语句2应用场景：
用于将多个表中相似信息连接在一起
特点：
1.要求多条查询语句的查询列表是一致的！
2.要求多条查询语句查询的每一列的类型和顺序是一致的
3.union关键字默认去重，如果使用union all可以包含重复项
例：
mysql>select*fromemployeeswhereemaillike'%a%'unionselect*fromemployeeswheredepartment_id>90;DML语言的学习 数据操作语言：数据的插入 insert，修改 update，删除 delete
插入语句 语法一：
mysql>insertinto表名(列名,...)values(值1,...);例：
mysql>#不可以为null的值必须插入值，可以为null的列如何插入值？ insertintobeauty(id,name,sex,phone)values(15,'王心凌','女','13888888888')语法二：
mysql>insertinto表名set列名=值,列名=值...;注：
1.方式一可以省略列名，但添加值的顺序必须和表中的顺序一致
2.方式一可以支持插入多行，方式二不支持
3.方式一支持子查询，省略了values()，方式二不支持
修改语句 语法：
mysql>update表名set列=新值,列=新值...where筛选条件;mysql>update表1别名inner(right,left)join表2别名on连接条件set列=值...where筛选条件;删除语句 语法：
mysql> delete from 表名 where 筛选条件; mysql> truncate table 表名; 1.delete可以加where条件，truncate不能加
2.truncate删除，效率比delete高
3.假如要删除的表中有自增长列，如果用delete删除后，再插入数据，自增长列的值从断点开始，而如果truncate删除后，再插入数据，自增长列的值从1开始。
4.truncate删除后没有返回值，而delete删除后有返回值。
5.truncate删除不能回滚，而delete删除可以回滚。
##DDL 数据定义语言
库和表的管理
一、库的管理：创建、修改、删除
二、表的管理：创建、修改、删除、复制
创建：create，修改alter，删除drop
###一、库的管理
1.库的创建
mysql> create database if not exists 库名; 2.库的修改
更改库的字符集
mysql> alter database 库名 character set gbk; 3.库的删除
mysql> drop database if exists 库名; ###二、表的创建
1.表的创建
mysql> create table if not exists 表名( 列名, 列的类型, [(长度) 约束], 列名, 列的类型, [(长度) 约束], ... 列名, 列的类型, [(长度) 约束] ); 2.表的修改
修改列名
mysql> alter table 表名 change column 旧列名 新列名 类型; 列的类型或约束
mysql> alter table 表名 modify column 列名 新类型; 添加列
mysql> alter table 表名 add column 新列名 新类型; 删除列
mysql> alter table 表名 drop column 列名; 修改表名
mysql> alter table 表名 rename to 新表名; 3.表的删除
mysql> drop table if exists 表名; 4.表的复制
mysql> 只复制表的结构 create table 新表名 like 旧表名; mysql> 复制表的结构和数据 create table 新表名 select * from 旧表名 mysql> 只复制部分数据 create table 新表名 select 内容1，内容2 from 旧表名 where 条件; mysql> 只复制某些字段 create table 新表名 select 内容 from 旧表名 where 0; ##常见的数据类型 数值型：整型，小数（定点数、浮点数） 字符型：较短的文本char,varchar，较长的文本text,blob（较长的二进制数据） 日期型：
###一、整型
整数类型 字节 范围 tinyint 1 有符号：-128~127，无符号：0~255 smallint 2 有符号：-32768~32767，无符号：0~65535 mediumint 3 有符号：-8388608~8388607，无符号：0~1677215 int/integer 4 有符号：-2147483648~2147483647，无符号：0~4294967295 bigint 8 有符号：-2^64-1~2^64，无符号2^65+1 特点： 1.如果不设置无符号还是有符号，默认是有符号，如果想设置无符号，需要添加unsigned关键字。 2.如果插入的数值超出了整型的范围，会报out of range异常，并且插入临界值。 3.如果不设置长度，会有默认的长度 4.若要设置显示宽度，则在数据类型后面加上（要显示的长度），如果不够会用0在左边填充，但必须搭配关键字zerofill写在数据类型后使用。 1.如何设置有符号和无符号
mysql> drop table if exists tab_int create table tab_int( t1 int, t2 int unsigned ) insert into tab_int values(-123) insert into tab_int values(-123); ###二、小数
浮点数类型 字节 float 4 double 8 定点数类型 字节 decimal(M,D) M+2 特点： 1.M表示整数位数+小数位数，D表示小数点后数字的位数，如果小数点后位数超出会自动四舍五入，如果整数部分超出整数位数则会插入临界值。 2.M和D都可以省略，会生成默认长度 ###三、字符型 较短的文本：char,varchar， 其他：binary和varbinary用于保存较短的二进制，enum用于保存枚举，set用于保存集合 较长的文本：text,blob（较长的二进制数据） 字符串类型|最多字符数|描述及存储需求|特点|空间耗费|效率 &ndash;|&ndash;|&ndash;|&ndash;|&ndash;| char(M)|M，可以省略，默认为1|M为0~255之间的整数|固定长度的字符|比较耗费|高 varchar(M)|M，不能省略|M为0~65535之间的整数|可变长度的字符|比较节省|低
###四、日期型
字符串类型 字节 最小值 最大值 date 4 1000-01-01 9999-12-31 datetime 8 1000-01-01 00:00:00 9999-12-31 23:59:59 timestamp 4 1970年 2038年的某个时刻 time 3 -838:59:59 838:59:59 year 1 1901 2155</content></entry><entry><title>Win 10环境下安装MySQL 5.7</title><url>https://murphyhanxu.github.io/post/mysql-install/</url><categories><category>CS</category></categories><tags><tag>SQL</tag></tags><content type="html"> 记录在Win 10下安装、配置MySQL 5.7的过程。
安装步骤 官网下载安装包（https://dev.mysql.com/downloads/mysql/）。 打开网站，默认显示的是最新的8.0版本；如果要下载5.7版本，需要打开Archives页签，将查询条件设置为5.7.36（目前5.7版本系列中最新的一个版本）。下载不包含测试套件的包即可。
将zip包解压到本机某个目录下。 例如： D:\mysql\mysql-5.7.36-winx64
在该目录下手工创建my.ini文件，拷贝如下内容，并根据实际安装目录修改两个basedir和datadir。
basedir配置为mysql安装目录，datadir在安装目录后加data。
**注意：**此时data文件夹并不存在，在执行后续安装步骤时会由系统自动创建。
[mysqld] #设置3306端口 port=3306 #设置mysql的安装目录 basedir=D:\mysql\mysql-5.7.36-winx64 #设置mysql数据库的数据的存放目录 datadir=D:\mysql\mysql-5.7.36-winx64\data #允许最大连接数 max_connections=200 #允许连接失败的次数。这是为了防止有人从该主机试图攻击数据库系统 max_connect_errors=10 #服务端使用的字符集默认为UTF8 character-set-server=utf8 #创建新表时将使用的默认存储引擎 default-storage-engine=INNODB #默认使用“mysql_native_password”插件认证 default_authentication_plugin=mysql_native_password [mysql] #设置mysql客户端默认字符集 default-character-set=utf8 [client] #设置mysql客户端连接服务端时默认使用的端口 port=3306 default-character-set=utf8 配置环境变量，为系统环境变量path添加一个值：MySQL安装目录下的bin目录。
例如 D:\mysql\mysql-5.7.36-winx64\bin
以管理员身份打开cmd窗口，执行如下命令初始化数据库：
**注意：**一定要用管理员身份打开cmd窗口，否则后续的安装步骤可能因为权限问题异常。
打开windows菜单，“开始 > Windows管理工具 > Windows系统 > 命令提示符”，单击鼠标右键，选择“更多 > 以管理员身份运行”。
C:\Windows\system32> mysqld --initialize-insecure --user=mysql 初始化完成后，检查MySQL根目录，会发现步骤3指定的data文件夹已创建成功。
同时，系统会创建root用户（密码为空）。
为windows安装mysql服务。
C:\Windows\system32> mysqld -install 系统提示“service successfully installed.”则代表配置成功。系统创建的默认服务名为mysql。
启动数据库服务
C:\Windows\system32> net start mysql 以root用户登录mysql。
C:\Windows\system32> mysql -u root -p 因为初始化数据库时我们没有设置密码，所以这里系统提示输入密码时，直接回车即可。 出现 mysql> 提示符，代表登录成功。
为root设置密码。
下面命令中引号内的部分即为要设置的密码，请自行修改。
mysql>alteruseruser()identifiedby"xxxpasswd";修改完成，退出登录。
mysql>quit 使用新设置的密码再次登录mysql，查看系统默认的数据库。
安装完毕，日常访问数据库时，可以用普通模式打开cmd窗口。
C:\Windows\system32>mysql-uroot-pmysql>showdatabases; 创建自己的数据库
这里假设要创建的数据库名为“mypython”，请根据自己的需要自行修改。
mysql>createdatabasemypython;创建完毕，仍然可以用show databases命令检查。
至此，MySQL的安装和配置完成，后续可以在这个环境基础上创建数据库表，并向表中插入、修改、删除、查询数据。
其他 安装过程中如果有异常需要回退，可以使用以下命令和前面的对应。
删除数据库：
mysql>dropdatabasemypython; 停止数据库服务
C:\Windows\system32> net stop mysql 卸载服务
C:\Windows\system32> mysqld -remove</content></entry><entry><title>Python中list、tuple、dict和set的对比小结</title><url>https://murphyhanxu.github.io/post/python-list/</url><categories><category>CS</category></categories><tags><tag>Python</tag></tags><content type="html"> 对Python中list、turple、dict和set这四种数据类型进行对比总结。
概览 列表list 元组tuple 字典dict 集合set 读写要求 读写 只读 只读 读写 读取方式 索引 索引 键key 只能遍历 值是否重复 是 是 键不能重复，值可以 否 数据存储 连续、静态 连续、静态 不连续、动态 不连续、动态 是否有序 是 是 否（自动正序） 否 初始化 [lvalue1, lvalue2] (tvalue1, tvalue2) {key1:value1, key2:value2} {svalue1, svalue2} 增 list.append(value) 只读 dict[key1] = value1 set.add(value1) 删 del list[2] 只读 del dict[key] set.remove(value1) 改 list[2]=newValue 只读 dict[key1] = newValue set.update(value) 查 list[2:] tuple[1:5] dict[key] value in set 应用场景 非结构化数据存储 稳定的数据存储 结构化数据存储 数据剔重 列表 列表是一组有序存储的数据，它的特性包括：
用中括号将元素括起来，元素之间有逗号隔开。
列表可存储任意类型的数据，列表中各元素的类型可以不同，列表中各元素的值可以重复。
列表数据按顺序存储（链式存储），每个元素都有索引，支持正序、倒序两种索引，正序索引从0开始，倒序索引从-1开始。
列表创建后，其中的数据可以修改。
样例代码：
# 定义列表 list_t1 = ['I', 'love', 'use', 'python', [1, 2, 'a']] list_t2 = list(["C语言中文网", "http://c.biancheng.net"]) print('list_t1:', list_t1) print('list_t2:', list_t2) # 将字符串转换成列表 list_t3 = list("hello") print('list_t3:', list_t3) # 将元组转换成列表 tuple1 = ('Python', 'Java', 'C++', 'JavaScript') list_t4 = list(tuple1) print('list_t4:', list_t4) # 将字典转换成列表 dict1 = {'a':100, 'b':42, 'c':9} list_t5 = list(dict1) print('list_t5:', list_t5) #将区间转换成列表 range1 = range(1, 6) list_t6 = list(range1) print('list_t6:', list_t6) #创建空列表 print(list()) # 使用列表表达式创建列表 list_t7 = [x * x for x in range(1, 11)] print('List Comprehensions, list_t7:', list_t7) list_t8 = [x * x for x in range(1, 11) if x % 2 == 0] print('List Comprehensions use if, list_t8:', list_t8) list_t9 = [m + n for m in 'ABC' for n in 'XYZ'] print('List Comprehensions use double cycle, list_t9:', list_t9) list_t10 = [x if x % 2 == 0 else -x for x in range(1, 11)] print('List Comprehensions use else, list_t10:', list_t10) print('--------------------------------------') # 获取list长度 # print('list length:%d'.format(len(list_t1))) print('length of list_t1:', len(list_t1)) print('--------------------------------------') # 判断列表中是否包含某元素 print('python is in list_t1:', ('python' in list_t1)) print('Python is in list_t1:', ('Python' in list_t1)) print('--------------------------------------') # 按索引获取list中某个元素的值 print('the first element of list_t1:', list_t1[0]) print('the last element of list_t1:', list_t1[-1]) print('the last element of list_t1:', list_t1[len(list_t1)-1]) # 切片，按索引获取list中某几个元素的值,注意左闭右开 print('the first three elements of list_t1:', list_t1[0:3]) print('the first three elements of list_t1:', list_t1[:3]) print('the last two elements of list_t1:', list_t1[-2:]) print('every two elements of list_t1:', list_t1[0:5:2]) print('--------------------------------------') # 根据元素值定位元素在列表中的index索引位置 print('index of python in list_t1：', list_t1.index('python')) print('--------------------------------------') # 统计某个值在列表元素中的个数 print('quantity of python in list_t1：', list_t1.count('python')) print('quantity of Python in list_t1：', list_t1.count('Python')) print('--------------------------------------') # 在list最后追加元素 list_t1.append('too') print('After append, list_t1:', list_t1) # 在list中间插入元素 list_t1.insert(1, 'really') print('After insert, list_t1:',list_t1) # 把一个list添加到另一个list中 list_t5.extend(list_t6) print('After extend, list_t5:',list_t5) # 合并两个list list_t7 = list_t3 + list_t4 print('After join list_t3 and list_t4:',list_t7) print('--------------------------------------') # 修改list中的元素 list_t1[-3] = 'java' print('modify list_t1:', list_t1) list_t1[4:7] = ['python', 'haha'] print('modify list_t1:', list_t1) print('--------------------------------------') # 删除list中的元素 del list_t1[1] print('delete element by index， list_t1:', list_t1) list_t1.pop() print('delete the last element， list_t1:', list_t1) list_t1.remove('love') print('delete element by value， list_t1:', list_t1) print('--------------------------------------') # 遍历列表 print('print the elements of list_t1 one by one:',end=' ') for i in range(len(list_t1)): print(list_t1[i], end=' ') print('\n--------------------------------------') # 同时遍历列表的索引和对应值 print('同时遍历列表的索引和对应值') for index, value in enumerate(list_t1): print('index: {0}value: {1}'.format(index, value)) print('--------------------------------------') # 排序 list_t1.sort() print('sort List_t1:', list_t1) list_t1.reverse() print('reverse List_t1:', list_t1) print('--------------------------------------') 测试结果：
list_t1: ['I', 'love', 'use', 'python', [1, 2, 'a']] list_t2: ['C语言中文网', 'http://c.biancheng.net'] list_t3: ['h', 'e', 'l', 'l', 'o'] list_t4: ['Python', 'Java', 'C++', 'JavaScript'] list_t5: ['a', 'b', 'c'] list_t6: [1, 2, 3, 4, 5] [] List Comprehensions, list_t7: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] List Comprehensions use if, list_t8: [4, 16, 36, 64, 100] List Comprehensions use double cycle, list_t9: ['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] List Comprehensions use else, list_t10: [-1, 2, -3, 4, -5, 6, -7, 8, -9, 10] -------------------------------------- length of list_t1: 5 -------------------------------------- python is in list_t1: True Python is in list_t1: False -------------------------------------- the first element of list_t1: I the last element of list_t1: [1, 2, 'a'] the last element of list_t1: [1, 2, 'a'] the first three elements of list_t1: ['I', 'love', 'use'] the first three elements of list_t1: ['I', 'love', 'use'] the last two elements of list_t1: ['python', [1, 2, 'a']] every two elements of list_t1: ['I', 'use', [1, 2, 'a']] -------------------------------------- index of python in list_t1： 3 -------------------------------------- quantity of python in list_t1： 1 quantity of Python in list_t1： 0 -------------------------------------- After append, list_t1: ['I', 'love', 'use', 'python', [1, 2, 'a'], 'too'] After insert, list_t1: ['I', 'really', 'love', 'use', 'python', [1, 2, 'a'], 'too'] After extend, list_t5: ['a', 'b', 'c', 1, 2, 3, 4, 5] After join list_t3 and list_t4: ['h', 'e', 'l', 'l', 'o', 'Python', 'Java', 'C++', 'JavaScript'] -------------------------------------- modify list_t1: ['I', 'really', 'love', 'use', 'java', [1, 2, 'a'], 'too'] modify list_t1: ['I', 'really', 'love', 'use', 'python', 'haha'] -------------------------------------- delete element by index， list_t1: ['I', 'love', 'use', 'python', 'haha'] delete the last element， list_t1: ['I', 'love', 'use', 'python'] delete element by value， list_t1: ['I', 'use', 'python'] -------------------------------------- print the elements of list_t1 one by one: I use python -------------------------------------- 同时遍历列表的索引和对应值 index: 0 value: I index: 1 value: use index: 2 value: python -------------------------------------- sort List_t1: ['I', 'python', 'use'] reverse List_t1: ['use', 'python', 'I'] -------------------------------------- 元组 元组是一组有序存储的数据，它的特性包括：
用小括号将元素括起来，元素之间有逗号隔开。
元组可存储任意类型的数据，元组中各元素的类型可以不同，元组中各元素的值可以重复。
元组数据按顺序存储（链式存储），每个元素都有索引，支持正序、倒序两种索引，正序索引从0开始，倒序索引从-1开始。
元组一经初始化，数据不能修改。
与列表相比，元组是不可变的，这使得它可以作为字典的 key，或者扔进集合里。元组放弃了对元素的增删，换取的是性能上的提升：创建元组比列表快，存储空间比列表占用更小。多线程并发的时候，元组是不需要加锁的，不用担心安全问题，编写也简单多了。
样例代码：
# 元组和列表一样，支持获取长度函数len、使用索引获取元素、切片、for和range遍历、for和enumerate遍历，以及in、not in判断。 # 由于元组的内容不能修改，他不支持增删改方法,也不支持sort和reverse排序方法。 # 可以将元组先转化为列表，排序后再转化回元组，间接实现元组排序。 tuple_t1 = ('banana', 'color', 'apple', 'dark') tmp_l1 = list(tuple_t1) tmp_l1.sort() tuple_t1 = tuple(tmp_l1) for index, value in enumerate(tuple_t1): print('index:%dvalue:%s' % (index, value)) print('--------------------------------------') 测试结果：
index:0 value:apple index:1 value:banana index:2 value:color index:3 value:dark -------------------------------------- 字典 字典是一组无序存储的key-value键值对，它的特性包括：
用大括号将元素括起来，每个元素包含一个键和一个值，键和值用冒号分隔，元素之间有逗号隔开。 字典中的键key可以是数字、字符串或者是元组等不可变类型；字典中的值value可以是任何数据类型。 字典中的键key是大小写敏感的，不能重复。可使用key，获取字典中对应的value。 字典根据key计算其保存位置（哈希算法），所以其内部存放顺序与key放入顺序无关。 与列表相比：字典的查找和插入的速度极快，不会随着key的增加而变慢；但字典需要占用大量的内存，内存浪费多。 样例代码：
# 直接定义字典 dict1 = {'name': '小明', 'sex': 'male', 'age': 18, 'high': 180} print('dict1:', dict1) print('--------------------------------------') # 使用dict和zip，将两个列表、元组或者字符串转为字典 print('use dict and zip') list1 = ['key1','key2','key3'] list2 = ['1','2','3'] dict2 = dict(zip(list1,list2)) print('dict2:', dict2) print('-------------') tuple1 = ('key1','key2','key3') tuple2 = ('1','2','3') dict2 = dict(zip(tuple1,tuple2)) print('dict2:', dict2) print('-------------') str1 = 'abcde' str2 = '12345' dict2 = dict(zip(str1,str2)) print('dict2:', dict2) print('--------------------------------------') # 使用dict，将嵌套列表或者元组映射转化为字典的key和value print('use dict') list3 = [['key1','value1'],['key2','value2'],['key3','value3']] dict3 = dict(list3) print('dict3:', dict3) print('-------------') list4 = [('key1','value1'),('key2','value2'),('key3','value3')] dict3 = dict(list4) print('dict3:', dict3) print('-------------') tuple3 = (['key1','value1'],['key2','value2'],['key3','value3']) dict3 = dict(tuple3) print('dict3:', dict3) print('-------------') tuple4 = (('key1','value1'),('key2','value2'),('key3','value3')) dict3 = dict(tuple4) print('dict3:', dict3) print('--------------------------------------') # 使用fromkeys方法创建字典 print('use fromkeys') list5 = ['语文', '数学', '英语'] dict4 = dict.fromkeys(list5) print('dict4:', dict4) dict4 = dict.fromkeys(list5, 60) print('dict4:', dict4) print('--------------------------------------') # 字典的key和value互转 dict5 = {value:key for key, value in dict2.items()} print('switch key and value of dict2:', dict5) print('--------------------------------------') # 获取dict的元素个数 print('length of dict1:', len(dict1)) print('--------------------------------------') # 判断字典中是否包含某元素 print('name is in dict1:', ('name' in dict1)) print('Name is in dict1:', ('Name' in dict1)) print('--------------------------------------') # 通过键访问元素,使用get方法避免key不存在时的异常 print('get value by key(name), dict1:', dict1['name']) print('get value by key(name), dict1:', dict1.get('name')) print('get value by key(school), dict1:', dict1.get('school')) print('get value by key(school), dict1:', dict1.get('school', 'haha')) print('--------------------------------------') # 添加单个元素 dict1['score'] = 100 print('add key(score), dict1:', dict1) # 添加多个元素（合并两个字典) dict8 = {'country': 'china', 'city': 'Beijing'} dict1.update(dict8) print('add dict8 to dict1:', dict1) # 修改单个元素的value dict1['score'] = 80 print('modify value of key(score), dict1:', dict1) #更新多个元素的值 dict1.update(name='王四', age=40) print('modify values, dict1:', dict1) # 设置默认 dict1.setdefault('score', 90) print('set default value, dict1:', dict1) dict1.setdefault('job', 'Stu') print('set default value, dict1:', dict1) print('--------------------------------------') # 字典删除 dict1.pop('score') print('delete key(score):', dict1) del dict1['country'] print('delete key(country):', dict1) dict1.popitem() print('delete the last key:', dict1) dict2.clear() print('clear dict2:', dict2) print('--------------------------------------') # 字典的视图,会随着字典的变化而变化 key = dict1.keys() value = dict1.values() item = dict1.items() print('keys of dict1：', key) print('values of dict1：', value) print('items of dict1：', item) dict1['school']='szu' print('keys of dict1：', key) print('values of dict1：', value) print('items of dict1：', item) print('--------------------------------------') # 使用视图，遍历字典元素 print('遍历字典元素') for key in dict1.keys(): print('键:', key, '\t值:', dict1[key]) print('-------------') for key in dict1: print('键:', key, '\t值:', dict1[key]) print('-------------') for key,value in dict1.items(): print('键:', key, '\t值:', value) print('--------------------------------------') 测试结果：
dict1: {'name': '小明', 'sex': 'male', 'age': 18, 'high': 180} -------------------------------------- use dict and zip dict2: {'key1': '1', 'key2': '2', 'key3': '3'} ------------- dict2: {'key1': '1', 'key2': '2', 'key3': '3'} ------------- dict2: {'a': '1', 'b': '2', 'c': '3', 'd': '4', 'e': '5'} -------------------------------------- use dict dict3: {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'} ------------- dict3: {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'} ------------- dict3: {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'} ------------- dict3: {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'} -------------------------------------- use fromkeys dict4: {'语文': None, '数学': None, '英语': None} dict4: {'语文': 60, '数学': 60, '英语': 60} -------------------------------------- switch key and value of dict2: {'1': 'a', '2': 'b', '3': 'c', '4': 'd', '5': 'e'} -------------------------------------- length of dict1: 4 -------------------------------------- name is in dict1: True Name is in dict1: False -------------------------------------- get value by key(name), dict1: 小明 get value by key(name), dict1: 小明 get value by key(school), dict1: None get value by key(school), dict1: haha -------------------------------------- add key(score), dict1: {'name': '小明', 'sex': 'male', 'age': 18, 'high': 180, 'score': 100} add dict8 to dict1: {'name': '小明', 'sex': 'male', 'age': 18, 'high': 180, 'score': 100, 'country': 'china', 'city': 'Beijing'} modify value of key(score), dict1: {'name': '小明', 'sex': 'male', 'age': 18, 'high': 180, 'score': 80, 'country': 'china', 'city': 'Beijing'} modify values, dict1: {'name': '王四', 'sex': 'male', 'age': 40, 'high': 180, 'score': 80, 'country': 'china', 'city': 'Beijing'} set default value, dict1: {'name': '王四', 'sex': 'male', 'age': 40, 'high': 180, 'score': 80, 'country': 'china', 'city': 'Beijing'} set default value, dict1: {'name': '王四', 'sex': 'male', 'age': 40, 'high': 180, 'score': 80, 'country': 'china', 'city': 'Beijing', 'job': 'Stu'} -------------------------------------- delete key(score): {'name': '王四', 'sex': 'male', 'age': 40, 'high': 180, 'country': 'china', 'city': 'Beijing', 'job': 'Stu'} delete key(country): {'name': '王四', 'sex': 'male', 'age': 40, 'high': 180, 'city': 'Beijing', 'job': 'Stu'} delete the last key: {'name': '王四', 'sex': 'male', 'age': 40, 'high': 180, 'city': 'Beijing'} clear dict2: {} -------------------------------------- keys of dict1： dict_keys(['name', 'sex', 'age', 'high', 'city']) values of dict1： dict_values(['王四', 'male', 40, 180, 'Beijing']) items of dict1： dict_items([('name', '王四'), ('sex', 'male'), ('age', 40), ('high', 180), ('city', 'Beijing')]) keys of dict1： dict_keys(['name', 'sex', 'age', 'high', 'city', 'school']) values of dict1： dict_values(['王四', 'male', 40, 180, 'Beijing', 'szu']) items of dict1： dict_items([('name', '王四'), ('sex', 'male'), ('age', 40), ('high', 180), ('city', 'Beijing'), ('school', 'szu')]) -------------------------------------- 遍历字典元素 键: name 值: 王四 键: sex 值: male 键: age 值: 40 键: high 值: 180 键: city 值: Beijing 键: school 值: szu ------------- 键: name 值: 王四 键: sex 值: male 键: age 值: 40 键: high 值: 180 键: city 值: Beijing 键: school 值: szu ------------- 键: name 值: 王四 键: sex 值: male 键: age 值: 40 键: high 值: 180 键: city 值: Beijing 键: school 值: szu -------------------------------------- 集合 集合是一组无序的、不重复的元素，它的特性包括：
用大括号将元素括起来，元素之间有逗号隔开。 集合和字典的区别在于没有存储对应的value。 集合中各元素的值不可重复，所以集合可用于数据剔重。 集合中的元素只能是不可变的数据类型，包括整型、浮点型、字符串、元组，无法存储列表、字典、集合这些可变的数据类型。 样例代码：
# 创建集合/不可变集合 set1 = {'Beijing', 'Shanghai', 'Shenzhen', 'HongKong'} print('set1:', set1) set2 = set('hello') print('set2:', set2) set3 = set([1,2,3,4,5,6,5,3]) print('set3:', set3) set4 = set((1,2,3,4,5,6,6,1)) print('set4:', set4) fzset1 = frozenset('python') print('fset1:', fzset1) print('--------------------------------------') # 获取set的元素个数 print('length of set1：', len(set1)) print('--------------------------------------') # 由于集合的无序性，访问集合只能遍历 print('访问集合只能遍历') for elem in set1: print(elem, end=',') print('\n--------------------------------------') # 集合中添加和修改元素 set1.add('Chengdu') set1.add((1, 2)) print('set1:', set1) set8 = set([2, 3, 4]) set1.update(set8) print('set1:', set1) print('--------------------------------------') # 删除集合元素 set1.remove(2) print('delete set1:', set1) set1.discard(2) print('delete set1:', set1) set1.discard((1, 2)) print('delete set1:', set1) aaa = set1.pop() print('after pop, aaa:', aaa) print('after pop, set1:', set1) set2.clear() print('clear set2:', set2) print('--------------------------------------') # 判断集合中是否包含某元素 print('Beijing is in set1:', ('Beijing' in set1)) print('beijing is in set1:', ('beijing' in set1)) print('--------------------------------------') # 比较两个集合的关系,判断集合关系的操作符：==、!=、&lt;、&lt;=、>、>= print('set1 > set8:', (set1 > set8)) print('set3 = set4:', (set3 == set4)) print('--------------------------------------') # 集合的并集 set5 = set1 | set8 print('union of set1 and set8:', set5) set5 = set1.union(set8) print('union of set1 and set8:', set5) print('--------------------------------------') # 集合的交集 set5 = set1 &amp; set8 print('intersection of set1 and set8:', set5) set5 = set1.intersection(set8) print('intersection of set1 and set8:', set5) print('--------------------------------------') # 集合的差集 set5 = set1 - set8 print('difference of set1 and set8:', set5) set5 = set1.difference(set8) print('difference of set1 and set8:', set5) print('--------------------------------------') # 集合的对称差分:有所有属于集合A和集合B，并且不同时属于集合A和集合B的元素组成。 set5 = set1 ^ set8 print('symmetric difference of set1 and set8:', set5) set5 = set1.symmetric_difference(set8) print('symmetric difference of set1 and set8:', set5) print('--------------------------------------') 测试结果：
set1: {'Shenzhen', 'Shanghai', 'Beijing', 'HongKong'} set2: {'h', 'e', 'l', 'o'} set3: {1, 2, 3, 4, 5, 6} set4: {1, 2, 3, 4, 5, 6} fset1: frozenset({'y', 'h', 'n', 'p', 'o', 't'}) -------------------------------------- length of set1： 4 -------------------------------------- 访问集合只能遍历 Shenzhen,Shanghai,Beijing,HongKong, -------------------------------------- set1: {(1, 2), 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} set1: {2, (1, 2), 3, 4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} -------------------------------------- delete set1: {(1, 2), 3, 4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} delete set1: {(1, 2), 3, 4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} delete set1: {3, 4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} after pop, aaa: 3 after pop, set1: {4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} clear set2: set() -------------------------------------- Beijing is in set1: True beijing is in set1: False -------------------------------------- set1 > set8: False set3 = set4: True -------------------------------------- union of set1 and set8: {2, 3, 4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} union of set1 and set8: {2, 3, 4, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} -------------------------------------- intersection of set1 and set8: {4} intersection of set1 and set8: {4} -------------------------------------- difference of set1 and set8: {'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} difference of set1 and set8: {'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} -------------------------------------- symmetric difference of set1 and set8: {2, 3, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} symmetric difference of set1 and set8: {2, 3, 'Shanghai', 'Shenzhen', 'Beijing', 'HongKong', 'Chengdu'} --------------------------------------</content></entry><entry><title>定制个人博客</title><url>https://murphyhanxu.github.io/post/setup-blog/</url><categories><category>CS</category></categories><tags><tag>GitHub Pages</tag><tag>Hugo</tag></tags><content type="html"> 昨天使用Hugo部署的网站框架里部署的还是themes带的样例页面。今天进行个性化定制，包括修改页面上的图片、链接等，并放入自己的博文。
需要修改的文件主要包括：
博文内容文件，在“D:\Hugo\myblog”下content文件夹下。 网站配置文件，在“D:\Hugo\myblog”下config文件夹下。 发布网站是用到的静态资源（如siderbar使用的头像图片），在主题目录下的静态资源文件夹“D:\Hugo\myblog\themes\hugo-theme-next\static”下。 如果自己加入的图片和原图的命名不同，就还需要根据实际修改相关的html文件，在主题目录下的布局文件夹“D:\Hugo\myblog\themes\hugo-theme-next\layouts”下。 本机启动Hugo server，下面的修改基本可以立即生效，方便一边修改一边验证。修改过程记录如下：
在“D:\Hugo\myblog\content”下放入自己写的博文。
注意：中文和英文的文章是分目录存放的。例如，中文博文放在“D:\Hugo\myblog\content\zh-CN\post”下。
post目录下原有的样例博文，可以直接删除，也可以通过设置draft属性为true来屏蔽。
博文中用到的图，我暂时放在post目录下了，md文件中的路径写的github上的URL。
逐一打开“D:\Hugo\myblog\config”下的配置文件，根据需要修改。
我实际只修改了“config.toml”、“languages”、“params.en.toml”和“params.zh-CN.toml”。
本地调试的时候，可以先改“development”子目录；调试完成需要同步修改“_default”子目录，否则Hugo发布的public站点文件还是错误的。
在“D:\Hugo\myblog\themes\hugo-theme-next\static\img”替换自己的图片。
该目录下是页面上的一些公共图片，例如siderbar的个人信息图片、博文下的QQ二维码、微信收款码等。
static下还有css、js文件夹，如果不修改页面样式，无需修改。
（可选）根据需要修改“D:\Hugo\myblog\themes\hugo-theme-next\layouts”下的页面组件html文件。
主要关注“D:\Hugo\myblog\themes\hugo-theme-next\layouts\partials”下的文件，通常有两种情况需要修改：
替换图片时，如果新文件和旧图片文件的名字不同，则将相关html中的link修改成新文件名。 修改页面显示内容。例如，我没有支付宝，就屏蔽了“D:\Hugo\myblog\themes\hugo-theme-next\layouts\partials\widgets\reward.html”中的支付宝收款二维码相关代码段。 将站点发布到GitHub。
清空public目录，再重新发布生成。
在站点根目录执行如下cmd命令：
$ hugo 进入"D:\Hugo\myblog\public"文件夹，鼠标右键选择“Git Bash Here”，进入Git Bash窗口，执行后续命令。
将文件提交到本机git库中。commit备注可以根据实际需要修改。
$ git add --all $ git commit -m "commit my own articles" 将站点提交到远程：
$ git push -u origin master</content></entry><entry><title>使用Hugo创建个人博客框架</title><url>https://murphyhanxu.github.io/post/setup-hugo/</url><categories><category>CS</category></categories><tags><tag>GitHub Pages</tag><tag>Hugo</tag></tags><content type="html">  在已经跑通了使用GitHub Pages建了自己的第一个hello world页面的前提下，今天尝试使用Hugo来建一个完整的静态网站框架。
 这里先介绍如何安装Hugo，使用Hugo创建站点，并引入一个主题。按照本文操作完，站点的页面还是themes带的样例页面。我将在下一篇文章中总结如何加入自己的博文，以及修改网站的其他个人信息。
前言  为什么我们能够使用不同的电脑（客户端）成功地访问同一个网站？
我们在浏览器输入网页地址，此地址称为统一资源定位器（URL），并且可以使用其自己的个人URL访问每个页面。浏览器会先在其缓存中查找请求的URL，如果不存在，它会请求操作系统地DNS服务器找到所需的IP地址。DNS服务器负责名称解析。可以在操作系统和路由器中配置要请求的DNS服务器。由于请求域名系统需要一些时间，因此已访问过的站点的IP地址通常存储在操作系统或浏览器的DNS缓存中。
接着，路由器作为互联网和家庭网络之间的接口。它从互联网请求数据并将其分发到台式计算机，笔记本电脑和平板电脑等网络设备。由于家庭网络中的设备使用本地IP地址相互通信，同时向外共享路由器的公共IP地址，因此需要路由器作为链路。然后，网络地址通过称为网络地址转换（NAT）的过程进行转换。
当识别出所选网页的IP地址时，浏览器从适当的Web服务器请求该页面的相关数据。此请求通过HTTP以数据包的形式发生，该数据包包含Web服务器为传递网页数据所需的所有信息。浏览器传达所选网页的IP地址，并提供有关操作系统本身以及应在其上显示网页的设备的信息。路由器将自己的公共IP地址添加为发送方，并将数据包转发到公共Internet。Web服务器处理该信息并发送一个HTTP状态码。如果请求成功，服务器发送状态码200和数据包，包含该页面所需的所有信息。如果服务器无法在请求的地址找到网页，则会发送状态码404。
最后，传入数据包从路由器转发到正在访问网页的计算机。然后，Web浏览器承担分析数据包的任务。网页通常包含HTML、Css和Java文件。这样我们想要访问的网页就呈现在我们眼前了。 现在我们想要自己搭建一个网站需要什么？
需要自己编写网页的HTML、Css、Java文件和一台云服务器以及提供上云的软件和管理云服务器的软件等等，这种搭建网站的方式详情见教程。
搭建这样的动态网站方式也有缺点，就是搭建云上服务太耗时，而且上传的网站页面生成很慢，也还有维护服务器、数据库的烦恼。以Wordpress作为博客的载体太笨重，对markdown格式的支持不是很好，且打开速度极慢。
 今天介绍一种快速简便的搭建静态网站的方式，不需要租云服务器等，只需使用到Hugo和GitHub pages。其中Hugo提供静态网站的生成，包括主题、样式等。GitHub pages提供网站的托管服务。
Hugo是什么？
Hugo 是一个快速且现代的静态网站生成器，采用 Go 编程语言开发，Hugo 的设计目标是让创建网站重新变得有趣。
Hugo 是一个通用的网站框架。从技术上讲，Hugo是一个静态站点生成器。与动态构建页面的系统不同，Hugo在创建或更新内容时构建页面。由于网站的浏览频率远高于编辑频率，因此Hugo旨在为您的网站最终用户提供最佳的浏览体验，并为网站作者提供理想的写作体验。
Hugo能干什么？
从技术的角度来说，Hugo从源目录读取文件和模板，并将其作为输入来创建完整的网站。
谁应该使用 Hugo ？
Hugo 适合那些喜欢用文本编辑器而不是浏览器来写作的人。
Hugo 是为那些想手工编写自己的网站代码而不必担心设置复杂的运行时、依赖项和数据库的人设计的。
Hugo 能够用于构建博客、公司网站、投资组合网站、文档、单一的登陆页面或有数千页面的网站。
Hugo的特点
相比于使用Wordpress搭建网站，Hugo拥有惊人的速度，强大的内容管理和模板语言，非常适合各种静态网站。它的构建时间极快（每页&lt;1ms）。
使用Hugo搭建网站的HTML文件都呈现在你自己的计算机上。在将文件复制到承载HTTP服务器的计算机之前，因为HTML文件不是动态生成的，你可以在本地查看这些万件。
GitHub是什么？
GitHub是一个面向开源及私有软件项目的托管平台，因为只支持Git作为唯一的版本库格式进行托管，故名GitHub。GitHub于2008年4月10日正式上线，除了Git代码仓库托管及基本的Web管理界面以外，还提供了订阅、讨论组、文本渲染、在线文件编辑器、协作图谱（报表）、代码片段分享（Gist）等功能。目前，其注册用户已经超过350万，托管版本数量也是非常之多，其中不乏知名开源项目Ruby on Rails、jQuery、python等。
GitHub功能特点
GitHub可以托管各种git库，并提供一个web界面，但它与外国的SourceForge、Google Code或中国的coding的服务不同，GitHub的独特卖点在于从另外一个项目进行分支的简易性。为一个项目贡献代码非常简单：首先点击项目站点的“fork”的按钮，然后将代码检出并将修改加入到刚才分出的代码库中，最后通过内建的“pull request”机制向项目负责人申请代码合并。已经有人将GitHub称为代码玩家的MySpace。
搭建步骤 1. 打开Hugo下载页面，获取与本机环境相匹配的安装包。 例如，我下载的是：“hugo_0.89.4_Windows-64bit.zip”。
2. 安装Hugo  1. 在本机建一个Hugo文件夹，为方便后续管理，在其下再建一个bin目录。 例如，我建的目录是“D:\works\Hugo\bin”
 2. 将安装包拷贝到bin目录下并解压。 解压成功后，可以在bin目录下看到“hugo.exe”。
3. 配置系统环境变量，为变量Path添加“hugo.exe”所在目录。 对于我来说，添加的是“D:\works\Hugo\bin”。 4. 执行如下命令，如果能显示版本号，则说明安装成功。
$ hugo version hugo v0.89.4-AB01BA6E windows/amd64 BuildDate=2021-11-17T08:24:09Z VendorInfo=gohugoio 3. 建立站点。  1. 在Windows cmd窗口下进入Hugo文件夹。 （注意这里是“D:\works\Hugo”，不是“D:\works\Hugo\bin”。)
 2. 假设要创建的站点目录为“myblog”，则执行如下命令：
>$ hugo new site myblog Congratulations! Your new Hugo site is created in D:\works\Hugo\myblog. Just a few more steps and you are ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ orcreate your own with the "hugo new theme &lt;THEMENAME>" command. 2. Perhaps you want to add some content. You can add single files with "hugo new &lt;SECTIONNAME>\&lt;FILENAME>.&lt;FORMAT>". 3. Start the built-in live server via "hugo server". Visit https://gohugo.io/ for quickstart guide and full documentation.  3. 加入主题并预览，下载themes。 访问Hugo主题页面，找一个自己喜欢的主题下载到上一步创建的“themes”文件夹下，并解压。
我这次下载的是NexT主题，它支持多设备显示自适应，同时支持评论、转发等博客需要的功能。
下载完成后，需要按照themes的说明做一些配置。对于我下载的主题，我按照要求把hugo-theme-next(-main)目录下的两个子目录config和content到站点根目录（即“D:\works\Hugo\myblog”)下。
 4. 在本地启动站点。在站点根目录执行如下cmd命令：
>$ hugo server Start building sites … hugo v0.89.4-AB01BA6E windows/amd64 BuildDate=2021-11-17T08:24:09Z VendorInfo=gohugoio | ZH-CN | EN -------------------+-------+----- Pages | 28 | 34 Paginator pages | 0 | 0 Non-page files | 8 | 0 Static files | 25 | 25 Processed images | 0 | 0 Aliases | 9 | 12 Sitemaps | 2 | 1 Cleaned | 0 | 0 Built in 42196 ms Watching for changes inD:\Hugo\myblog\{archetypes,content,data,layouts,static,themes} Watching for config changes in D:\Hugo\myblog\config.toml, D:\Hugo\myblog\config\_default, D:\Hugo\myblog\config\development Environment: "development" Serving pages from memory Running in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender Web Server is available at http://localhost:1313/ (bind address 127.0.0.1) Press Ctrl+C to stop  5. hugo服务启动完成时，将出现与上面相类似的响应。
 6. 在浏览器中访问“http://localhost:1313/”，检查本地站点效果。
 7. 在cmd窗口中按Ctrl+C，停止Hugo服务。
4. 发布需要提交到到GitHub的站点文件。  1. 将站点的BaseURL配置为GitHub Pages主页地址。待修改的文件包括“D:\works\Hugo\myblog\config.toml”、“D:\works\Hugo\myblog\config\development\config.toml”和“D:\works\Hugo\myblog\config_default\config.toml”，将BaseURL的值修改为“https://MurphyHanxu.github.io/”。
 2. 发布站点。 在站点根目录执行如下cmd命令：
$ hugo hugo v0.89.4-AB01BA6E windows/amd64 BuildDate=2021-11-17T08:24:09Z VendorInfo=gohugoio | ZH-CN | EN -------------------+-------+----- Pages | 28 | 34 Paginator pages | 0 | 0 Non-page files | 8 | 0 Static files | 25 | 25 Processed images | 0 | 0 Aliases | 9 | 12 Sitemaps | 2 | 1 Cleaned | 0 | 0 Total in 42190 ms 发布成功，可以在“D:\works\Hugo\myblog\”下看到public文件夹。将这个文件夹发布到GitHub即可。
5. 将站点发布到GitHub,详细参考廖雪峰git教程。  1. 进入上一步创建的"D:\works\Hugo\myblog\public"文件夹，鼠标右键选择“Git Bash Here”，进入Git Bash窗口，执行后续命令。
 2. 初始化git库：
$ git init Reinitialized existing Git repository in D:/Hugo/myblog/public/.git/  3. 将文件提交到本机git库中。commit备注可以根据实际需要修改。
$ git add --all $ git commit -m "first commit of Hugo site"  4. 检查本机git库是否已经提交成功。下例中的系统响应代表本地git库当前的分支名是master，并且本地已经没有需要commit的文件了。
$ git status On branch master Your branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits) nothing to commit, working tree clean  5. 使用如下命令，与远程GitHub公仓建立连接，并将站点提交到远程： 请根据自己的情况，修改GitHub仓库地址和本地分支名。
$ git remote add origin https://github.com/MurphyHanxu/MurphyHanxu.github.io.git $ git push -u origin master Enumerating objects: 206, done. Counting objects: 100% (206/206), done. Delta compression using up to 8 threads Compressing objects: 100% (64/64), done. Writing objects: 100% (205/205), 194.83 KiB | 32.47 MiB/s, done. Total 205 (delta 90), reused 190 (delta 83), pack-reused 0 remote: Resolving deltas: 100% (90/90), done. To https://github.com/Jasmine617/jasmine617.github.io.git 5e8f0dc..8850953 master -> master Branch 'master' set up to track remote branch 'master' from 'origin'. 如果git操作不熟练，这里可能会出现关联远程仓库失败或者推送失败的情况。请根据错误提示，搜索解决方法。 到此就完成了网页的上传，托管到了GitHub上。再根据上一篇blog的方法查看自己的网站页面。</content></entry><entry><title>Python中print小结</title><url>https://murphyhanxu.github.io/post/python-print/</url><categories><category>CS</category></categories><tags><tag>Python</tag></tags><content type="html"> 对Python中print函数的使用进行总结。包括：
print方法的基本语法格式。 使用多种方式进行打印格式化。 print语法格式 print()函数具有丰富的功能，详细语法格式如下：
print(value, ..., sep=' ', end='\n', file=sys.stdout, flush=False) 除了待打印输出的value，其他可选关键字参数如下：
file：类文件对象（stream），默认为当前的sys.stdout，即打印到屏幕上。如果指定一个文件，则打印输出到文件中。 sep：打印多个value时，在值之间插入的分隔字符串，默认为空格。 end：在最后一个值后附加的字符串，默认为换行符。 flush：控制输出缓存，一般为了可以获得较好的性能，保持为False即可。 样例代码：
# 在屏幕上打印一个字符串 print('hello world') # 打印输出到文件中 fp=open('D:/PycharmProjects/testfile.txt', 'a+') print('hello world', file=fp) fp.close() #打印多个字符串，用逗号分隔 print('hello world', 'python') #打印多个字符串，并设置参数间的分隔符 print('hello world', 'python', sep='|') # 使用加号，打印一个计算公式计算结果 print(3+1) # 使用加号，连接打印多个字符串 print('hello world'+'python') # 打印后不换行，设置和下一次打印间的分隔符 print('春风得意马蹄疾', end=' ') print('一夜看尽长安花') print('行到水穷处', end='\t') print('坐看云起时') print('--------------------------------------') # 待打印字符串中包含转义符 print('hello\tworld') print('hello\nworld') print('\'aaa\'') # 待打印字符串中包含字体颜色设置 print('\033[0:31:47m试试颜色\033[0m') print('\033[4;31m试试颜色\033[0m') print('--------------------------------------') 测试结果：
hello world hello world python hello world|python 4 hello worldpython 春风得意马蹄疾 一夜看尽长安花 行到水穷处 坐看云起时 -------------------------------------- hello world hello world 'aaa' 使用%进行数据格式化 print() 函数使用以%开头的转换说明符，对各种类型的数据进行格式化输出。
符号 描述 %c 格式化字符及其ASCII码 %s 格式化字符串 %d 格式化整数 %u 格式化无符号整型 %o 格式化无符号八进制数 %x 格式化无符号十六进制数 %X 格式化无符号十六进制数（大写） %f 格式化浮点数字，可指定小数点后的精度 %e 用科学计数法格式化浮点数 %E 作用同%e，用科学计数法格式化浮点数 %g %f和%e的简写 %G %f 和 %E 的简写 %p 用十六进制数格式化变量的地址 在使用上述转换说明符时，还可以添加辅助指令：
符号 功能 * 定义宽度或者小数点精度 - 用做左对齐 + 在正数前面显示加号( + ) 在正数前面显示空格 # 在八进制数前面显示零(&lsquo;0&rsquo;)，在十六进制前面显示'0x&rsquo;或者'0X&rsquo; 0 显示的数字前面填充'0&rsquo;而不是默认的空格 % &lsquo;%%&lsquo;输出一个单一的&rsquo;%&rsquo; m.n m 是显示的最小总宽度,n 是小数点后的位数 样例代码（格式化整数）：
# 格式化整数 num = 9855 print('这里有一个整数：%d'%num) #未定义数字宽度，按实际位数显示 print('这里有一个整数：%8d'%num) #定义数据宽度为8，不足的在左侧留空格 print('这里有一个整数：%08d'%num) #定义数据宽度为8，不足的在左侧用0补齐 print('这里有一个整数：%-08d'%num) #左对齐，数字后空格补齐8位 print('这里有一个整数：%03d'%num) #实际位数大于3，则按实际显示 print('这里有一个整数：%0*d'%(6,num)) #用*从后面的元组中获取宽度 print('这里有一个整数：%+08d'%num) #显示正负号 print('--------------------------------------') 测试结果：
这里有一个整数：9855 这里有一个整数： 9855 这里有一个整数：00009855 这里有一个整数：9855 这里有一个整数：9855 这里有一个整数：009855 这里有一个整数：+0009855 样例代码（转换整数的进制）：
# 显示整数的其他进制 print('它的八进制是：%o'%num) #显示八进制格式 print('它的八进制是：%#o'%num) #在八进制前显示0o print('它的十六进制是：%x'%num) #显示小写十六进制 print('它的十六进制是：%#X'%num) #显示大写十六进展，并在前面表示0X print('-------------') # 未使用格式化时，还可以使用函数进行进制转换 print('它的二进制是：',bin(num)) print('它的八进制是：',oct(num)) print('它的十六进制是：',hex(num)) print('--------------------------------------') 测试结果：
它的八进制是：23177 它的八进制是：0o23177 它的十六进制是：267f 它的十六进制是：0X267F ------------- 它的二进制是： 0b10011001111111 它的八进制是： 0o23177 它的十六进制是： 0x267f 样例代码（格式化浮点数）：
# 格式化浮点数 pi = 3.141592653 print('这是一个浮点数：%10.3f' % pi) #数字宽度为10，精度3 print("这是一个浮点数：%*.*f" % (8,3,pi)) #用*从后面的元组中读取字段宽度和精度 print("这是一个浮点数：%.*f" % (3,pi)) #用*从后面的元组中读取字段精度 print('这是一个浮点数：%010.3f' % pi) #用0填充空白 print('这是一个浮点数：%-10.3f' % pi) #左对齐，数字后面有5个占位的空格 print('这是一个浮点数：%+f' % pi) #显示正负号 测试结果：
这是一个浮点数： 3.142 这是一个浮点数： 3.142 这是一个浮点数：3.142 这是一个浮点数：000003.142 这是一个浮点数：3.142 这是一个浮点数：+3.141593 样例代码（格式化字符串）：
# 格式化字符串 name = "Jasmine" print('My name is：%s'%name) print('My name is：%10s'%name) 测试结果：
My name is：Jasmine My name is： Jasmine 使用format函数进行格式化 相对基本格式化输出采用‘%’的方法，format()功能更强大。
格式为：
print('{&lt;参数序号>:&lt;格式控制标记>}xxxxx{}xxxxxxxxx{}'.format(参数1, 参数2, 参数3)) 上述示例中：
xxxxx为静态内容，print直接输出。 每对{}对应一个参数，print输出时，将被format后定义的参数的值替换。 每对{}可以定义序号（例如{0}、{1}），也可以不定义。不定义时默认依次定义为{0}，{1}。 每对{}内可以定义辅助指令，辅助指令放置在:后，其格式为&lt;填充>&lt;对齐>&lt;宽度>&lt;,>&lt;.精度>&lt;类型> &lt;填充>：当输出宽度大于参数宽度时，显示的填充符号。如果不设置，则默认用空格填充。 &lt;对齐>：&lt;左对齐，>右对齐，^居中。默认为右对齐。 &lt;宽度>：参数输出时的总占位宽度。 &lt;,>：对于整数和浮点数，是否显示千位分隔符。 &lt;.精度>：浮点数的小数点后位数。 &lt;类型>：c、s、d、f等，对应输出参数的数据类型。 样例代码：
# 使用format格式化 name = '小明' age = 12 height = 1.5678 print('他是{}，今年{}岁，身高是{}米。'.format(name, age, height)) #{}中未定义参数序号，直接依次与format中的参数匹配 print('他是{0}，今年{2}岁，身高是{1}米。'.format(name, height, age)) #{}中标识参数序号，即为format中的参数顺序 print('他是{:^6}，今年{:04}岁，身高是{:.2f}米。'.format(name, age, height)) #name占10位并居中显示，age占4位空位用0填充，height保留2位小数 print('--------------------------------------') 测试结果：
他是小明，今年12岁，身高是1.5678米。 他是小明，今年12岁，身高是1.5678米。 他是 小明 ，今年0012岁，身高是1.57米。 使用f-string进行格式化 在print中使用f加字符串的方式，则在打印输出时，会将字符串中{}中的内容替换为对应的变量名的值。相比前面两种格式化方式，这种写法代码最简洁。
格式为：
print(f'xxxx{&lt;参数名>:&lt;格式控制标记>}xxxxx{参数名}xxxxxxxxx{参数名}') 上述示例中：
xxxxx为静态内容，print直接输出。 每对{}对应一个参数，需要定义参数名；print输出时，将显示为该参数的值。 每对{}内可以定义辅助指令，辅助指令放置在:后，其格式为&lt;填充>&lt;对齐>&lt;宽度>&lt;,>&lt;.精度>&lt;类型>，具体规则和format方法一致。 样例代码：
# 使用f-string格式化 print(f'他是{name}，今年{age}岁，身高是{height}米。') #{}中定义参数名 print(f'他是{name:^6}，今年{age:04d}岁，身高是{height:.2f}米。') print('--------------------------------------') 测试结果：
他是小明，今年12岁，身高是1.5678米。 他是 小明 ，今年0012岁，身高是1.57米。</content></entry><entry><title>创建第一个GitHub Page</title><url>https://murphyhanxu.github.io/post/setup-helloworld/</url><categories><category>CS</category></categories><tags><tag>GitHub Pages</tag></tags><content type="html"> 如果想把自己日常的学习心得记录下来，可以创建一个个人博客网站。经过几天的研究比较，发现使用GitHub提供的Pages功能，可以满足基本要求。
参照网上的多个总结，今天完成了我自己个人博客首页的创建（虽然只是一个hello world）。
建议先花半天时间，看看廖雪峰大神的git总结和GitHub Pages官方文档，系统了解一下git、GitHub等的关系，以及GitHub Pages的创建方法，搞清楚背景知识，实际动手会更顺利。
我的创建过程还比较顺利，基本过程记录如下：
访问GitHub官网，注册账号并登录。
注册仅需要个人邮箱。
在Github上创建仓库。
这个仓库是计划给GitHub Pages用的，所以注意仓库名要和用户名一致。
例如：MurphyHanxu.github.io
在本机安装git。
参考：廖雪峰博客-安装git
注意：安装完git后，一定要配置用户名和邮箱，否则后续commit会报错。
在Git Bash中执行如下命令，name和email请根据实际情况替换：
$ git config --global user.name "Murphy" $ git config --global user.email "123456@qq.com" 在本机生成SSH密钥，并配置到GitHub上。
配置密钥，是为了GitHub确认本机上传文件合法；如果不配置，后续将无法将文件push到GitHub上。
参考：廖雪峰博客-对接远程仓库
检查用户主目录（Windows环境为"C:\Users\yourusername"目录下是否存在".ssh"文件夹。如果不存在，需要生成公钥文件。
使用Git Bash执行，注意替换email：
$ ssh-keygen -t rsa -C "123456@qq.com" 再将公钥内容配置到GitHub中。
将GitHub上的仓库克隆到本地。
先在GitHub上获取仓库地址：
在本机创建一个文件夹，用于保存从公仓获取的文件，例如"D:\myplog"。打开该目录后鼠标右键选择“Git Bash Here”，进入Git Bash窗口，执行后续命令。
推荐使用SSH协议进行clone（请用从GitHub中拷贝的git仓库地址替换下例中的地址）：
$ git clone git@github.com:MurphyHanxu/MurphyHanxu.github.io.git Cloning into 'MurphyHanxu.github.io'... warning: You appear to have cloned an empty repository. 因为步骤2中创建的是一个空仓库，没有任何文件，上例的系统响应中有一个warning，无需理会。 如果使用HTTP协议，则为：
$ git clone https://github.com/Jasmine617/jasmine617.github.io.git 创建主页文件index.html，并提交到本机git库。
检查上一步中的"D:\myplog"文件夹，可以看到克隆成功后新增了一个文件夹"MurphyHanxu.github.io"。
在新增的"MurphyHanxu.github.io"文件夹下创建一个网页文件index.html，按html语法随便写一点内容。html样例如下：
&lt;!DOCTYPE html> &lt;html lang="en"> &lt;head> &lt;meta charset="UTF-8"> &lt;title>my first blog&lt;/title> &lt;/head> &lt;body> &lt;p>hello world&lt;/p> &lt;/body> &lt;/html> 在Git Bash中进入git库目录。将文件提交到本机git库中。commit备注可以根据实际需要修改。
$ cd MurphyHanxu.github.io $ git add --all $ git commit -m "test commit index.html" 将index.html推送到GitHub公仓。
检查本机git库是否已经提交成功。下例中的系统响应代表本地git库当前的分支名是main，并且本地已经没有需要commit的文件了（即新创建的index.html已经成功提交到本机git版本库）。
$ git status On branch main Your branch is up to date with 'origin/main'. nothing to commit, working tree clean 使用如下命令将新增的index.html提交到GitHub公仓，其中main是上个命令中查询到的本机git分支名：
$ git push origin main Enumerating objects: 3, done. Counting objects: 100% (3/3), done. Delta compression using up to 8 threads Compressing objects: 100% (2/2), done. Writing objects: 100% (3/3), 338 bytes | 338.00 KiB/s, done. Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 To https://github.com/MurphyHanxu/MurphyHanxu.github.io.git * [new branch] main -> main 检查GitHub Page。
首先在GitHub仓库中检查index.html文件是否已经存在。
再检查Pages设置是否正确。本例中index.html是上传仓库根目录下的，所以这里设置为root并保存。
打开GitHub Pages页面，如图显示则说明整个配置成功。</content></entry><entry><title>关于我</title><url>https://murphyhanxu.github.io/about.html</url><categories/><tags/><content type="html"> Hugo是用Go编写的一个开放源代码静态站点生成器，可在Apache许可证2.0下使用。 Hugo支持TOML, YAML和JSON数据文件类型，Markdown和HTML内容文件，并使用短代码添加丰富的内容。其他值得注意的功能包括分类法、多语言模式、图像处理、自定义输出格式、HTML/CSS/JS缩小和对Sass SCSS工作流的支持。
Hugo使用了多种开源项目，包括:
https://github.com/yuin/goldmark https://github.com/alecthomas/chroma https://github.com/muesli/smartcrop https://github.com/spf13/cobra https://github.com/spf13/viper Hugo是博客、企业网站、创意作品集、在线杂志、单页应用程序甚至是数千页的网站的理想选择。
Hugo适合那些想要手工编写自己的网站代码，而不用担心设置复杂的运行时、依赖关系和数据库的人。
使用Hugo建立的网站非常快速、安全，可以部署在任何地方，包括AWS、GitHub Pages、Heroku、Netlify和任何其他托管提供商。
更多信息请访问GitHub.</content></entry><entry><title/><url>https://murphyhanxu.github.io/post/dide3.3_notes/</url><categories/><tags/><content type="html"> author = &ldquo;Murphy&rdquo; title = &ldquo;DIDL3.2 Notes&rdquo; date = &ldquo;2022-09-07&rdquo;
description = "" tags = [ &ldquo;DIDL&rdquo;, ]
categories = [ &ldquo;CS&rdquo;, ]
math= true
toc= true
+++
3.3
线性回归的简洁实现
1.生成数据集 与3.2节相同，我们首先生成数据集。
import numpy as np import torch from torch.utils import data from d2l import torch as d2l true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = d2l.synthetic_data(true_w, true_b, 1000) 2.读取数据集 我们可以调用框架中现有的API来读取数据。我们将features和labels作为API的参数传递，并通过数据迭代器制定batch_size。此外，布尔值is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据。
def load_array(data_arrays, batch_size, is_train=True): #@save """构造一个PyTorch数据迭代器""" dataset = data.TensorDataset(*data_arrays) return data.DataLoader(dataset, batch_size, shuffle=is_train) batch_size = 10 data_iter = load_array((features, labels), batch_size) 使用data_iter的方式与我们在3.2节中使用data_iter函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。与3.2节不同，这里我们使用iter构造Python迭代器，并使用next从迭代器中获取第一项。
next(iter(data_iter)) print(next(iter(data_iter))) 3.定义模型 当我们在3.2节中实现线性回归时，我们明确定义了模型参数变量，并编写了计算的代码，这样通过基本的线性代数运算得到输出。但是，如果模型变得更加复杂，且当你几乎每天都需要实现模型时，你会想简化这个过程。这种情况类似于为自己的博客从零开始编写网页。做一两次是有益的，但如果每个新博客你就花一个月的时间重新开始编写网页，那并不高效。
对于标准深度学习模型，我们可以使用框架的预定义好的层。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。我们首先定义一个模型变量net，它是一个Sequential类的实例。Sequential类将多个层串联在一起。当给定输入数据时，Sequential实例将数据传入到第一层，然后将第一层的输出作为第二层的输入，以此类推。在下面的例子中，我们的模型只包含一个层，因此实际上不需要Sequential。但是由于以后几乎所有的模型都是多层的，在这里使用Sequential会让你熟悉“标准的流水线”。
回顾单层网络架构，这一单层被称为全连接层(fully-connected layer)，因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。
在PyTorch中，全连接层在Linear类中定义。值得注意的是，我们将两个参数传递到nn.Linear中。第一个指定输入特征形状，即2。第二个指定输出特征形状，输出特征形状为单个标量，因此为1。
# nn是神经网络的缩写 from torch import nn net = nn.Sequential(nn.Linear(2, 1)) 4.初始化模型参数 在使用net之前，我们需要初始化模型参数。如在线性回归模型中的权重和偏置。深度学习框架通常有预定义的方法来初始化参数。在这里，我们指定每个权重参数应该从均值为0，标准差为0.01的正太分布中随机采样，偏置参数将初始化为零。
正如我们在构造nn.Linear时指定输入和输出尺寸一样，现在我们能直接访问参数以设定它们的初始值。我们通过net[0]选择网络中的第一个图层，然后使用weight.data和bias.data方法访问参数。我们还可以使用替换方法normal_和fill_来重写参数值。
net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) 5.定义损失函数 计算均方误差使用的是MSELoss类，也称为平方$L_2$范数。默认情况下，它返回所有样本损失的平均值。
loss = nn.MSELoss() 6.定义优化算法 小批量随机梯度下降算法是一种优化神经网络的标准工具，PyTorch在optim模块中实现了该算法的许多变种。当我们实例化一个SGD实例时，我们要指定优化的参数（可通过net.parameters()从我们的模型中获得）以及优化算法所需的超参数字典。小批量随机梯度下降只需要设置lr值，这里设置为0.03。
trainer = torch.optim.SGD(net.parameters(), lr=0.03) 7.训练 通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。当我们需要更复杂的模型时，高级API的优势将大大增加。当我们有了所有的基本组件，训练过程代码与我们从零开始实现时所做的非常相似。
回顾一下：在每个迭代周期里，我们将完整遍历一次数据集(train_data)，不停地从中获取一个小批量的输入和相应的标签。对于每一个小批量，我们会进行以下步骤：
通过调用net(X)生成预测并计算损失l(前向传播)。 通过进行反向传播来计算梯度 通过调用优化器来更新模型参数。 为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。
num_epochs = 3 for epoch in range(num_epochs): for X, y in data_iter: l = loss(net(X) ,y) trainer.zero_grad() l.backward() trainer.step() l = loss(net(features), labels) print(f'epoch {epoch + 1}, loss {l:f}') 下面我们比较生成数据集的真实参数和通过有限数据训练获得的模型参数。要访问参数，我们首先从net访问所需的层，然后读取该层的权重和偏置。正如在3.2节中一样，我们估计得到的参数与生成数据的真实参数非常接近。
w = net[0].weight.data print('w的估计误差：', true_w - w.reshape(true_w.shape)) b = net[0].bias.data print('b的估计误差：', true_b - b)</content></entry><entry><title/><url>https://murphyhanxu.github.io/post/numericalanalysis_hw1/</url><categories/><tags/><content type="html"> 数值分析第一次作业 韩旭 2020141210183
2022-09-23
题目1. $(1.1)_{10}=(1.00011001100)_2$
用IEEE754单精度浮点数规则的表达形式为0011100011001100
最小正正规范数的表达式为0000100000000000
结果为$(-1)^0\times2^{(0001)_2-7}\times(1.00000000000)_2=1\times2^{-6}$
最大正正规范数的表达式为0111011111111111
结果为$(-1)^0\times2^{(1110)_2-7}\times(1.11111111111)_2=1.99951171875\times2^7$
题目2. 观察到在Python中
print(0.1+0,2==0.3) >False 这就是64位计算机中无法严格地将二进制数和十进制数一一对应，导致将$0.1$从二进制转换为十进制时，只能截取其二进制表示小数点后前53位，使其无限趋近于$0.1$。我们将其打印出来发现，$0.1$在十进制小数点后第16位出现了不确定小数。因此可以估计机器精度就在$10^{-16}$左右。于是编写程序，囿于电脑内存的限制，只能精确机器精度到小数点后第24位，实现程序如下：
# 机器精度的另外一种定义是满足float(1+e)>1的最小的e import numpy as np # 定义函数以小数点形式输出浮点数 def float_to_str(f): float_string = repr(f) if 'e' in float_string: digits, exp = float_string.split('e') digits = digits.replace('.', '').replace('-', '') exp = int(exp) zero_padding = '0' * (abs(int(exp)) - 1) # minus 1 for decimal point in the sci notation sign = '-' if f &lt; 0 else '' if exp > 0: float_string = '{}{}{}.0'.format(sign, digits, zero_padding) else: float_string = '{}0.{}{}'.format(sign, zero_padding, digits) return float_string # 囿于电脑内存的限制，只能精确机器精度到小数点后第24位 for e in np.arange(10**(-24), 10**(-15), 10**(-24)): if float(1+e)>1: eps=e break else: continue print(eps) print(float_to_str(eps)) 输出答案为：
>1.11022303e-16 >0.000000000000000111022303 题目3. import math for x in [10**3, 10**5, 10**7, 10**9, 10**11]: # print(x-math.sqrt(x*x-1)) ans = math.log(x-math.sqrt(x*x-1)) print(ans) >-7.600902209454717 >-12.206073762186564 >-16.805431370234086 >ValueError: math domain error 改进算法，将分子有理化，求函数值$f(x)=-ln(x+\sqrt{x^2+1})$
for x in [10**3, 10**5, 10**7, 10**9, 10**11]: # print(x+math.sqrt(x*x-1)) ans = -math.log(x+math.sqrt(x*x-1)) print(ans) >-7.600902209541989 >-12.206072645505174 >-16.811242831518264 >-21.416413017506358 >-26.021583203494448 题目4. import numpy as np import math def g(x): ans = (math.exp(1 + float(x)) - math.exp(1)) / float(x) return ans def cal_absloss(a, b): return abs(a - b) list1, list2 = [], [] for h in np.arange(1e-16, 1, 1e-16): # 取h从1e-16直到1，计算cal_absloss # 实际运行中可将区间(1e-16,1)分成(1e-16, 1e-11),(1e-12, 1e-7),(1e-8, 1e-3),(1e-4, 1)提高运行效率 loss = cal_absloss(g(h), math.exp(1)) list1.append(h) list2.append(loss) minloss=min(list2) dict1 = dict(zip(list2, list1)) print('loss = ', minloss) print('h = ', dict1[minloss]) >loss = 9.694911540236717e-12 >h = 8.6857e-11 题目5. import torch matrix1 = torch.tensor([[10, -1], [-1, 1]]) b1 = torch.tensor([[8], [1]]) x0 = torch.tensor([[0], [0]]) # print(x0.shape) x1 = x0+(b1-torch.mm(matrix1, x0)) # print(x1, x1.shape) x2 = x1+(b1-torch.mm(matrix1, x1)) x3 = x2+(b1-torch.mm(matrix1, x2)) x4 = x3+(b1-torch.mm(matrix1, x3)) x5 = x4+(b1-torch.mm(matrix1, x4)) x6 = x5+(b1-torch.mm(matrix1, x5)) x7 = x6+(b1-torch.mm(matrix1, x6)) x8 = x7+(b1-torch.mm(matrix1, x7)) x9 = x8+(b1-torch.mm(matrix1, x8)) x10 = x9+(b1-torch.mm(matrix1, x9)) print(x10, x10.shape) >tensor([[-3035438298], [ 333206829]]) torch.Size([2, 1]) import numpy as np matrix2 = np.array([[1, -0.1], [-1, 1]]) b2 = np.array([[0.8], [1]]) x0 = np.array([[0], [0]]) # print(x0.shape) x1 = x0+(b2-np.dot(matrix2, x0)) # print(x1, x1.shape) x2 = x1+(b2-np.dot(matrix2, x1)) x3 = x2+(b2-np.dot(matrix2, x2)) x4 = x3+(b2-np.dot(matrix2, x3)) x5 = x4+(b2-np.dot(matrix2, x4)) x6 = x5+(b2-np.dot(matrix2, x5)) x7 = x6+(b2-np.dot(matrix2, x6)) x8 = x7+(b2-np.dot(matrix2, x7)) x9 = x8+(b2-np.dot(matrix2, x8)) x10 = x9+(b2-np.dot(matrix2, x9)) print(x10, x10.shape) >[[0.99999] [1.99998]] (2, 1) 对于第一个线性方程组，可以得到精确解$x_{10}=[-3035438298, 333206829]^T$。
对于第二个线性方程组，计算过程中会出现无限循环小数，在进制转换时会产生方法误差，将小数点后16位截断，得到解$x_{10}=[0.99999, 1.99998]^T$
MathJax.Hub.Config({ tex2jax: {inlineMath: [['$', '$']]}, messageStyle: "none" });</content></entry></search>